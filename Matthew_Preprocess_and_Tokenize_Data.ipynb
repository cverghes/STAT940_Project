{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocess and Tokenize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 0.0\n",
      "Epoch 2/50, Train Loss: 0.0\n",
      "Epoch 3/50, Train Loss: 0.0\n",
      "Epoch 4/50, Train Loss: 0.0\n",
      "Early stopping occurred at epoch 4\n",
      "Preprocessing complete with embeddings. Data saved.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Set the random seed (for replicability)\n",
    "seed = 20777980\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Constants for tokenization\n",
    "PAD_TOKEN = \"<PAD>\"\n",
    "NOISE_LEVEL = 0.1\n",
    "EMBEDDING_DIM = 100  # Set the dimension of the embeddings\n",
    "EPOCHS = 50  # Number of epochs for Word2Vec training\n",
    "PATIENCE = 3  # Patience for early stopping (number of epochs to wait for improvement)\n",
    "MIN_DELTA = 0.0001  # Minimum change in loss to count as an improvement\n",
    "\n",
    "def tokenize_skeleton(skeleton_str):\n",
    "    \"\"\"Tokenize the skeleton string into a sequence of symbols.\"\"\"\n",
    "    skeleton_str = skeleton_str.replace(\"**\", \"^\")  # Replace '**' with '^'\n",
    "    pattern = r'[a-zA-Z_][a-zA-Z0-9_]*|[+\\-*/^(),.]|C|sin|cos|log|exp|sqrt'\n",
    "    tokens = re.findall(pattern, skeleton_str)\n",
    "    return tokens\n",
    "\n",
    "def train_word2vec_embeddings(dataset, embedding_dim=EMBEDDING_DIM, epochs=EPOCHS, patience_num_epochs=PATIENCE):\n",
    "    \"\"\"Train Word2Vec embeddings on the dataset over multiple epochs with early stopping.\"\"\"\n",
    "    sentences = []\n",
    "    for entry in dataset:\n",
    "        skeleton_str = entry[\"skeleton\"]\n",
    "        tokens = tokenize_skeleton(skeleton_str)\n",
    "        sentences.append(tokens)\n",
    "    \n",
    "    # Initialize the Word2Vec model\n",
    "    model = Word2Vec(sentences, vector_size=embedding_dim, window=5, min_count=1, workers=4, epochs=1)\n",
    "\n",
    "    best_loss = np.inf\n",
    "    num_epochs_without_improvement = 0\n",
    "    early_stopping = False\n",
    "\n",
    "    performance_metrics_DICT = {\n",
    "        \"epoch_list\": [],\n",
    "        \"train_loss_list\": [],\n",
    "    }\n",
    "\n",
    "    # Train Word2Vec model with early stopping\n",
    "    for epoch in range(epochs-1):\n",
    "        # Train for one epoch\n",
    "        model.train(sentences, total_examples=model.corpus_count, epochs=1)\n",
    "\n",
    "        # Get the current loss (Word2Vec model loss is stored in the 'trainables' attribute)\n",
    "        current_loss = model.get_latest_training_loss()\n",
    "\n",
    "        # Record loss\n",
    "        performance_metrics_DICT['epoch_list'].append(epoch+1)\n",
    "        performance_metrics_DICT['train_loss_list'].append(current_loss)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {current_loss}\")\n",
    "\n",
    "        # Early stopping check\n",
    "        if current_loss < best_loss:\n",
    "            best_loss = current_loss\n",
    "            model.save(\"Data/embeddings_model.model\")\n",
    "            num_epochs_without_improvement = 0\n",
    "            save_JSON(performance_metrics_DICT,'Data/embeddings_performance_metrics_DICT.json')\n",
    "        else:\n",
    "            num_epochs_without_improvement += 1\n",
    "\n",
    "        if num_epochs_without_improvement >= patience_num_epochs:\n",
    "            print(f'Early stopping occurred at epoch {epoch + 1}')\n",
    "            early_stopping = True\n",
    "            break\n",
    "        \n",
    "    if early_stopping == False:\n",
    "        model.save(\"Data/embeddings_model.model\")\n",
    "        save_JSON(performance_metrics_DICT,'Data/embeddings_performance_metrics_DICT.json')\n",
    "    return model, performance_metrics_DICT\n",
    "\n",
    "def build_vocab_and_embeddings(dataset, model=None):\n",
    "    \"\"\"Build vocabulary and convert tokens to embeddings using Word2Vec model.\"\"\"\n",
    "    token_set = set()\n",
    "    for entry in dataset:\n",
    "        skeleton_str = entry[\"skeleton\"]\n",
    "        tokens = tokenize_skeleton(skeleton_str)\n",
    "        token_set.update(tokens)\n",
    "    \n",
    "    # Convert tokens to embeddings using the Word2Vec model\n",
    "    vocab_embeddings = {}\n",
    "    if model:\n",
    "        for token in token_set:\n",
    "            if token in model.wv:\n",
    "                embedding = model.wv[token]\n",
    "                # Normalize the embedding to have a unit norm (length = 1)\n",
    "                embedding = normalize([embedding])[0]\n",
    "                vocab_embeddings[token] = embedding\n",
    "            else:\n",
    "                # If the token isn't in the model, use a random vector\n",
    "                vocab_embeddings[token] = np.random.uniform(-0.1, 0.1, size=EMBEDDING_DIM)\n",
    "    else:\n",
    "        # If no pre-trained model is provided, use random embeddings for all tokens\n",
    "        for token in token_set:\n",
    "            vocab_embeddings[token] = np.random.uniform(-0.1, 0.1, size=EMBEDDING_DIM)\n",
    "    \n",
    "    # Add PAD_TOKEN to the vocabulary and set its embedding to zero\n",
    "    vocab_embeddings[PAD_TOKEN] = np.zeros(EMBEDDING_DIM)\n",
    "    \n",
    "    return vocab_embeddings\n",
    "\n",
    "def tokenize_dataset_with_embeddings(dataset, vocab_embeddings):\n",
    "    \"\"\"Tokenize the dataset and convert tokens to embeddings.\"\"\"\n",
    "    tokenized_data = []\n",
    "    for entry in dataset:\n",
    "        skeleton_str = entry[\"skeleton\"]\n",
    "        tokenized_skeleton = [vocab_embeddings[token] for token in tokenize_skeleton(skeleton_str)]\n",
    "        \n",
    "        for data_point in entry[\"data\"]:\n",
    "            inputs = data_point[\"inputs\"]\n",
    "            output = data_point[\"output\"]\n",
    "            tokenized_data.append({\n",
    "                \"tokens\": tokenized_skeleton,\n",
    "                \"inputs\": inputs,\n",
    "                \"output\": output\n",
    "            })\n",
    "    \n",
    "    return tokenized_data\n",
    "\n",
    "def normalize_data(data, range_vals=(-1, 1)):\n",
    "    \"\"\"Normalize the inputs and outputs to the specified range.\"\"\"\n",
    "    input_keys = []\n",
    "    for dp in data:\n",
    "        input_keys.extend(dp[\"inputs\"].keys())\n",
    "    input_keys = sorted(set(input_keys), key=lambda x: (int(x[1:]), x))\n",
    "    \n",
    "    all_inputs = [dp[\"inputs\"] for dp in data]\n",
    "    all_outputs = [dp[\"output\"] for dp in data]\n",
    "    \n",
    "    input_mins = {key: min([inputs.get(key, float('inf')) for inputs in all_inputs]) for key in input_keys}\n",
    "    input_maxs = {key: max([inputs.get(key, float('-inf')) for inputs in all_inputs]) for key in input_keys}\n",
    "    output_min = min(all_outputs)\n",
    "    output_max = max(all_outputs)\n",
    "    \n",
    "    for dp in data:\n",
    "        normalized_inputs = {}\n",
    "        for key in input_keys:\n",
    "            if key in dp[\"inputs\"]:\n",
    "                normalized_inputs[key] = 2 * (dp[\"inputs\"][key] - input_mins[key]) / (input_maxs[key] - input_mins[key]) - 1\n",
    "            else:\n",
    "                normalized_inputs[key] = np.nan  \n",
    "        \n",
    "        normalized_output = 2 * (dp[\"output\"] - output_min) / (output_max - output_min) - 1\n",
    "        \n",
    "        dp[\"inputs\"] = normalized_inputs\n",
    "        dp[\"output\"] = normalized_output\n",
    "    \n",
    "    return data\n",
    "\n",
    "def add_masking_to_data(data):\n",
    "    \"\"\"Adds a mask to the data where 1 indicates valid data and 0 indicates NaN.\"\"\"\n",
    "    for dp in data:\n",
    "        dp[\"mask\"] = {key: 1 if not np.isnan(value) else 0 for key, value in dp[\"inputs\"].items()}\n",
    "    return data\n",
    "\n",
    "def add_noise_to_data(data, noise_type=\"gaussian\", noise_level=NOISE_LEVEL):\n",
    "    \"\"\"Add noise to the dataset while ensuring NaN values are ignored.\"\"\"\n",
    "    for dp in data:\n",
    "        for key, value in dp[\"inputs\"].items():\n",
    "            if not np.isnan(value):\n",
    "                if noise_type == \"gaussian\":\n",
    "                    dp[\"inputs\"][key] += np.random.normal(0, noise_level)\n",
    "                elif noise_type == \"uniform\":\n",
    "                    dp[\"inputs\"][key] += np.random.uniform(-noise_level, noise_level)\n",
    "        if not np.isnan(dp[\"output\"]):\n",
    "            if noise_type == \"gaussian\":\n",
    "                dp[\"output\"] += np.random.normal(0, noise_level)\n",
    "            elif noise_type == \"uniform\":\n",
    "                dp[\"output\"] += np.random.uniform(-noise_level, noise_level)\n",
    "    return data\n",
    "\n",
    "def pad_sequences(tokenized_data, max_length, pad_embedding, pad_token=PAD_TOKEN):\n",
    "    \"\"\"Pad tokenized sequences to a fixed length.\"\"\" \n",
    "    for dp in tokenized_data:\n",
    "        token_length = len(dp[\"tokens\"])\n",
    "        if token_length < max_length:\n",
    "            dp[\"tokens\"] = dp[\"tokens\"] + [pad_embedding]*(max_length - token_length)\n",
    "        elif token_length > max_length:\n",
    "            dp[\"tokens\"] = dp[\"tokens\"][:max_length]\n",
    "    return tokenized_data\n",
    "\n",
    "def load_dataset(file_path):\n",
    "    \"\"\"Load the dataset from a JSON file.\"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        dataset = [json.loads(line) for line in file]\n",
    "    return dataset\n",
    "\n",
    "def preprocess_and_tokenize_dataset(file_path, model=None, noise_type=\"gaussian\", noise_level=NOISE_LEVEL, max_length='max_length'):\n",
    "    # Step 1: Load dataset\n",
    "    dataset = load_dataset(file_path)\n",
    "\n",
    "    # Step 2: Train Word2Vec model if not provided\n",
    "    if model is None:\n",
    "        model, performance_metrics_DICT = train_word2vec_embeddings(dataset)\n",
    "\n",
    "    # Step 3: Build vocabulary with embeddings\n",
    "    vocab_embeddings = build_vocab_and_embeddings(dataset, model)\n",
    "\n",
    "    # Step 4: Tokenize dataset and convert tokens to embeddings\n",
    "    tokenized_data = tokenize_dataset_with_embeddings(dataset, vocab_embeddings)\n",
    "\n",
    "    # Step 5: Normalize the data and determine the maximum input length\n",
    "    normalized_data = normalize_data(tokenized_data)\n",
    "\n",
    "    masked_data = add_masking_to_data(normalized_data)\n",
    "    \n",
    "    # Step 6: Add noise to the data\n",
    "    noisy_data = add_noise_to_data(normalized_data, noise_type, noise_level)\n",
    "\n",
    "    if max_length == 'max_length':\n",
    "        MAX_LENGTH = max(len(dp[\"tokens\"]) for dp in noisy_data)\n",
    "    else:\n",
    "        MAX_LENGTH = max_length\n",
    "    \n",
    "    # Step 7: Pad sequences to a fixed length\n",
    "    padded_data = pad_sequences(noisy_data,MAX_LENGTH,vocab_embeddings['<PAD>'])\n",
    "    \n",
    "    return padded_data, vocab_embeddings, model, performance_metrics_DICT\n",
    "\n",
    "# Save preprocessed data\n",
    "def save_preprocessed_data(data, output_path):\n",
    "    \"\"\"Save the preprocessed data to a file with JSON serialization.\"\"\"\n",
    "    def convert_to_serializable(obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()  # Convert ndarray to list\n",
    "        if isinstance(obj, dict):\n",
    "            return {key: convert_to_serializable(value) for key, value in obj.items()}\n",
    "        if isinstance(obj, list):\n",
    "            return [convert_to_serializable(item) for item in obj]\n",
    "        return obj  # Return the object as-is if it's already serializable\n",
    "\n",
    "    with open(output_path, 'w') as file:\n",
    "        for dp in data:\n",
    "            json.dump(convert_to_serializable(dp), file)\n",
    "            file.write(\"\\n\")\n",
    "\n",
    "def save_JSON(data, filename):\n",
    "    \"\"\"Save data to a JSON file with support for NumPy arrays.\"\"\"\n",
    "    def convert_to_serializable(obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()  # Convert ndarray to list\n",
    "        if isinstance(obj, dict):\n",
    "            return {key: convert_to_serializable(value) for key, value in obj.items()}\n",
    "        return obj  # Return the object as-is if it's already serializable\n",
    "\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(convert_to_serializable(data), f)\n",
    "        \n",
    "def load_JSON(filename):\n",
    "    \"\"\"Load a JSON file.\"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "# Main script execution\n",
    "file_path = \"Data/combined_dataset_5_variables_dynamic_seed20777980.json\"\n",
    "\n",
    "# Process the data and train Word2Vec embeddings\n",
    "preprocessed_data, vocab_embeddings, model, performance_metrics_DICT = preprocess_and_tokenize_dataset(file_path)\n",
    "\n",
    "# Save the preprocessed data, vocab embeddings, and trained Word2Vec model\n",
    "save_preprocessed_data(preprocessed_data, \"Data/preprocessed_data_with_embeddings.json\")\n",
    "save_JSON(vocab_embeddings, \"Data/vocab_embeddings.json\")\n",
    "\n",
    "print(\"Preprocessing complete with embeddings. Data saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_14528\\215895176.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  token_ids = torch.tensor(token_ids, dtype=torch.float)  # Ensure it's a float tensor\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (320x100 and 128x256)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[174], line 5\u001b[0m\n",
      "\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m DiffusionModel(vocab_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(vocab), embedding_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, num_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, num_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n",
      "\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n",
      "\u001b[1;32m----> 5\u001b[0m model,performance_metrics_DICT \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_diffusion_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mpatience_num_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\n",
      "Cell \u001b[1;32mIn[172], line 195\u001b[0m, in \u001b[0;36mtrain_diffusion_model\u001b[1;34m(model, train_loader, val_loader, num_epochs, patience_num_epochs)\u001b[0m\n",
      "\u001b[0;32m    192\u001b[0m t \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, model\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# Forward pass through the model (predict denoised expression at timestep t)\u001b[39;00m\n",
      "\u001b[1;32m--> 195\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoisy_tokens\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Predict logits (denoised tokens)\u001b[39;00m\n",
      "\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# Flatten the logits and target tokens for loss computation\u001b[39;00m\n",
      "\u001b[0;32m    198\u001b[0m logits \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, logits\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# Flatten the logits (seq_len * batch_size, vocab_size)\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\matth\\OneDrive - University of Waterloo\\Documents\\Python Files\\Environments\\STAT940_Final_Project_VENV\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\matth\\OneDrive - University of Waterloo\\Documents\\Python Files\\Environments\\STAT940_Final_Project_VENV\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\n",
      "Cell \u001b[1;32mIn[172], line 142\u001b[0m, in \u001b[0;36mDiffusionModel.forward\u001b[1;34m(self, embeddings)\u001b[0m\n",
      "\u001b[0;32m    139\u001b[0m batch_size, seq_len, embedding_dim \u001b[38;5;241m=\u001b[39m embeddings\u001b[38;5;241m.\u001b[39msize()\n",
      "\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# Project embeddings to match d_model (hidden_dim)\u001b[39;00m\n",
      "\u001b[1;32m--> 142\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_projection\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Shape: [batch_size, seq_len, hidden_dim]\u001b[39;00m\n",
      "\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# Rearrange embeddings to shape [seq_len, batch_size, hidden_dim] for the transformer\u001b[39;00m\n",
      "\u001b[0;32m    145\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m embeddings\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# [seq_len, batch_size, hidden_dim]\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\matth\\OneDrive - University of Waterloo\\Documents\\Python Files\\Environments\\STAT940_Final_Project_VENV\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\matth\\OneDrive - University of Waterloo\\Documents\\Python Files\\Environments\\STAT940_Final_Project_VENV\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\matth\\OneDrive - University of Waterloo\\Documents\\Python Files\\Environments\\STAT940_Final_Project_VENV\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n",
      "\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n",
      "\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (320x100 and 128x256)"
     ]
    }
   ],
   "source": [
    "# Initialize model, optimizer, and loss function\n",
    "model = DiffusionModel(vocab_size=len(vocab), embedding_dim=128, hidden_dim=256, num_layers=4, num_timesteps=1000)\n",
    "\n",
    "# Train the model\n",
    "model,performance_metrics_DICT = train_diffusion_model(model,train_loader,val_loader,num_epochs=10,patience_num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings Performance Metrics:\n",
      "{'epoch_list': [1], 'train_loss_list': [0.0]}\n"
     ]
    }
   ],
   "source": [
    "performance_metrics_DICT = load_JSON('Data/embeddings_performance_metrics_DICT.json')\n",
    "\n",
    "model = Word2Vec.load(\"Data/embeddings_model.model\")\n",
    "\n",
    "print(\"Embeddings Performance Metrics:\")\n",
    "print(performance_metrics_DICT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "STAT940_Final_Project_VENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
