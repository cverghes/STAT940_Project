{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a function to tokenize a formula\n",
    "def tokenize_formula(formula):\n",
    "    token_pattern = r\"[a-zA-Z_][a-zA-Z0-9_]*|[()+\\-*/]|\\d+\\.?\\d*\"\n",
    "    tokens = re.findall(token_pattern, formula)\n",
    "    return tokens\n",
    "\n",
    "@dataclass\n",
    "class tNetConfig:\n",
    "    num_vars: int\n",
    "    embedding_size: int\n",
    "\n",
    "class tNet(nn.Module):\n",
    "    def __init__(self, config: tNetConfig):\n",
    "        super(tNet, self).__init__()\n",
    "\n",
    "        self.config = config\n",
    "        self.num_vars = config.num_vars\n",
    "        self.n_embd = config.embedding_size\n",
    "\n",
    "        self.activation_func = F.relu\n",
    "\n",
    "        self.conv1 = nn.Conv1d(self.num_vars + 1, self.n_embd, 1)\n",
    "        self.conv2 = nn.Conv1d(self.n_embd, 2 * self.n_embd, 1)\n",
    "        self.conv3 = nn.Conv1d(2 * self.n_embd, 4 * self.n_embd, 1)\n",
    "\n",
    "        self.fc1 = nn.Linear(4 * self.n_embd, 2 * self.n_embd)\n",
    "        self.fc2 = nn.Linear(2 * self.n_embd, self.n_embd)\n",
    "\n",
    "        self.input_batch_norm = nn.GroupNorm(1, self.num_vars + 1)\n",
    "\n",
    "        self.bn1 = nn.GroupNorm(1, self.n_embd)\n",
    "        self.bn2 = nn.GroupNorm(1, 2 * self.n_embd)\n",
    "        self.bn3 = nn.GroupNorm(1, 4 * self.n_embd)\n",
    "        self.bn4 = nn.GroupNorm(1, 2 * self.n_embd)\n",
    "        self.bn5 = nn.GroupNorm(1, self.n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: [batch, #features + 1, #points]\n",
    "        :return: logit: [batch, embedding_size]\n",
    "        \"\"\"\n",
    "        x = self.input_batch_norm(x)\n",
    "        x = self.activation_func(self.bn1(self.conv1(x)))\n",
    "        x = self.activation_func(self.bn2(self.conv2(x)))\n",
    "        x = self.activation_func(self.bn3(self.conv3(x)))\n",
    "        x, _ = torch.max(x, dim=2)  # global max pooling\n",
    "        assert x.size(1) == 4 * self.n_embd\n",
    "\n",
    "        x = self.activation_func(self.bn4(self.fc1(x)))\n",
    "        x = self.activation_func(self.bn5(self.fc2(x)))\n",
    "\n",
    "        return x\n",
    "\n",
    "class TextDiffusionModel:\n",
    "    def __init__(self, vocab_size, seq_len, device=\"cpu\"):\n",
    "        \"\"\"\n",
    "        Initialize the text diffusion model.\n",
    "\n",
    "        Parameters:\n",
    "        - vocab_size: Size of the vocabulary (number of unique tokens).\n",
    "        - seq_len: Length of the token sequence.\n",
    "        - device: Device to use (\"cpu\" or \"cuda\").\n",
    "        \"\"\"\n",
    "        self.vocab_size = vocab_size\n",
    "        self.seq_len = seq_len\n",
    "        self.device = device\n",
    "        # self.noise_schedule = torch.linspace(0.01, 0.1, steps=1000).to(device)  # Noise variance per timestep\n",
    "        self.noise_schedule = torch.linspace(1e-4, 2e-2, steps=1000).to(device)  # Noise variance per timestep\n",
    "\n",
    "    def add_noise(self, tokens, t):\n",
    "        \"\"\"\n",
    "        Add noise to a sequence of tokens based on timestep t.\n",
    "\n",
    "        Parameters:\n",
    "        - tokens: A tensor of token indices with shape (batch_size, seq_len).\n",
    "        - t: A tensor of timesteps with shape (batch_size,).\n",
    "\n",
    "        Returns:\n",
    "        - noisy_tokens: The tokens with added noise.\n",
    "        - noise: The noise added to the tokens.\n",
    "        \"\"\"\n",
    "        noise_std = self.noise_schedule[t].view(-1, 1, 1)  # Shape: (batch_size, 1, 1)\n",
    "\n",
    "        # Convert tokens to one-hot vectors\n",
    "        one_hot = F.one_hot(tokens.long(), num_classes=self.vocab_size).float()\n",
    "        \n",
    "        # Add Gaussian noise to the one-hot vectors\n",
    "        noise = torch.randn_like(one_hot) * noise_std\n",
    "        noisy_one_hot = one_hot + noise\n",
    "\n",
    "        # Compute softmax to normalize the noisy one-hot vectors\n",
    "        noisy_tokens = F.softmax(noisy_one_hot, dim=-1)\n",
    "        return noisy_tokens, noise\n",
    "\n",
    "    def sample_from_noisy_tokens(self, noisy_tokens):\n",
    "        \"\"\"\n",
    "        Sample discrete tokens from the noisy token distribution.\n",
    "\n",
    "        Parameters:\n",
    "        - noisy_tokens: A tensor of noisy token distributions with shape (batch_size, seq_len, vocab_size).\n",
    "\n",
    "        Returns:\n",
    "        - sampled_tokens: A tensor of sampled token indices with shape (batch_size, seq_len).\n",
    "        \"\"\"\n",
    "        sampled_tokens = torch.argmax(noisy_tokens, dim=-1)\n",
    "        return sampled_tokens\n",
    "\n",
    "class ReverseProcessModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, num_vars, seq_len):\n",
    "        super(ReverseProcessModel, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.num_vars = num_vars\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "        # Calculate the correct input size for fc1\n",
    "        input_size = embedding_size + (seq_len * vocab_size) + 1  # embeddings + noisy_tokens + timestep\n",
    "\n",
    "        # Define layers for the reverse process model\n",
    "        self.fc1 = nn.Linear(input_size, 512)  # Adjusted input size\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, seq_len * vocab_size)  # Output for all tokens in the sequence\n",
    "\n",
    "    def forward(self, noisy_tokens, embeddings, t):\n",
    "        \"\"\"\n",
    "        Forward pass for the reverse process model.\n",
    "\n",
    "        :param noisy_tokens: Tensor of noisy tokens with shape [batch_size, seq_len, vocab_size].\n",
    "        :param embeddings: Tensor of embeddings with shape [batch_size, embedding_size].\n",
    "        :param t: Tensor of timesteps with shape [batch_size].\n",
    "        :return: Predicted noise.\n",
    "        \"\"\"\n",
    "        # Flatten noisy tokens to [batch_size, seq_len * vocab_size]\n",
    "        noisy_tokens_flat = noisy_tokens.view(noisy_tokens.size(0), -1)\n",
    "\n",
    "        # Concatenate embeddings, flattened noisy tokens, and timestep information\n",
    "        timestep_embedding = torch.cat([embeddings, noisy_tokens_flat, t.unsqueeze(1).float()], dim=-1)\n",
    "        \n",
    "        # Pass through the fully connected layers\n",
    "        x = F.relu(self.fc1(timestep_embedding))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        predicted_noise = self.fc3(x)\n",
    "\n",
    "        # Reshape to [batch_size, seq_len, vocab_size]\n",
    "        predicted_noise = predicted_noise.view(-1, self.seq_len, self.vocab_size)\n",
    "        \n",
    "        return predicted_noise\n",
    "\n",
    "# Main function\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Define the device \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    folder_path = \"data_symbolic_regression/train\"\n",
    "    val_folder_path = \"data_symbolic_regression/val\"\n",
    "\n",
    "    # Load and tokenize formulas from the training set; Convert the data points to a Pytorch tensor\n",
    "    tokenized_formulas = []\n",
    "    points_list = []\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".json\") and not file_name.startswith('properties'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            with open(file_path, \"r\") as file:\n",
    "                data = json.load(file)\n",
    "\n",
    "                formula_human_readable = data.get(\"formula_human_readable\", \"\")\n",
    "                if formula_human_readable:\n",
    "                    tokens = tokenize_formula(formula_human_readable)\n",
    "                    tokenized_formulas.append(tokens)\n",
    "                \n",
    "                points = data.get(\"points\")\n",
    "                if points:\n",
    "                    points_array = np.array([points[\"var_0\"], points[\"var_1\"], points[\"var_2\"], points[\"target\"]])\n",
    "                    points_tensor = torch.tensor(points_array, dtype=torch.float32, device=device).unsqueeze(0)  # Add batch dimension\n",
    "                    points_list.append(points_tensor)\n",
    "                    # Need below line if points_array is transposed\n",
    "                    # points_tensor = torch.tensor(points_array, dtype=torch.float32, device=device).unsqueeze(0).permute(0, 2, 1)  # Add batch dimension and transpose\n",
    "\n",
    "    val_tokenized_formulas = []\n",
    "    val_points_list = []\n",
    "\n",
    "    # Create the vocabulary from the tokens\n",
    "    for file_name in os.listdir(val_folder_path):\n",
    "        if file_name.endswith(\".json\") and not file_name.startswith('properties'):\n",
    "            file_path = os.path.join(val_folder_path, file_name)\n",
    "            with open(file_path, \"r\") as file:\n",
    "                val_data = json.load(file)\n",
    "\n",
    "                val_formula_human_readable = val_data.get(\"formula_human_readable\", \"\")\n",
    "                if val_formula_human_readable:\n",
    "                    val_tokens = tokenize_formula(val_formula_human_readable)\n",
    "                    val_tokenized_formulas.append(val_tokens)\n",
    "                \n",
    "                val_points = val_data.get(\"points\")\n",
    "                if val_points:\n",
    "                    val_points_array = np.array([val_points[\"var_0\"], val_points[\"var_1\"], val_points[\"var_2\"], val_points[\"target\"]])\n",
    "                    val_points_tensor = torch.tensor(val_points_array, dtype=torch.float32, device=device).unsqueeze(0)  # Add batch dimension\n",
    "                    val_points_list.append(val_points_tensor)\n",
    "\n",
    "    vocab_mapping = {token: idx for idx, token in enumerate(set(t for tokens in tokenized_formulas for t in tokens))}\n",
    "    vocab_size = len(vocab_mapping)\n",
    "\n",
    "    # Define EOS and PAD token IDs\n",
    "    eos_token_id = vocab_size - 1  # Assuming the last ID in the vocabulary is for EOS\n",
    "    pad_token_id = vocab_size - 2  # Assuming the second-to-last ID in the vocabulary is for PAD\n",
    "\n",
    "    # Add EOS and PAD tokens to vocab_mapping if not already present\n",
    "    if eos_token_id not in vocab_mapping.values():\n",
    "        vocab_mapping['<EOS>'] = eos_token_id\n",
    "    if pad_token_id not in vocab_mapping.values():\n",
    "        vocab_mapping['<PAD>'] = pad_token_id\n",
    "\n",
    "    # Tokenize and map tokens to vocabulary indices\n",
    "    token_sequences = [[vocab_mapping.get(token, pad_token_id) for token in tokens] for tokens in tokenized_formulas]\n",
    "\n",
    "    # Calculate sequence length based on the 95th percentile of formula lengths\n",
    "    formula_lengths = [len(tokens) for tokens in tokenized_formulas]\n",
    "    seq_len = int(np.percentile(formula_lengths, 95))  # Use 95th percentile\n",
    "    batch_size = 100  # Example batch size\n",
    "\n",
    "    # Pad or truncate sequences to seq_len, adding EOS token last\n",
    "    token_sequences = [\n",
    "        seq[:seq_len] + [pad_token_id] * max(0, seq_len - len(seq)) + [eos_token_id] \n",
    "        if len(seq) < seq_len else seq[:seq_len] + [eos_token_id]  # Add EOS token at the end after padding\n",
    "        for seq in token_sequences\n",
    "    ]\n",
    "\n",
    "    # Convert to tensor\n",
    "    token_tensor = torch.tensor(token_sequences, device=device)\n",
    "\n",
    "    # Initialize the model\n",
    "    diffusion_model = TextDiffusionModel(vocab_size, seq_len, device=device)\n",
    "    \n",
    "    # Pad or truncate sequences to seq_len\n",
    "    token_sequences = [seq[:seq_len] + [0] * max(0, seq_len - len(seq)) for seq in token_sequences]\n",
    "    token_tensor = torch.tensor(token_sequences, device=device)\n",
    "\n",
    "    val_vocab_mapping = {token: idx for idx, token in enumerate(set(t for tokens in val_tokenized_formulas for t in tokens))}\n",
    "    val_vocab_size = len(val_vocab_mapping)\n",
    "\n",
    "    # Add EOS and PAD tokens to vocab_mapping if not already present\n",
    "    if eos_token_id not in val_vocab_mapping.values():\n",
    "        val_vocab_mapping['<EOS>'] = eos_token_id\n",
    "    if pad_token_id not in val_vocab_mapping.values():\n",
    "        val_vocab_mapping['<PAD>'] = pad_token_id\n",
    "\n",
    "    # Tokenize and map tokens to vocabulary indices\n",
    "    val_token_sequences = [[val_vocab_mapping.get(token, pad_token_id) for token in tokens] for tokens in val_tokenized_formulas]\n",
    "\n",
    "    # Calculate sequence length based on the 95th percentile of formula lengths\n",
    "    val_formula_lengths = [len(tokens) for tokens in val_tokenized_formulas]\n",
    "    val_seq_len = int(np.percentile(val_formula_lengths, 95))  # Use 95th percentile\n",
    "\n",
    "    # Pad or truncate sequences to seq_len, adding EOS token last\n",
    "    val_token_sequences = [\n",
    "        seq[:seq_len] + [pad_token_id] * max(0, seq_len - len(seq)) + [eos_token_id] \n",
    "        if len(seq) < seq_len else seq[:seq_len] + [eos_token_id]  # Add EOS token at the end after padding\n",
    "        for seq in val_token_sequences\n",
    "    ]\n",
    "\n",
    "    # Convert to tensor\n",
    "    val_token_tensor = torch.tensor(val_token_sequences, device=device)\n",
    "\n",
    "    # Initialize the model\n",
    "    diffusion_model = TextDiffusionModel(vocab_size, seq_len, device=device)\n",
    "    \n",
    "    # Pad or truncate sequences to seq_len\n",
    "    val_token_sequences = [seq[:seq_len] + [0] * max(0, seq_len - len(seq)) for seq in val_token_sequences]\n",
    "    val_token_tensor = torch.tensor(val_token_sequences, device=device)\n",
    "\n",
    "    t = torch.randint(0, 1000, (len(token_tensor),), device=device)\n",
    "\n",
    "    # Add noise to the tokens\n",
    "    noisy_tokens, noise = diffusion_model.add_noise(token_tensor, t)\n",
    "\n",
    "    # Sample from noisy tokens\n",
    "    sampled_tokens = diffusion_model.sample_from_noisy_tokens(noisy_tokens)\n",
    "\n",
    "    # Configuration for tNet\n",
    "    num_vars = 3\n",
    "    embedding_size = 128  # Example embedding size\n",
    "    config = tNetConfig(num_vars=num_vars, embedding_size=embedding_size)\n",
    "\n",
    "    # Instantiate the model\n",
    "    tnet_model = tNet(config)\n",
    "\n",
    "    # Input: batch_size x (num_vars + 1) x num_points\n",
    "    batch_size = 1\n",
    "\n",
    "    # Generate embeddings\n",
    "    # input_tensor = torch.rand(batch_size, num_vars, 100)\n",
    "\n",
    "    output_embeddings = []\n",
    "    for pt in points_list:\n",
    "        output_embedding = tnet_model(pt)\n",
    "        output_embeddings.append(output_embedding)\n",
    "    \n",
    "    points_tensors = torch.cat(points_list, dim=0)\n",
    "    \n",
    "    output_embeddings_tensor = torch.cat(output_embeddings, dim=0)\n",
    "    # Print the output\n",
    "    print(\"Input shape:\", points_tensors.shape)\n",
    "    print(\"Output shape:\", output_embeddings_tensor.shape)\n",
    "\n",
    "    # Print results\n",
    "    print(\"Original Tokens shape:\", token_tensor.shape)\n",
    "    print(\"Noisy Tokens (probabilities) shape:\", noisy_tokens.shape)\n",
    "    print(\"Sampled Tokens shape:\", sampled_tokens.shape)\n",
    "\n",
    "    # Initialize reverse model (denoiser)\n",
    "    reverse_model = ReverseProcessModel(vocab_size, embedding_size, num_vars, seq_len).to(device)\n",
    "\n",
    "    # Cross-entropy loss function\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Train the reverse process model\n",
    "    epochs = 1000  # Define the number of epochs for training\n",
    "    batch_size = 100  # Example batch size\n",
    "\n",
    "    # Optimizer for the reverse process model\n",
    "    optimizer = torch.optim.Adam(reverse_model.parameters(), lr=1e-4)\n",
    "\n",
    "    # Early stopping parameters\n",
    "    patience = 10\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    # Initialize lists to store training and validation losses\n",
    "    training_losses = []\n",
    "    validation_losses = []\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        reverse_model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        # Training Phase\n",
    "        for batch_idx in range(0, len(points_list), batch_size):\n",
    "            batch_points = points_list[batch_idx:batch_idx + batch_size]\n",
    "            batch_token_tensor = token_tensor[batch_idx:batch_idx + batch_size]\n",
    "\n",
    "            # Random timesteps\n",
    "            t_batch = torch.randint(0, 1000, (len(batch_points),), device=device)\n",
    "\n",
    "            # Add noise\n",
    "            noisy_tokens, _ = diffusion_model.add_noise(batch_token_tensor, t_batch)\n",
    "\n",
    "            # Get embeddings\n",
    "            batch_embeddings = [tnet_model(pt) for pt in batch_points]\n",
    "            embeddings_tensor = torch.cat(batch_embeddings, dim=0)\n",
    "\n",
    "            # Predict logits\n",
    "            logits = reverse_model(noisy_tokens, embeddings_tensor, t_batch)\n",
    "\n",
    "            # Reshape logits and target tokens for CrossEntropyLoss\n",
    "            logits_flat = logits.view(-1, vocab_size)\n",
    "            target_tokens = batch_token_tensor.view(-1)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_fn(logits_flat, target_tokens)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation Phase\n",
    "        reverse_model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for val_batch_idx in range(0, len(val_points_list), batch_size):\n",
    "                val_batch_points = val_points_list[val_batch_idx:val_batch_idx + batch_size]\n",
    "                val_batch_token_tensor = val_token_tensor[val_batch_idx:val_batch_idx + batch_size]\n",
    "\n",
    "                val_t_batch = torch.randint(0, 1000, (len(val_batch_points),), device=device)\n",
    "\n",
    "                val_noisy_tokens, _ = diffusion_model.add_noise(val_batch_token_tensor, val_t_batch)\n",
    "\n",
    "                val_embeddings = [tnet_model(pt) for pt in val_batch_points]\n",
    "                val_embeddings_tensor = torch.cat(val_embeddings, dim=0)\n",
    "\n",
    "                val_logits = reverse_model(val_noisy_tokens, val_embeddings_tensor, val_t_batch)\n",
    "                val_logits_flat = val_logits.view(-1, vocab_size)\n",
    "                val_target_tokens = val_batch_token_tensor.view(-1)\n",
    "\n",
    "                val_loss += loss_fn(val_logits_flat, val_target_tokens).item()\n",
    "\n",
    "        val_loss /= len(val_points_list)\n",
    "\n",
    "        # Store losses for plotting\n",
    "        training_losses.append(total_loss / len(points_list))\n",
    "        validation_losses.append(val_loss)\n",
    "\n",
    "        # Print progress\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {training_losses[-1]:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Early stopping logic\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(reverse_model.state_dict(), 'best_model.pth')  # Save the best model\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stopping triggered. Restoring best model...\")\n",
    "            reverse_model.load_state_dict(torch.load('best_model.pth'))\n",
    "            break\n",
    "\n",
    "    # Plot training and validation losses\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(training_losses) + 1), training_losses, label='Training Loss', color='blue')\n",
    "    plt.plot(range(1, len(validation_losses) + 1), validation_losses, label='Validation Loss', color='orange')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss Curves')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Tokens: [24, 15, 5, 0, 24, 24, 17, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24]\n",
      "Test Tokens without Padding: [15, 5, 0, 17, 23]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Define a function to tokenize a formula, including <EOS> and <PAD> tokens\n",
    "def tokenize_formula(formula, vocab_mapping, seq_len, eos_token_id, pad_token_id):\n",
    "    \"\"\"\n",
    "    Tokenizes a mathematical formula into tokens, mapping them to vocabulary indices.\n",
    "\n",
    "    Parameters:\n",
    "    - formula: A string representing the mathematical formula.\n",
    "    - vocab_mapping: A dictionary mapping tokens to vocabulary indices.\n",
    "    - seq_len: Desired sequence length for padding/truncation.\n",
    "    - eos_token_id: Vocabulary index for the <EOS> token.\n",
    "    - pad_token_id: Vocabulary index for the <PAD> token.\n",
    "\n",
    "    Returns:\n",
    "    - A list of token indices with length seq_len.\n",
    "    \"\"\"\n",
    "    token_pattern = r\"[a-zA-Z_][a-zA-Z0-9_]*|[()+\\-*/]|\\d+\\.?\\d*\"\n",
    "    tokens = re.findall(token_pattern, formula)\n",
    "\n",
    "    # Map tokens to vocabulary indices and truncate if necessary\n",
    "    token_indices = [vocab_mapping.get(token, pad_token_id) for token in tokens[:seq_len - 1]]\n",
    "\n",
    "    # Add <EOS> token and pad to seq_len\n",
    "    token_indices.append(eos_token_id)\n",
    "    if len(token_indices) < seq_len:\n",
    "        token_indices.extend([pad_token_id] * (seq_len - len(token_indices)))\n",
    "\n",
    "    return token_indices\n",
    "\n",
    "@dataclass\n",
    "class tNetConfig:\n",
    "    num_vars: int\n",
    "    embedding_size: int\n",
    "\n",
    "# Define the main function\n",
    "if __name__ == \"__main__\":\n",
    "    # Define device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Define paths\n",
    "    folder_path = \"data_symbolic_regression/train\"\n",
    "    val_folder_path = \"data_symbolic_regression/val\"\n",
    "\n",
    "    # Load formulas and points\n",
    "    tokenized_formulas = []\n",
    "    points_list = []\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".json\") and not file_name.startswith('properties'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            with open(file_path, \"r\") as file:\n",
    "                data = json.load(file)\n",
    "\n",
    "                formula_human_readable = data.get(\"formula_human_readable\", \"\")\n",
    "                points = data.get(\"points\")\n",
    "                \n",
    "                if formula_human_readable:\n",
    "                    tokenized_formulas.append(formula_human_readable)\n",
    "                \n",
    "                if points:\n",
    "                    points_array = np.array([\n",
    "                        points[\"var_0\"],\n",
    "                        points[\"var_1\"],\n",
    "                        points[\"var_2\"],\n",
    "                        points[\"target\"]\n",
    "                    ])\n",
    "                    points_tensor = torch.tensor(points_array, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "                    points_list.append(points_tensor)\n",
    "\n",
    "    # Create vocabulary\n",
    "    unique_tokens = set(re.findall(r\"[a-zA-Z_][a-zA-Z0-9_]*|[()+\\-*/]|\\d+\\.?\\d*\", \" \".join(tokenized_formulas)))\n",
    "    vocab_mapping = {token: idx for idx, token in enumerate(unique_tokens)}\n",
    "    \n",
    "    # Add <EOS> and <PAD> tokens\n",
    "    eos_token_id = len(vocab_mapping)\n",
    "    pad_token_id = eos_token_id + 1\n",
    "    vocab_mapping['<EOS>'] = eos_token_id\n",
    "    vocab_mapping['<PAD>'] = pad_token_id\n",
    "    vocab_size = len(vocab_mapping)\n",
    "\n",
    "    # Tokenize and pad formulas\n",
    "    seq_len = 100  # Example sequence length\n",
    "    token_sequences = [\n",
    "        tokenize_formula(formula, vocab_mapping, seq_len, eos_token_id, pad_token_id)\n",
    "        for formula in tokenized_formulas\n",
    "    ]\n",
    "\n",
    "    # Convert to tensor\n",
    "    token_tensor = torch.tensor(token_sequences, device=device)\n",
    "\n",
    "    # Example inference: Remove <PAD> tokens during prediction\n",
    "    def remove_padding(tokens, pad_token_id):\n",
    "        \"\"\"Removes <PAD> tokens from a sequence of tokens.\"\"\"\n",
    "        return [token for token in tokens if token != pad_token_id]\n",
    "\n",
    "    # Test with a single formula\n",
    "    test_formula = \"3 * var_0 + 5 / var_1\"\n",
    "    test_tokens = tokenize_formula(test_formula, vocab_mapping, seq_len, eos_token_id, pad_token_id)\n",
    "    test_tokens_tensor = torch.tensor(test_tokens, device=device).unsqueeze(0)\n",
    "\n",
    "    print(\"Test Tokens:\", test_tokens)\n",
    "    print(\"Test Tokens without Padding:\", remove_padding(test_tokens, pad_token_id))\n",
    "\n",
    "    # Ready for training or inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stat940-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
