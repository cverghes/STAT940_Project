{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Diffusion Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.23779887557029725, Val Loss: 0.4486483931541443\n",
      "Epoch 2/100, Train Loss: 0.10243501961231231, Val Loss: 0.4412689507007599\n",
      "Epoch 3/100, Train Loss: 0.059051104635000226, Val Loss: 0.43448907136917114\n",
      "Epoch 4/100, Train Loss: 0.03806477934122086, Val Loss: 0.42765307426452637\n",
      "Epoch 5/100, Train Loss: 0.028167488798499108, Val Loss: 0.42596903443336487\n",
      "Epoch 6/100, Train Loss: 0.023289132118225097, Val Loss: 0.4268840551376343\n",
      "Epoch 7/100, Train Loss: 0.02140187583863735, Val Loss: 0.42439475655555725\n",
      "Epoch 8/100, Train Loss: 0.019652978330850602, Val Loss: 0.4292699992656708\n",
      "Epoch 9/100, Train Loss: 0.01858958601951599, Val Loss: 0.42538952827453613\n",
      "Epoch 10/100, Train Loss: 0.01812881454825401, Val Loss: 0.42740288376808167\n",
      "Epoch 11/100, Train Loss: 0.01749928668141365, Val Loss: 0.4254731237888336\n",
      "Epoch 12/100, Train Loss: 0.017029761523008346, Val Loss: 0.42796412110328674\n",
      "Epoch 13/100, Train Loss: 0.01678049601614475, Val Loss: 0.42996978759765625\n",
      "Epoch 14/100, Train Loss: 0.016441794484853743, Val Loss: 0.424726277589798\n",
      "Epoch 15/100, Train Loss: 0.01596267372369766, Val Loss: 0.4221039414405823\n",
      "Epoch 16/100, Train Loss: 0.015852971002459526, Val Loss: 0.42684200406074524\n",
      "Epoch 17/100, Train Loss: 0.015405166149139404, Val Loss: 0.4217410087585449\n",
      "Epoch 18/100, Train Loss: 0.015238349325954914, Val Loss: 0.42433297634124756\n",
      "Epoch 19/100, Train Loss: 0.014891835860908031, Val Loss: 0.4320971965789795\n",
      "Epoch 20/100, Train Loss: 0.014647636003792286, Val Loss: 0.42630451917648315\n",
      "Epoch 21/100, Train Loss: 0.014527326449751854, Val Loss: 0.42593804001808167\n",
      "Epoch 22/100, Train Loss: 0.014203350618481636, Val Loss: 0.4247186481952667\n",
      "Epoch 23/100, Train Loss: 0.013994108326733113, Val Loss: 0.425071656703949\n",
      "Epoch 24/100, Train Loss: 0.013706809654831887, Val Loss: 0.4283972680568695\n",
      "Epoch 25/100, Train Loss: 0.013522388972342014, Val Loss: 0.422078400850296\n",
      "Epoch 26/100, Train Loss: 0.013445437513291835, Val Loss: 0.4253804385662079\n",
      "Epoch 27/100, Train Loss: 0.013082524947822093, Val Loss: 0.4281878173351288\n",
      "Training stopped early at epoch 27. Best validation loss: 0.4217410087585449\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "from torch.nn import functional as F\n",
    "from dataclasses import dataclass\n",
    "import pdb\n",
    "\n",
    "# Set the random seed for replicability\n",
    "seed = 940\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "def determine_max_seq_len(data, max_length='max_length'):\n",
    "    \"\"\"Calculate the max sequence length dynamically if 'max_length' is used as an argument.\"\"\"\n",
    "    if max_length == 'max_length':\n",
    "        MAX_LENGTH = max(len(dp[\"tokens\"]) for dp in data)\n",
    "    else:\n",
    "        MAX_LENGTH = max_length\n",
    "    return MAX_LENGTH\n",
    "\n",
    "def setup_device():\n",
    "    \"\"\"Set up the device for training.\"\"\"\n",
    "    return torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def save_model(model, filepath):\n",
    "    \"\"\"Save the model's state dictionary.\"\"\"\n",
    "    torch.save(model.state_dict(), filepath)\n",
    "    return model\n",
    "\n",
    "def load_model(model, filepath):\n",
    "    \"\"\"Load a saved model state dictionary.\"\"\"\n",
    "    model.load_state_dict(torch.load(filepath))\n",
    "    model.eval()\n",
    "    device = setup_device()\n",
    "    model.to(device)\n",
    "    return model, device\n",
    "\n",
    "def load_dataset(filepath):\n",
    "    \"\"\"Load the dataset from a JSON file.\"\"\"\n",
    "    with open(filepath, 'r') as file:\n",
    "        dataset = [json.loads(line) for line in file]\n",
    "    return dataset\n",
    "\n",
    "def save_JSON(data, filename):\n",
    "    \"\"\"Save data to a JSON file.\"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "    return\n",
    "\n",
    "def load_JSON(filename):\n",
    "    \"\"\"Load a JSON file.\"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "@dataclass\n",
    "class tNetConfig:\n",
    "    num_vars: int\n",
    "    embedding_size: int\n",
    "\n",
    "class tNet(nn.Module):\n",
    "    def __init__(self, config: tNetConfig):\n",
    "        super(tNet, self).__init__()\n",
    "\n",
    "        self.config = config\n",
    "        self.num_vars = config.num_vars\n",
    "        self.n_embd = config.embedding_size\n",
    "\n",
    "        self.activation_func = F.relu\n",
    "\n",
    "        # Define the convolutional layers\n",
    "        self.conv1 = nn.Conv1d(self.num_vars, self.n_embd, 1)\n",
    "        self.conv2 = nn.Conv1d(self.n_embd, 2*self.n_embd, 1)\n",
    "        self.conv3 = nn.Conv1d(2*self.n_embd, 4*self.n_embd, 1)\n",
    "\n",
    "        # Define fully connected layers\n",
    "        self.fc1 = nn.Linear(4*self.n_embd, 2*self.n_embd)\n",
    "        self.fc2 = nn.Linear(2*self.n_embd, self.n_embd)\n",
    "\n",
    "        # Corrected GroupNorm initialization\n",
    "        self.input_batch_norm = nn.GroupNorm(1, self.num_vars)  # Corrected to match input channels\n",
    "        \n",
    "        # Define other GroupNorm layers\n",
    "        self.bn1 = nn.GroupNorm(1, self.n_embd)\n",
    "        self.bn2 = nn.GroupNorm(1, 2*self.n_embd)\n",
    "        self.bn3 = nn.GroupNorm(1, 4*self.n_embd)\n",
    "        self.bn4 = nn.GroupNorm(1, 2*self.n_embd)\n",
    "        self.bn5 = nn.GroupNorm(1, self.n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply normalization and convolutions\n",
    "        x = self.input_batch_norm(x)\n",
    "        x = self.activation_func(self.bn1(self.conv1(x)))\n",
    "        x = self.activation_func(self.bn2(self.conv2(x)))\n",
    "        x = self.activation_func(self.bn3(self.conv3(x)))\n",
    "\n",
    "        # Global max pooling\n",
    "        x, _ = torch.max(x, dim=2)  # Reducing along the sequence dimension (index 2)\n",
    "        assert x.size(1) == 4*self.n_embd  # Ensure correct output size\n",
    "\n",
    "        # Apply fully connected layers\n",
    "        x = self.activation_func(self.bn4(self.fc1(x)))\n",
    "        x = self.activation_func(self.bn5(self.fc2(x)))\n",
    "        return x\n",
    "\n",
    "class CosineNoiseSchedule:\n",
    "    def __init__(self, timesteps=1000, epsilon=1e-6, device=None):\n",
    "        self.timesteps = timesteps\n",
    "        self.epsilon = epsilon\n",
    "        self.device = device\n",
    "        \n",
    "        # Create alphas using a cosine schedule\n",
    "        self.alphas = torch.cos(torch.linspace(0, math.pi / 2, timesteps, device=device)) ** 2\n",
    "        self.betas = 1.0 - self.alphas\n",
    "        self.alpha_bar = torch.maximum(torch.cumprod(self.alphas, dim=0), torch.tensor(self.epsilon, device=self.alphas.device))\n",
    "\n",
    "    def get_alpha(self, t):\n",
    "        return self.alphas[t]\n",
    "\n",
    "    def get_beta(self, t):\n",
    "        return self.betas[t]\n",
    "\n",
    "    def get_variance(self, t):\n",
    "        return self.get_beta(t) * (1 - self.get_alpha(t))\n",
    "\n",
    "    def get_alpha_bar(self, t):\n",
    "        return self.alpha_bar[t]\n",
    "\n",
    "class SymbolicRegressionDataset(Dataset):\n",
    "    def __init__(self, data, vocab, max_seq_len, noise_schedule):\n",
    "        self.data = data\n",
    "        self.vocab = vocab  # Add vocab here\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.noise_schedule = noise_schedule\n",
    "\n",
    "    def get_input_embeddings(self, tokens):\n",
    "        embeddings = torch.stack([torch.tensor(token) for token in tokens])\n",
    "        padded_embeddings = nn.functional.pad(embeddings, (0, self.max_seq_len - embeddings.size(0)))\n",
    "        padded_embeddings = padded_embeddings.transpose(0,1)\n",
    "        return padded_embeddings\n",
    "    \n",
    "    def add_noise(self, token_embeddings, t, schedule):\n",
    "        alpha_t = schedule.get_alpha(t)\n",
    "        beta_t = schedule.get_beta(t)\n",
    "                \n",
    "        noisy_embeddings = torch.sqrt(alpha_t)*token_embeddings + torch.sqrt(beta_t)*torch.randn_like(token_embeddings)\n",
    "        return noisy_embeddings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_point = self.data[idx]\n",
    "        tokens = data_point['tokens']\n",
    "        current_data = data_point['data']\n",
    "        # Map symbols to embeddings using vocab\n",
    "        x = torch.tensor(current_data['x'], dtype=torch.float32)\n",
    "        y = torch.tensor(current_data['y'], dtype=torch.float32)\n",
    "        mask = torch.tensor(current_data['mask'], dtype=torch.float32)\n",
    "        token_embeddings = self.get_input_embeddings(tokens)\n",
    "        \n",
    "        t = random.randint(0, self.noise_schedule.timesteps - 1)\n",
    "        noisy_token_embeddings = self.add_noise(token_embeddings, t, self.noise_schedule)\n",
    "        \n",
    "        noisy_x = self.add_noise(x, t, self.noise_schedule)  # Fix: using the dataset's add_noise method\n",
    "        noisy_y = self.add_noise(y, t, self.noise_schedule)  # Fix: using the dataset's add_noise method\n",
    "        \n",
    "        skeleton = data_point['skeleton']\n",
    "        \n",
    "        return token_embeddings, noisy_token_embeddings, noisy_x, noisy_y, t, mask, skeleton\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "class DiffusionModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, num_heads, num_timesteps, max_seq_len=5000, pretrained_embeddings=None, tnet_config=None):\n",
    "        super(DiffusionModel, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.tnet = tNet(tnet_config) if tnet_config is not None else None\n",
    "\n",
    "        if pretrained_embeddings is not None:\n",
    "            pretrained_embeddings = torch.tensor(list(pretrained_embeddings.values()), dtype=torch.float32)\n",
    "            if pretrained_embeddings.size(1) != embedding_dim:\n",
    "                raise ValueError(\n",
    "                    f\"Pretrained embeddings size {pretrained_embeddings.size(1)} does not match the required embedding_dim {embedding_dim}.\"\n",
    "                )\n",
    "            self.embedding = nn.Parameter(pretrained_embeddings)\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        self.projection = nn.Linear(embedding_dim, hidden_dim) if embedding_dim != hidden_dim else nn.Identity()\n",
    "        self.layer_norm = nn.LayerNorm(hidden_dim, eps=1e-6)\n",
    "\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=hidden_dim,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_layers,\n",
    "            num_decoder_layers=num_layers,\n",
    "            batch_first=False\n",
    "        )\n",
    "        \n",
    "        self.fc_out = nn.Linear(hidden_dim, embedding_dim)\n",
    "\n",
    "    def forward(self, embeddings):\n",
    "        batch_size, hidden_dim, seq_len = embeddings.shape\n",
    "        if self.embedding_dim != self.hidden_dim:\n",
    "            embeddings = self.projection(embeddings)\n",
    "        embeddings = embeddings.transpose(1, 2)\n",
    "        embeddings = self.layer_norm(embeddings)\n",
    "        embeddings = embeddings.transpose(0, 1)\n",
    "        embeddings = self.transformer(embeddings, embeddings)\n",
    "        embeddings = embeddings.transpose(0, 1)\n",
    "        logits = self.fc_out(embeddings)\n",
    "        logits = logits.transpose(1, 2)\n",
    "        return logits\n",
    "    \n",
    "    def add_noise(self, token_embeddings, t, schedule):\n",
    "        alpha_t = schedule.get_alpha(t)\n",
    "        beta_t = schedule.get_beta(t)\n",
    "                \n",
    "        noisy_embeddings = torch.sqrt(alpha_t)*token_embeddings + torch.sqrt(beta_t)*torch.randn_like(token_embeddings)\n",
    "        return noisy_embeddings\n",
    "    \n",
    "    def reverse_diffusion(self, noisy_input, schedule):\n",
    "        x_t = noisy_input\n",
    "        device = x_t.device\n",
    "        for t in reversed(range(self.num_timesteps)):\n",
    "            predicted_noise = self.tnet(x_t) if self.tnet is not None else self.forward(x_t)\n",
    "            #predicted_noise = self.forward(x_t)\n",
    "            alpha_t = schedule.get_alpha(t)\n",
    "            beta_t = schedule.get_beta(t)\n",
    "            mean_x_prev = (x_t - beta_t * predicted_noise) / torch.sqrt(alpha_t)\n",
    "            if t > 0:\n",
    "                std_dev = torch.sqrt(beta_t)\n",
    "                noise = torch.randn_like(x_t, device=device) * std_dev\n",
    "                x_t = mean_x_prev + noise\n",
    "            else:\n",
    "                x_t = mean_x_prev\n",
    "            x_t = torch.clamp(x_t, min=-1.0, max=1.0)\n",
    "        return x_t\n",
    "\n",
    "def denoising_loss(predicted_embeddings, clean_embeddings):\n",
    "    return nn.MSELoss()(predicted_embeddings, clean_embeddings)\n",
    "\n",
    "def train_diffusion_model(model, train_loader, val_loader, num_epochs=10, patience_num_epochs=3):\n",
    "    device = setup_device()\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    #optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)\n",
    "    #scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode='min',patience=2,factor=0.5)\n",
    "    schedule = CosineNoiseSchedule(timesteps=1000, device=device)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    num_epochs_without_improvement = 0\n",
    "    early_stopping = False\n",
    "    performance_metrics = {\"epoch_list\": [], \"train_loss_list\": [], \"val_loss_list\": []}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for token_embeddings, noisy_token_embeddings, x, y, t, mask, skeleton in train_loader:\n",
    "            token_embeddings, noisy_token_embeddings, x, y, mask = token_embeddings.to(device), noisy_token_embeddings.to(device), x.to(device), y.to(device), mask.to(device)\n",
    "            mask = mask.to(device) if mask is not None else None\n",
    "            optimizer.zero_grad()\n",
    "            predicted_embeddings = model(noisy_token_embeddings)\n",
    "            loss = denoising_loss(predicted_embeddings, token_embeddings)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        train_loss = total_loss/len(train_loader)\n",
    "        performance_metrics['train_loss_list'].append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for token_embeddings, noisy_token_embeddings, x, y, t, mask, skeleton in val_loader:\n",
    "                token_embeddings, noisy_token_embeddings, x, y, mask = token_embeddings.to(device), noisy_token_embeddings.to(device), x.to(device), y.to(device), mask.to(device)\n",
    "                mask = mask.to(device) if mask is not None else None\n",
    "\n",
    "                # Forward pass\n",
    "                denoised_token_embeddings = model.reverse_diffusion(noisy_token_embeddings, schedule)\n",
    "                \n",
    "                # Compute loss\n",
    "                loss = denoising_loss(denoised_token_embeddings, token_embeddings)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        performance_metrics['val_loss_list'].append(val_loss)\n",
    "        performance_metrics['epoch_list'].append(epoch + 1)\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss}, Val Loss: {val_loss}')\n",
    "\n",
    "        #scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            save_model(model, \"Data/best_diffusion_model_method1.pt\")\n",
    "            num_epochs_without_improvement = 0\n",
    "        else:\n",
    "            num_epochs_without_improvement += 1\n",
    "\n",
    "        if num_epochs_without_improvement >= patience_num_epochs:\n",
    "            print(f\"Training stopped early at epoch {epoch + 1}. Best validation loss: {best_val_loss}\")\n",
    "            early_stopping = True\n",
    "            break\n",
    "        \n",
    "    if early_stopping == False:\n",
    "        save_model(model, \"../Data/best_diffusion_model_method1.pt\")\n",
    "\n",
    "    return model, performance_metrics\n",
    "\n",
    "# Example of loading and preparing the dataset\n",
    "dataset = load_dataset('Data/preprocessed_data_with_embeddings.json')\n",
    "vocab = load_JSON(\"Data/vocab_embeddings.json\")  # Vocabulary is a dictionary of continuous embeddings\n",
    "\n",
    "MAX_LENGTH = determine_max_seq_len(dataset)  # Determine the max length dynamically\n",
    "\n",
    "schedule = CosineNoiseSchedule(timesteps=1000,device=setup_device())\n",
    "\n",
    "# First, perform the split on the raw dataset\n",
    "train_size = int(0.7*len(dataset))  # 70% for training\n",
    "val_size = int(0.15*len(dataset))  # 15% for validation\n",
    "test_size = len(dataset) - train_size - val_size  # 15% for testing\n",
    "\n",
    "# Perform random split\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_dataset_SR = SymbolicRegressionDataset(train_dataset, vocab, MAX_LENGTH, schedule)\n",
    "val_dataset_SR = SymbolicRegressionDataset(val_dataset, vocab, MAX_LENGTH, schedule)\n",
    "test_dataset_SR = SymbolicRegressionDataset(test_dataset, vocab, MAX_LENGTH, schedule)\n",
    "\n",
    "# Create DataLoader objects for each subset\n",
    "train_loader = DataLoader(train_dataset_SR, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset_SR, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset_SR, batch_size=16, shuffle=True)\n",
    "\n",
    "# Initialize the model\n",
    "num_heads = 4  # Number of attention heads, ensure this is a divisor of embedding_dim\n",
    "embedding_dim = 100  # The embedding dimension is 100 as per your problem\n",
    "hidden_dim = embedding_dim  # Hidden dimension stays the same for simplicity\n",
    "\n",
    "# Ensure embedding_dim is divisible by num_heads\n",
    "if embedding_dim % num_heads != 0:\n",
    "    raise ValueError(f\"embedding_dim ({embedding_dim}) must be divisible by num_heads ({num_heads}).\")\n",
    "\n",
    "model = DiffusionModel(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_layers=4,\n",
    "    num_heads=4,\n",
    "    num_timesteps=1000,\n",
    "    pretrained_embeddings=vocab\n",
    ")\n",
    "\n",
    "model,performance_metrics_DICT = train_diffusion_model(model,train_loader,val_loader,num_epochs=100,patience_num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Visualize the train and validation loss\n",
    "def plot_train_valid(model_name,performance_metrics_DICT):\n",
    "    plt.figure();\n",
    "    plt.plot(performance_metrics_DICT['epoch_list'], performance_metrics_DICT['train_loss_list'], label=f'Train Loss', color='blue', linestyle='--', marker='o');\n",
    "    plt.plot(performance_metrics_DICT['epoch_list'], performance_metrics_DICT['val_loss_list'], label=f'Validation Loss', color='green', linestyle='-', marker='x');\n",
    "    plt.title(f'{model_name} Training and Validation Loss');\n",
    "    plt.xlabel('Epochs');\n",
    "    plt.ylabel('Loss');\n",
    "    plt.legend();\n",
    "    plt.grid();\n",
    "    plt.xlim(0,max(performance_metrics_DICT['epoch_list'])+1);\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = 'Diffusion Model'\n",
    "\n",
    "plot_train_valid(model_name,performance_metrics_DICT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 63\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m avg_test_loss, decoded_formulas, actual_formulas\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Example of loading and preparing the dataset\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData/preprocessed_data_with_embeddings.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     64\u001b[0m vocab \u001b[38;5;241m=\u001b[39m load_JSON(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData/vocab_embeddings.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Vocabulary is a dictionary of continuous embeddings\u001b[39;00m\n\u001b[0;32m     66\u001b[0m MAX_LENGTH \u001b[38;5;241m=\u001b[39m determine_max_seq_len(dataset)  \u001b[38;5;66;03m# Determine the max length dynamically\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "def decode_embeddings_to_tokens(embeddings, vocab):\n",
    "    batch_size, embedding_dim, seq_length = embeddings.shape\n",
    "    vocab_embeddings = torch.stack([torch.tensor(embed) for embed in vocab.values()])  # Shape: [embedding_dim, num_symbols]\n",
    "\n",
    "    # Reshape vocab_embeddings to shape: [num_symbols, embedding_dim] for broadcasting    \n",
    "    # Compute the pairwise distance between each embedding in the sequence and all vocab embeddings\n",
    "    # embeddings: [batch_size, embedding_dim, seq_length]\n",
    "    # vocab_embeddings: [num_symbols, embedding_dim]\n",
    "    \n",
    "    # To compute pairwise distances, we need to reshape embeddings to [batch_size * seq_length, embedding_dim]\n",
    "    embeddings_flattened = embeddings.view(batch_size * seq_length, embedding_dim)\n",
    "    \n",
    "    # Compute pairwise distances using cdist (shape: [batch_size * seq_length, num_symbols])\n",
    "    distances = torch.cdist(embeddings_flattened, vocab_embeddings)  # Shape: [batch_size * seq_length, num_symbols]\n",
    "\n",
    "    # Reshape distances back to [batch_size, seq_length, num_symbols]\n",
    "    distances = distances.view(batch_size, seq_length, -1)\n",
    "    \n",
    "    # Find the index of the closest token for each position in the sequence\n",
    "    closest_token_indices = torch.argmin(distances, dim=-1)  # Shape: [batch_size, seq_length]\n",
    "    \n",
    "    # Convert indices to tokens\n",
    "    decoded_tokens = []\n",
    "    for batch_idx in range(batch_size):\n",
    "        tokens = [list(vocab.keys())[idx.item()] for idx in closest_token_indices[batch_idx]]\n",
    "        decoded_tokens.append(tokens)\n",
    "\n",
    "    return decoded_tokens\n",
    "\n",
    "def evaluate_diffusion_model(model, test_loader, vocab, schedule, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_test_loss = 0.0\n",
    "    decoded_formulas = []\n",
    "    actual_formulas = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for token_embeddings, noisy_token_embeddings, x, y, t, mask, skeleton_list in test_loader:\n",
    "            token_embeddings, noisy_token_embeddings, x, y, mask = token_embeddings.to(device), noisy_token_embeddings.to(device), x.to(device), y.to(device), mask.to(device)\n",
    "            # Get the predicted denoised embeddings\n",
    "            t = random.randint(0, model.num_timesteps - 1)  # Random timestep for diffusion\n",
    "            pred_embeddings = model.reverse_diffusion(noisy_token_embeddings, schedule)\n",
    "\n",
    "            # Calculate the loss (MSE between predicted and target embeddings)\n",
    "            loss = denoising_loss(pred_embeddings, noisy_token_embeddings)\n",
    "            total_test_loss += loss.item()\n",
    "\n",
    "            # Now, we need to decode the denoised embeddings back to tokens\n",
    "            decoded_tokens_list = decode_embeddings_to_tokens(pred_embeddings, vocab)\n",
    "\n",
    "            # Convert the decoded tokens to a formula string\n",
    "            predicted_formula = [\"\".join(decoded_tokens).replace('<PAD>', '').replace('+', ' + ') for decoded_tokens in decoded_tokens_list]\n",
    "            decoded_formulas.append(predicted_formula)\n",
    "\n",
    "            # Assuming target embeddings have a corresponding ground truth formula (you can adjust this part)\n",
    "            actual_formula = list(skeleton_list)\n",
    "            actual_formulas.append(actual_formula)\n",
    "\n",
    "    # Calculate average test loss\n",
    "    avg_test_loss = total_test_loss/len(test_loader)\n",
    "    return avg_test_loss, decoded_formulas, actual_formulas\n",
    "\n",
    "# Example of loading and preparing the dataset\n",
    "dataset = load_dataset('Data/preprocessed_data_with_embeddings.json')\n",
    "vocab = load_JSON(\"Data/vocab_embeddings.json\")  # Vocabulary is a dictionary of continuous embeddings\n",
    "\n",
    "MAX_LENGTH = determine_max_seq_len(dataset)  # Determine the max length dynamically\n",
    "\n",
    "schedule = CosineNoiseSchedule(timesteps=1000,device=setup_device())\n",
    "\n",
    "# First, perform the split on the raw dataset\n",
    "train_size = int(0.7*len(dataset))  # 70% for training\n",
    "val_size = int(0.15*len(dataset))  # 15% for validation\n",
    "test_size = len(dataset) - train_size - val_size  # 15% for testing\n",
    "\n",
    "# Perform random split\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_dataset_SR = SymbolicRegressionDataset(train_dataset, vocab, MAX_LENGTH, schedule)\n",
    "val_dataset_SR = SymbolicRegressionDataset(val_dataset, vocab, MAX_LENGTH, schedule)\n",
    "test_dataset_SR = SymbolicRegressionDataset(test_dataset, vocab, MAX_LENGTH, schedule)\n",
    "\n",
    "# Create DataLoader objects for each subset\n",
    "train_loader = DataLoader(train_dataset_SR, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset_SR, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset_SR, batch_size=16, shuffle=True)\n",
    "\n",
    "# Initialize the model\n",
    "num_heads = 4  # Number of attention heads, ensure this is a divisor of embedding_dim\n",
    "embedding_dim = 100  # The embedding dimension is 100 as per your problem\n",
    "hidden_dim = embedding_dim  # Hidden dimension stays the same for simplicity\n",
    "\n",
    "# Ensure embedding_dim is divisible by num_heads\n",
    "if embedding_dim % num_heads != 0:\n",
    "    raise ValueError(f\"embedding_dim ({embedding_dim}) must be divisible by num_heads ({num_heads}).\")\n",
    "\n",
    "model = DiffusionModel(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_layers=4,\n",
    "    num_heads=4,\n",
    "    num_timesteps=1000,\n",
    "    pretrained_embeddings=vocab\n",
    ")\n",
    "\n",
    "# Example: Evaluate the model on the test set\n",
    "model, device = load_model(model, \"Data/best_diffusion_model_method1.pt\")\n",
    "test_loss, decoded_formulas, actual_formulas = evaluate_diffusion_model(model, test_loader, vocab, schedule, device)\n",
    "\n",
    "# Print out the average test loss\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "# Print out the first few decoded formulas and their corresponding actual formulas\n",
    "for predicted, actual in zip(decoded_formulas[:5], actual_formulas[:5]):\n",
    "    print(f\"Predicted Formula: {predicted}\")\n",
    "    print(f\"Actual Formula: {actual}\")\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternate Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.7206235289573669, Val Loss: 0.6199209690093994\n",
      "Epoch 2/100, Train Loss: 0.46560250520706176, Val Loss: 0.6199209690093994\n",
      "Epoch 3/100, Train Loss: 0.3378569185733795, Val Loss: 0.6199209690093994\n",
      "Epoch 4/100, Train Loss: 0.2589802235364914, Val Loss: 0.6199209690093994\n",
      "Epoch 5/100, Train Loss: 0.214978489279747, Val Loss: 0.6199209690093994\n",
      "Epoch 6/100, Train Loss: 0.1942541182041168, Val Loss: 0.6199209690093994\n",
      "Epoch 7/100, Train Loss: 0.17953898012638092, Val Loss: 0.6199209690093994\n",
      "Epoch 8/100, Train Loss: 0.17081521451473236, Val Loss: 0.6199209690093994\n",
      "Epoch 9/100, Train Loss: 0.16131505072116853, Val Loss: 0.6199209690093994\n",
      "Epoch 10/100, Train Loss: 0.1597515672445297, Val Loss: 0.6199209690093994\n",
      "Epoch 11/100, Train Loss: 0.14926388263702392, Val Loss: 0.6199209690093994\n",
      "Epoch 12/100, Train Loss: 0.1479350209236145, Val Loss: 0.6199209690093994\n",
      "Epoch 13/100, Train Loss: 0.14628997445106506, Val Loss: 0.6199209690093994\n",
      "Epoch 14/100, Train Loss: 0.1413947492837906, Val Loss: 0.6199209690093994\n",
      "Epoch 15/100, Train Loss: 0.14508646130561828, Val Loss: 0.6199209690093994\n",
      "Epoch 16/100, Train Loss: 0.14382776618003845, Val Loss: 0.6199209690093994\n",
      "Epoch 17/100, Train Loss: 0.14063076972961425, Val Loss: 0.6199209690093994\n",
      "Epoch 18/100, Train Loss: 0.14094341099262236, Val Loss: 0.6199209690093994\n",
      "Epoch 19/100, Train Loss: 0.1401250571012497, Val Loss: 0.6199209690093994\n",
      "Epoch 20/100, Train Loss: 0.13966304957866668, Val Loss: 0.6199209690093994\n",
      "Epoch 21/100, Train Loss: 0.1380559027194977, Val Loss: 0.6199209690093994\n",
      "Epoch 22/100, Train Loss: 0.13773658275604247, Val Loss: 0.6199209690093994\n",
      "Epoch 23/100, Train Loss: 0.13765364289283752, Val Loss: 0.6199209690093994\n",
      "Epoch 24/100, Train Loss: 0.13779976069927216, Val Loss: 0.6199209690093994\n",
      "Epoch 25/100, Train Loss: 0.13831033706665039, Val Loss: 0.6199209690093994\n",
      "Epoch 26/100, Train Loss: 0.13659653663635254, Val Loss: 0.6199209690093994\n",
      "Epoch 27/100, Train Loss: 0.1340498834848404, Val Loss: 0.6199209690093994\n",
      "Epoch 28/100, Train Loss: 0.13933752179145814, Val Loss: 0.6199209690093994\n",
      "Epoch 29/100, Train Loss: 0.13627262711524962, Val Loss: 0.6199209690093994\n",
      "Epoch 30/100, Train Loss: 0.14032966792583465, Val Loss: 0.6199209690093994\n",
      "Epoch 31/100, Train Loss: 0.13724209368228912, Val Loss: 0.6199209690093994\n",
      "Epoch 32/100, Train Loss: 0.13973080813884736, Val Loss: 0.6199209690093994\n",
      "Epoch 33/100, Train Loss: 0.1352227210998535, Val Loss: 0.6199209690093994\n",
      "Epoch 34/100, Train Loss: 0.13777195513248444, Val Loss: 0.6199209690093994\n",
      "Epoch 35/100, Train Loss: 0.13965288698673248, Val Loss: 0.6199209690093994\n",
      "Epoch 36/100, Train Loss: 0.13929089903831482, Val Loss: 0.6199209690093994\n",
      "Epoch 37/100, Train Loss: 0.13589569330215454, Val Loss: 0.6199209690093994\n",
      "Epoch 38/100, Train Loss: 0.13641760051250457, Val Loss: 0.6199209690093994\n",
      "Epoch 39/100, Train Loss: 0.13944524228572847, Val Loss: 0.6199209690093994\n",
      "Epoch 40/100, Train Loss: 0.13653745949268342, Val Loss: 0.6199209690093994\n",
      "Epoch 41/100, Train Loss: 0.14010678231716156, Val Loss: 0.6199209690093994\n",
      "Epoch 42/100, Train Loss: 0.13581314384937287, Val Loss: 0.6199209690093994\n",
      "Epoch 43/100, Train Loss: 0.13770573139190673, Val Loss: 0.6199209690093994\n",
      "Epoch 44/100, Train Loss: 0.1381816416978836, Val Loss: 0.6199209690093994\n",
      "Epoch 45/100, Train Loss: 0.1372412383556366, Val Loss: 0.6199209690093994\n",
      "Epoch 46/100, Train Loss: 0.13964733779430388, Val Loss: 0.6199209690093994\n",
      "Epoch 47/100, Train Loss: 0.13706936836242675, Val Loss: 0.6199209690093994\n",
      "Epoch 48/100, Train Loss: 0.1359063059091568, Val Loss: 0.6199209690093994\n",
      "Epoch 49/100, Train Loss: 0.13578867316246032, Val Loss: 0.6199209690093994\n",
      "Epoch 50/100, Train Loss: 0.13504832088947297, Val Loss: 0.6199209690093994\n",
      "Epoch 51/100, Train Loss: 0.13913078010082244, Val Loss: 0.6199209690093994\n",
      "Epoch 52/100, Train Loss: 0.13800675868988038, Val Loss: 0.6199209690093994\n",
      "Epoch 53/100, Train Loss: 0.1394233912229538, Val Loss: 0.6199209690093994\n",
      "Epoch 54/100, Train Loss: 0.14018962383270264, Val Loss: 0.6199209690093994\n",
      "Epoch 55/100, Train Loss: 0.13520313203334808, Val Loss: 0.6199209690093994\n",
      "Epoch 56/100, Train Loss: 0.13394689559936523, Val Loss: 0.6199209690093994\n",
      "Epoch 57/100, Train Loss: 0.13681080639362336, Val Loss: 0.6199209690093994\n",
      "Epoch 58/100, Train Loss: 0.13942002058029174, Val Loss: 0.6199209690093994\n",
      "Epoch 59/100, Train Loss: 0.13812209963798522, Val Loss: 0.6199209690093994\n",
      "Epoch 60/100, Train Loss: 0.1383316546678543, Val Loss: 0.6199209690093994\n",
      "Epoch 61/100, Train Loss: 0.13680026233196257, Val Loss: 0.6199209690093994\n",
      "Epoch 62/100, Train Loss: 0.13962289988994597, Val Loss: 0.6199209690093994\n",
      "Epoch 63/100, Train Loss: 0.13326553702354432, Val Loss: 0.6199209690093994\n",
      "Epoch 64/100, Train Loss: 0.13877361118793488, Val Loss: 0.6199209690093994\n",
      "Epoch 65/100, Train Loss: 0.13959548771381378, Val Loss: 0.6199209690093994\n",
      "Epoch 66/100, Train Loss: 0.1424848437309265, Val Loss: 0.6199209690093994\n",
      "Epoch 67/100, Train Loss: 0.13769370019435884, Val Loss: 0.6199209690093994\n",
      "Epoch 68/100, Train Loss: 0.14380577206611633, Val Loss: 0.6199209690093994\n",
      "Epoch 69/100, Train Loss: 0.1353621929883957, Val Loss: 0.6199209690093994\n",
      "Epoch 70/100, Train Loss: 0.13725090324878692, Val Loss: 0.6199209690093994\n",
      "Epoch 71/100, Train Loss: 0.13729995787143706, Val Loss: 0.6199209690093994\n",
      "Epoch 72/100, Train Loss: 0.13669239580631257, Val Loss: 0.6199209690093994\n",
      "Epoch 73/100, Train Loss: 0.1365759015083313, Val Loss: 0.6199209690093994\n",
      "Epoch 74/100, Train Loss: 0.13437871336936952, Val Loss: 0.6199209094047546\n",
      "Epoch 75/100, Train Loss: 0.13812992870807647, Val Loss: 0.6199209690093994\n",
      "Epoch 76/100, Train Loss: 0.1377488672733307, Val Loss: 0.6199209690093994\n",
      "Epoch 77/100, Train Loss: 0.1378587454557419, Val Loss: 0.6199209690093994\n",
      "Epoch 78/100, Train Loss: 0.13744878768920898, Val Loss: 0.6199209690093994\n",
      "Epoch 79/100, Train Loss: 0.13984255492687225, Val Loss: 0.6199209690093994\n",
      "Epoch 80/100, Train Loss: 0.13995029926300048, Val Loss: 0.6199209690093994\n",
      "Epoch 81/100, Train Loss: 0.1376222401857376, Val Loss: 0.6199209690093994\n",
      "Epoch 82/100, Train Loss: 0.13722145259380342, Val Loss: 0.6199209690093994\n",
      "Epoch 83/100, Train Loss: 0.138803169131279, Val Loss: 0.6199209690093994\n",
      "Epoch 84/100, Train Loss: 0.1342374086380005, Val Loss: 0.6199209690093994\n",
      "Epoch 85/100, Train Loss: 0.13654062449932097, Val Loss: 0.6199209094047546\n",
      "Epoch 86/100, Train Loss: 0.1401545822620392, Val Loss: 0.6199209690093994\n",
      "Epoch 87/100, Train Loss: 0.1401611626148224, Val Loss: 0.6199209690093994\n",
      "Epoch 88/100, Train Loss: 0.13846067488193511, Val Loss: 0.6199209690093994\n",
      "Epoch 89/100, Train Loss: 0.1396716445684433, Val Loss: 0.6199209690093994\n",
      "Epoch 90/100, Train Loss: 0.13871659934520722, Val Loss: 0.6199209690093994\n",
      "Epoch 91/100, Train Loss: 0.13867261111736298, Val Loss: 0.6199209690093994\n",
      "Epoch 92/100, Train Loss: 0.13873914182186126, Val Loss: 0.6199209690093994\n",
      "Epoch 93/100, Train Loss: 0.1380009800195694, Val Loss: 0.6199209690093994\n",
      "Epoch 94/100, Train Loss: 0.13616972267627717, Val Loss: 0.6199209690093994\n",
      "Epoch 95/100, Train Loss: 0.13817777037620543, Val Loss: 0.6199209690093994\n",
      "Epoch 96/100, Train Loss: 0.1350281298160553, Val Loss: 0.6199209690093994\n",
      "Epoch 97/100, Train Loss: 0.1390557110309601, Val Loss: 0.6199209690093994\n",
      "Epoch 98/100, Train Loss: 0.13901992440223693, Val Loss: 0.6199209690093994\n",
      "Epoch 99/100, Train Loss: 0.13614541590213775, Val Loss: 0.6199209690093994\n",
      "Epoch 100/100, Train Loss: 0.1386029303073883, Val Loss: 0.6199209690093994\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "from torch.nn import functional as F\n",
    "from dataclasses import dataclass\n",
    "import pdb\n",
    "\n",
    "# Set the random seed for replicability\n",
    "seed = 940\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "def determine_max_seq_len(data, max_length='max_length'):\n",
    "    \"\"\"Calculate the max sequence length dynamically if 'max_length' is used as an argument.\"\"\"\n",
    "    if max_length == 'max_length':\n",
    "        MAX_LENGTH = max(len(dp[\"tokens\"]) for dp in data)\n",
    "    else:\n",
    "        MAX_LENGTH = max_length\n",
    "    return MAX_LENGTH\n",
    "\n",
    "def setup_device():\n",
    "    \"\"\"Set up the device for training.\"\"\"\n",
    "    return torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def save_model(model, filepath):\n",
    "    \"\"\"Save the model's state dictionary.\"\"\"\n",
    "    torch.save(model.state_dict(), filepath)\n",
    "    return model\n",
    "\n",
    "def load_model(model, filepath):\n",
    "    \"\"\"Load a saved model state dictionary.\"\"\"\n",
    "    model.load_state_dict(torch.load(filepath))\n",
    "    model.eval()\n",
    "    device = setup_device()\n",
    "    model.to(device)\n",
    "    return model, device\n",
    "\n",
    "def load_dataset(filepath):\n",
    "    \"\"\"Load the dataset from a JSON file.\"\"\"\n",
    "    with open(filepath, 'r') as file:\n",
    "        dataset = [json.loads(line) for line in file]\n",
    "    return dataset\n",
    "\n",
    "def load_dataset_torch(filepath):\n",
    "    loaded_data = torch.load(filepath)\n",
    "    formula_embeddings = loaded_data['formula_embeddings']\n",
    "    dataset_embeddings = loaded_data['dataset_embeddings']\n",
    "    return formula_embeddings,dataset_embeddings\n",
    "\n",
    "def save_JSON(data, filename):\n",
    "    \"\"\"Save data to a JSON file.\"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "    return\n",
    "\n",
    "def load_JSON(filename):\n",
    "    \"\"\"Load a JSON file.\"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "@dataclass\n",
    "class tNetConfig:\n",
    "    num_vars: int\n",
    "    embedding_size: int\n",
    "\n",
    "class tNet(nn.Module):\n",
    "    def __init__(self, config: tNetConfig):\n",
    "        super(tNet, self).__init__()\n",
    "\n",
    "        self.config = config\n",
    "        self.num_vars = config.num_vars\n",
    "        self.n_embd = config.embedding_size\n",
    "\n",
    "        self.activation_func = F.relu\n",
    "\n",
    "        # Define the convolutional layers\n",
    "        self.conv1 = nn.Conv1d(self.num_vars, self.n_embd, 1)\n",
    "        self.conv2 = nn.Conv1d(self.n_embd, 2*self.n_embd, 1)\n",
    "        self.conv3 = nn.Conv1d(2*self.n_embd, 4*self.n_embd, 1)\n",
    "\n",
    "        # Define fully connected layers\n",
    "        self.fc1 = nn.Linear(4*self.n_embd, 2*self.n_embd)\n",
    "        self.fc2 = nn.Linear(2*self.n_embd, self.n_embd)\n",
    "\n",
    "        # Corrected GroupNorm initialization\n",
    "        self.input_batch_norm = nn.GroupNorm(1, self.num_vars)  # Corrected to match input channels\n",
    "        \n",
    "        # Define other GroupNorm layers\n",
    "        self.bn1 = nn.GroupNorm(1, self.n_embd)\n",
    "        self.bn2 = nn.GroupNorm(1, 2*self.n_embd)\n",
    "        self.bn3 = nn.GroupNorm(1, 4*self.n_embd)\n",
    "        self.bn4 = nn.GroupNorm(1, 2*self.n_embd)\n",
    "        self.bn5 = nn.GroupNorm(1, self.n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply normalization and convolutions\n",
    "        if len(x.shape) == 2:  # If no batch dimension\n",
    "            x = x.unsqueeze(0)  # Add batch dimension\n",
    "        \n",
    "        x = self.input_batch_norm(x)\n",
    "        x = self.activation_func(self.bn1(self.conv1(x)))\n",
    "        x = self.activation_func(self.bn2(self.conv2(x)))\n",
    "        x = self.activation_func(self.bn3(self.conv3(x)))\n",
    "\n",
    "        # Global max pooling\n",
    "        x, _ = torch.max(x, dim=2)  # Reducing along the sequence dimension (index 2)\n",
    "        assert x.size(1) == 4*self.n_embd  # Ensure correct output size\n",
    "\n",
    "        # Apply fully connected layers\n",
    "        x = self.activation_func(self.bn4(self.fc1(x)))\n",
    "        x = self.activation_func(self.bn5(self.fc2(x)))\n",
    "        return x\n",
    "\n",
    "class CosineNoiseSchedule:\n",
    "    def __init__(self, timesteps=1000, epsilon=1e-6, device=None):\n",
    "        self.timesteps = timesteps\n",
    "        self.epsilon = epsilon\n",
    "        self.device = device\n",
    "        \n",
    "        # Create alphas using a cosine schedule\n",
    "        self.alphas = torch.cos(torch.linspace(0, math.pi/2, timesteps, device=device))**2\n",
    "        self.betas = 1.0 - self.alphas\n",
    "        self.alpha_bar = torch.maximum(torch.cumprod(self.alphas, dim=0), torch.tensor(self.epsilon, device=self.alphas.device))\n",
    "\n",
    "    def get_alpha(self, t):\n",
    "        return self.alphas[t]\n",
    "\n",
    "    def get_beta(self, t):\n",
    "        return self.betas[t]\n",
    "\n",
    "    def get_variance(self, t):\n",
    "        return self.get_beta(t) * (1 - self.get_alpha(t))\n",
    "\n",
    "    def get_alpha_bar(self, t):\n",
    "        return self.alpha_bar[t]\n",
    "\n",
    "class SymbolicRegressionDataset(Dataset):\n",
    "    def __init__(self, preprocessed_data, vocab, max_seq_len, noise_schedule):\n",
    "        self.preprocessed_data = preprocessed_data\n",
    "        self.vocab = vocab  # Add vocab here\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.noise_schedule = noise_schedule\n",
    "    \n",
    "    def add_noise(self, embeddings, t):\n",
    "        \"\"\"Add noise to the embeddings based on the cosine noise schedule.\"\"\"\n",
    "        alpha_t = self.noise_schedule.get_alpha(t)\n",
    "        beta_t = self.noise_schedule.get_beta(t)\n",
    "        noise = torch.randn_like(embeddings)*torch.sqrt(beta_t)\n",
    "        noisy_embeddings = torch.sqrt(alpha_t)*embeddings + noise\n",
    "        return noisy_embeddings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Prepare a single data point.\"\"\"\n",
    "        data_point = self.preprocessed_data[idx]\n",
    "        formula_emb = torch.tensor(data_point['formula_embedding'], dtype=torch.float32)\n",
    "        dataset_emb =  torch.tensor(data_point['dataset_embedding'], dtype=torch.float32)\n",
    "        skeleton = data_point['skeleton']\n",
    "\n",
    "        # Sample a timestep t\n",
    "        t = random.randint(0, self.noise_schedule.timesteps - 1)\n",
    "        noisy_formula_emb = self.add_noise(formula_emb, t)\n",
    "        return formula_emb, noisy_formula_emb, dataset_emb, t, skeleton\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.preprocessed_data)\n",
    "\n",
    "class DiffusionModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, num_heads, num_timesteps, max_seq_len=5000, pretrained_embeddings=None):\n",
    "        super(DiffusionModel, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_timesteps = num_timesteps\n",
    "                \n",
    "        # Initialize embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.projection = nn.Linear(embedding_dim, hidden_dim) if embedding_dim != hidden_dim else nn.Identity()\n",
    "        self.layer_norm = nn.LayerNorm(hidden_dim, eps=1e-6)\n",
    "\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=hidden_dim,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_layers,\n",
    "            num_decoder_layers=num_layers,\n",
    "            batch_first=False\n",
    "        )\n",
    "        \n",
    "        # Cross-attention mechanism for conditioning\n",
    "        self.cross_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim, \n",
    "            num_heads=num_heads, \n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.fc_out = nn.Linear(hidden_dim, embedding_dim)\n",
    "        \n",
    "    def forward(self, embeddings):\n",
    "        # Process embeddings\n",
    "        batch_size, embedding_dim = embeddings.shape\n",
    "        embeddings = self.projection(embeddings)\n",
    "        embeddings = self.layer_norm(embeddings)\n",
    "        embeddings = embeddings.unsqueeze(0)  # Shape: (1, batch_size, hidden_dim)\n",
    "        embeddings = self.transformer(embeddings, embeddings)  # Shape: (1, batch_size, hidden_dim)\n",
    "        embeddings = embeddings.squeeze(0)  # Shape: (batch_size, hidden_dim)\n",
    "        logits = self.fc_out(embeddings)  # Shape: (batch_size, output_dim)\n",
    "        return logits\n",
    "\n",
    "    def reverse_diffusion(self, noisy_formula_embeddings, dataset_embeddings, schedule):\n",
    "        \"\"\"Reverse diffusion process using attention-based conditioning.\"\"\"\n",
    "        device = noisy_formula_embeddings.device\n",
    "        batch_size, embedding_dim = noisy_formula_embeddings.size()\n",
    "        x_t = noisy_formula_embeddings\n",
    "        \n",
    "        tnet = tNet(tNetConfig(num_vars=batch_size,embedding_size=embedding_dim))\n",
    "        \n",
    "        # Expand dimensions for cross-attention\n",
    "        dataset_embeddings = dataset_embeddings.unsqueeze(1)  # Add sequence dimension (e.g., [B, D] -> [B, 1, D])\n",
    "        \n",
    "        for t in reversed(range(self.num_timesteps)):\n",
    "            # Predict the noise using cross-attention\n",
    "            query = x_t.unsqueeze(1)  # [B, 1, D]\n",
    "            conditioned_embedding, _ = self.cross_attention(\n",
    "                query=query,\n",
    "                key=dataset_embeddings,\n",
    "                value=dataset_embeddings\n",
    "            )\n",
    "            x_t = conditioned_embedding.squeeze(1)  # Remove sequence dimension\n",
    "            \n",
    "            # Use conditioned_embedding to predict noise\n",
    "            predicted_noise = tnet(x_t) if tnet is not None else self.forward(x_t) \n",
    "\n",
    "            # Extract alpha and beta values from schedule\n",
    "            alpha_t = schedule.get_alpha(t)\n",
    "            beta_t = schedule.get_beta(t)\n",
    "            \n",
    "            # Compute mean of x_{t-1}\n",
    "            mean_x_prev = (x_t - beta_t * predicted_noise) / torch.sqrt(alpha_t)\n",
    "            \n",
    "            if t > 0:\n",
    "                std_dev = torch.sqrt(beta_t)\n",
    "                noise = torch.randn_like(x_t, device=device) * std_dev\n",
    "                x_t = mean_x_prev + noise\n",
    "            else:\n",
    "                x_t = mean_x_prev\n",
    "            \n",
    "            # Clamp values to avoid out-of-bound values\n",
    "            x_t = torch.clamp(x_t, min=-1.0, max=1.0)\n",
    "        \n",
    "        return x_t\n",
    "\n",
    "def denoising_loss(predicted_embeddings, clean_embeddings):\n",
    "    return nn.MSELoss()(predicted_embeddings, clean_embeddings)\n",
    "\n",
    "def train_diffusion_model(model, train_loader, val_loader, num_epochs=10, patience_num_epochs=3):\n",
    "    device = setup_device()\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5)\n",
    "    schedule = CosineNoiseSchedule(timesteps=1000, device=device)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    num_epochs_without_improvement = 0\n",
    "    early_stopping = False\n",
    "    performance_metrics = {\"epoch_list\": [], \"train_loss_list\": [], \"val_loss_list\": []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for formula_emb, noisy_formula_emb, dataset_emb, t, skeleton in train_loader:\n",
    "            formula_emb, noisy_formula_emb, dataset_emb = formula_emb.to(device), noisy_formula_emb.to(device), dataset_emb.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Predict the denoised formula embeddings using the model\n",
    "            predicted_emb = model(noisy_formula_emb)\n",
    "\n",
    "            # Compute the loss using the original clean formula embeddings\n",
    "            loss = denoising_loss(predicted_emb, formula_emb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        train_loss = total_loss/len(train_loader)\n",
    "        performance_metrics['train_loss_list'].append(train_loss)\n",
    "\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        val_loss = 0.0\n",
    "        total_correct = 0\n",
    "        num_samples = 0\n",
    "\n",
    "        with torch.no_grad():  # No gradients needed during validation\n",
    "            for formula_emb, noisy_formula_emb, dataset_emb, t, skeleton in val_loader:\n",
    "                formula_emb, noisy_formula_emb, dataset_emb = formula_emb.to(device), noisy_formula_emb.to(device), dataset_emb.to(device)\n",
    "                predicted_emb = model.reverse_diffusion(noisy_formula_emb, dataset_emb, schedule)\n",
    "                loss = denoising_loss(predicted_emb, formula_emb)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                num_samples += formula_emb.size(0)\n",
    "\n",
    "        val_loss = val_loss/len(val_loader)\n",
    "        performance_metrics['val_loss_list'].append(val_loss)\n",
    "        performance_metrics['epoch_list'].append(epoch + 1)\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss}, Val Loss: {val_loss}')\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            save_model(model, \"best_diffusion_model_method2.pt\")\n",
    "            num_epochs_without_improvement = 0\n",
    "        else:\n",
    "            num_epochs_without_improvement += 1\n",
    "\n",
    "        if num_epochs_without_improvement >= patience_num_epochs:\n",
    "            print(f\"Training stopped early at epoch {epoch + 1}. Best validation loss: {best_val_loss}\")\n",
    "            early_stopping = True\n",
    "            break\n",
    "\n",
    "    if not early_stopping:\n",
    "        save_model(model, \"best_diffusion_model_method2.pt\")\n",
    "\n",
    "    return model, performance_metrics\n",
    "\n",
    "# Example of loading and preparing the dataset\n",
    "dataset = load_dataset('Data/preprocessed_data_with_embeddings.json')\n",
    "vocab = load_JSON(\"Data/vocab_embeddings.json\")  # Vocabulary is a dictionary of continuous embeddings\n",
    "\n",
    "MAX_LENGTH = determine_max_seq_len(dataset)  # Determine the max length dynamically\n",
    "\n",
    "schedule = CosineNoiseSchedule(timesteps=1000,device=setup_device())\n",
    "\n",
    "# First, perform the split on the raw dataset\n",
    "train_size = int(0.7*len(dataset))  # 70% for training\n",
    "val_size = int(0.15*len(dataset))  # 15% for validation\n",
    "test_size = len(dataset) - train_size - val_size  # 15% for testing\n",
    "\n",
    "# Perform random split\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_dataset_SR = SymbolicRegressionDataset(train_dataset, vocab, MAX_LENGTH, schedule)\n",
    "val_dataset_SR = SymbolicRegressionDataset(val_dataset, vocab, MAX_LENGTH, schedule)\n",
    "test_dataset_SR = SymbolicRegressionDataset(test_dataset, vocab, MAX_LENGTH, schedule)\n",
    "\n",
    "# Create DataLoader objects for each subset\n",
    "train_loader = DataLoader(train_dataset_SR, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset_SR, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset_SR, batch_size=16, shuffle=True)\n",
    "\n",
    "# Initialize the model\n",
    "num_heads = 4  # Number of attention heads, ensure this is a divisor of embedding_dim\n",
    "embedding_dim = 128  # The embedding dimension is 100 as per your problem\n",
    "hidden_dim = embedding_dim  # Hidden dimension stays the same for simplicity\n",
    "\n",
    "# Ensure embedding_dim is divisible by num_heads\n",
    "if embedding_dim % num_heads != 0:\n",
    "    raise ValueError(f\"embedding_dim ({embedding_dim}) must be divisible by num_heads ({num_heads}).\")\n",
    "\n",
    "model = DiffusionModel(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_layers=4,\n",
    "    num_heads=4,\n",
    "    num_timesteps=1000,\n",
    "    pretrained_embeddings=vocab,\n",
    ")\n",
    "\n",
    "model,performance_metrics_DICT = train_diffusion_model(model,train_loader,val_loader,num_epochs=100,patience_num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.7206235289573669, Val Loss: 0.6199209690093994\n",
      "Epoch 2/100, Train Loss: 0.4656024813652039, Val Loss: 0.6199209690093994\n",
      "Epoch 3/100, Train Loss: 0.33785690665245055, Val Loss: 0.6199209690093994\n",
      "Epoch 4/100, Train Loss: 0.2589802086353302, Val Loss: 0.6199209690093994\n",
      "Epoch 5/100, Train Loss: 0.21497848331928254, Val Loss: 0.6199209690093994\n",
      "Epoch 6/100, Train Loss: 0.19425413012504578, Val Loss: 0.6199209690093994\n",
      "Epoch 7/100, Train Loss: 0.1795389920473099, Val Loss: 0.6199209690093994\n",
      "Epoch 8/100, Train Loss: 0.17081521153450013, Val Loss: 0.6199209690093994\n",
      "Epoch 9/100, Train Loss: 0.16131505072116853, Val Loss: 0.6199209690093994\n",
      "Epoch 10/100, Train Loss: 0.15975157022476197, Val Loss: 0.6199209690093994\n",
      "Epoch 11/100, Train Loss: 0.1492638885974884, Val Loss: 0.6199209690093994\n",
      "Epoch 12/100, Train Loss: 0.14793502986431123, Val Loss: 0.6199209690093994\n",
      "Epoch 13/100, Train Loss: 0.14628996849060058, Val Loss: 0.6199209690093994\n",
      "Epoch 14/100, Train Loss: 0.14139475226402282, Val Loss: 0.6199209690093994\n",
      "Epoch 15/100, Train Loss: 0.14508646726608276, Val Loss: 0.6199209690093994\n",
      "Epoch 16/100, Train Loss: 0.14382776916027068, Val Loss: 0.6199209690093994\n",
      "Epoch 17/100, Train Loss: 0.14063077569007873, Val Loss: 0.6199209690093994\n",
      "Epoch 18/100, Train Loss: 0.14094341099262236, Val Loss: 0.6199209690093994\n",
      "Epoch 19/100, Train Loss: 0.14012505412101744, Val Loss: 0.6199209690093994\n",
      "Epoch 20/100, Train Loss: 0.13966305255889894, Val Loss: 0.6199209690093994\n",
      "Epoch 21/100, Train Loss: 0.1380559027194977, Val Loss: 0.6199209690093994\n",
      "Epoch 22/100, Train Loss: 0.13773660063743592, Val Loss: 0.6199209690093994\n",
      "Epoch 23/100, Train Loss: 0.13765364587306977, Val Loss: 0.6199209690093994\n",
      "Epoch 24/100, Train Loss: 0.13779977560043336, Val Loss: 0.6199209690093994\n",
      "Epoch 25/100, Train Loss: 0.13831034898757935, Val Loss: 0.6199209690093994\n",
      "Epoch 26/100, Train Loss: 0.13659653961658477, Val Loss: 0.6199209690093994\n",
      "Epoch 27/100, Train Loss: 0.13404988944530488, Val Loss: 0.6199209690093994\n",
      "Epoch 28/100, Train Loss: 0.1393375277519226, Val Loss: 0.6199209690093994\n",
      "Epoch 29/100, Train Loss: 0.13627262711524962, Val Loss: 0.6199209690093994\n",
      "Epoch 30/100, Train Loss: 0.1403296709060669, Val Loss: 0.6199209690093994\n",
      "Epoch 31/100, Train Loss: 0.13724210262298583, Val Loss: 0.6199209690093994\n",
      "Epoch 32/100, Train Loss: 0.1397308051586151, Val Loss: 0.6199209690093994\n",
      "Epoch 33/100, Train Loss: 0.13522272408008576, Val Loss: 0.6199209690093994\n",
      "Epoch 34/100, Train Loss: 0.1377719521522522, Val Loss: 0.6199209690093994\n",
      "Epoch 35/100, Train Loss: 0.139652881026268, Val Loss: 0.6199209690093994\n",
      "Epoch 36/100, Train Loss: 0.13929089307785034, Val Loss: 0.6199209690093994\n",
      "Epoch 37/100, Train Loss: 0.1358956903219223, Val Loss: 0.6199209690093994\n",
      "Epoch 38/100, Train Loss: 0.13641760051250457, Val Loss: 0.6199209690093994\n",
      "Epoch 39/100, Train Loss: 0.13944525122642518, Val Loss: 0.6199209690093994\n",
      "Epoch 40/100, Train Loss: 0.13653745651245117, Val Loss: 0.6199209690093994\n",
      "Epoch 41/100, Train Loss: 0.14010678827762604, Val Loss: 0.6199209690093994\n",
      "Epoch 42/100, Train Loss: 0.13581313490867614, Val Loss: 0.6199209690093994\n",
      "Epoch 43/100, Train Loss: 0.1377057284116745, Val Loss: 0.6199209690093994\n",
      "Epoch 44/100, Train Loss: 0.13818165063858032, Val Loss: 0.6199209690093994\n",
      "Epoch 45/100, Train Loss: 0.13724125027656556, Val Loss: 0.6199209690093994\n",
      "Epoch 46/100, Train Loss: 0.13964732587337494, Val Loss: 0.6199209690093994\n",
      "Epoch 47/100, Train Loss: 0.13706937730312346, Val Loss: 0.6199209690093994\n",
      "Epoch 48/100, Train Loss: 0.13590629994869233, Val Loss: 0.6199209690093994\n",
      "Epoch 49/100, Train Loss: 0.1357886850833893, Val Loss: 0.6199209690093994\n",
      "Epoch 50/100, Train Loss: 0.13504832684993745, Val Loss: 0.6199209690093994\n",
      "Epoch 51/100, Train Loss: 0.13913078010082244, Val Loss: 0.6199209690093994\n",
      "Epoch 52/100, Train Loss: 0.13800675868988038, Val Loss: 0.6199209690093994\n",
      "Epoch 53/100, Train Loss: 0.13942339420318603, Val Loss: 0.6199209690093994\n",
      "Epoch 54/100, Train Loss: 0.1401896208524704, Val Loss: 0.6199209690093994\n",
      "Epoch 55/100, Train Loss: 0.13520313799381256, Val Loss: 0.6199209690093994\n",
      "Epoch 56/100, Train Loss: 0.1339469075202942, Val Loss: 0.6199209690093994\n",
      "Epoch 57/100, Train Loss: 0.1368108093738556, Val Loss: 0.6199209690093994\n",
      "Epoch 58/100, Train Loss: 0.13942001163959503, Val Loss: 0.6199209690093994\n",
      "Epoch 59/100, Train Loss: 0.1381221145391464, Val Loss: 0.6199209690093994\n",
      "Epoch 60/100, Train Loss: 0.1383316546678543, Val Loss: 0.6199209690093994\n",
      "Epoch 61/100, Train Loss: 0.13680026233196257, Val Loss: 0.6199209690093994\n",
      "Epoch 62/100, Train Loss: 0.13962290585041046, Val Loss: 0.6199209690093994\n",
      "Epoch 63/100, Train Loss: 0.13326554596424103, Val Loss: 0.6199209690093994\n",
      "Epoch 64/100, Train Loss: 0.1387736141681671, Val Loss: 0.6199209690093994\n",
      "Epoch 65/100, Train Loss: 0.13959548771381378, Val Loss: 0.6199209690093994\n",
      "Epoch 66/100, Train Loss: 0.14248485565185548, Val Loss: 0.6199209690093994\n",
      "Epoch 67/100, Train Loss: 0.13769370913505555, Val Loss: 0.6199209690093994\n",
      "Epoch 68/100, Train Loss: 0.14380577504634856, Val Loss: 0.6199209690093994\n",
      "Epoch 69/100, Train Loss: 0.1353621929883957, Val Loss: 0.6199209690093994\n",
      "Epoch 70/100, Train Loss: 0.13725089728832246, Val Loss: 0.6199209690093994\n",
      "Epoch 71/100, Train Loss: 0.13729995489120483, Val Loss: 0.6199209690093994\n",
      "Epoch 72/100, Train Loss: 0.1366923987865448, Val Loss: 0.6199209690093994\n",
      "Epoch 73/100, Train Loss: 0.13657590448856355, Val Loss: 0.6199209690093994\n",
      "Epoch 74/100, Train Loss: 0.13437872529029846, Val Loss: 0.6199209094047546\n",
      "Epoch 75/100, Train Loss: 0.13812994360923767, Val Loss: 0.6199209690093994\n",
      "Epoch 76/100, Train Loss: 0.13774887323379517, Val Loss: 0.6199209690093994\n",
      "Epoch 77/100, Train Loss: 0.13785875141620635, Val Loss: 0.6199209690093994\n",
      "Epoch 78/100, Train Loss: 0.1374487966299057, Val Loss: 0.6199209690093994\n",
      "Epoch 79/100, Train Loss: 0.13984255790710448, Val Loss: 0.6199209690093994\n",
      "Epoch 80/100, Train Loss: 0.13995031118392945, Val Loss: 0.6199209690093994\n",
      "Epoch 81/100, Train Loss: 0.13762223422527314, Val Loss: 0.6199209690093994\n",
      "Epoch 82/100, Train Loss: 0.13722144961357116, Val Loss: 0.6199209690093994\n",
      "Epoch 83/100, Train Loss: 0.13880317211151122, Val Loss: 0.6199209690093994\n",
      "Epoch 84/100, Train Loss: 0.13423740565776826, Val Loss: 0.6199209690093994\n",
      "Epoch 85/100, Train Loss: 0.13654063045978546, Val Loss: 0.6199209094047546\n",
      "Epoch 86/100, Train Loss: 0.14015458822250365, Val Loss: 0.6199209690093994\n",
      "Epoch 87/100, Train Loss: 0.14016116857528688, Val Loss: 0.6199209690093994\n",
      "Epoch 88/100, Train Loss: 0.1384606659412384, Val Loss: 0.6199209690093994\n",
      "Epoch 89/100, Train Loss: 0.1396716296672821, Val Loss: 0.6199209690093994\n",
      "Epoch 90/100, Train Loss: 0.13871659934520722, Val Loss: 0.6199209690093994\n",
      "Epoch 91/100, Train Loss: 0.1386726140975952, Val Loss: 0.6199209690093994\n",
      "Epoch 92/100, Train Loss: 0.13873913884162903, Val Loss: 0.6199209690093994\n",
      "Epoch 93/100, Train Loss: 0.13800098598003388, Val Loss: 0.6199209690093994\n",
      "Epoch 94/100, Train Loss: 0.1361697345972061, Val Loss: 0.6199209690093994\n",
      "Epoch 95/100, Train Loss: 0.13817777633666992, Val Loss: 0.6199209690093994\n",
      "Epoch 96/100, Train Loss: 0.13502813875675201, Val Loss: 0.6199209690093994\n",
      "Epoch 97/100, Train Loss: 0.13905571401119232, Val Loss: 0.6199209690093994\n",
      "Epoch 98/100, Train Loss: 0.13901992738246918, Val Loss: 0.6199209690093994\n",
      "Epoch 99/100, Train Loss: 0.13614542484283448, Val Loss: 0.6199209690093994\n",
      "Epoch 100/100, Train Loss: 0.13860292136669158, Val Loss: 0.6199209690093994\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "from torch.nn import functional as F\n",
    "from dataclasses import dataclass\n",
    "import pdb\n",
    "\n",
    "# Set the random seed for replicability\n",
    "seed = 940\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "def determine_max_seq_len(data, max_length='max_length'):\n",
    "    \"\"\"Calculate the max sequence length dynamically if 'max_length' is used as an argument.\"\"\"\n",
    "    if max_length == 'max_length':\n",
    "        MAX_LENGTH = max(len(dp[\"tokens\"]) for dp in data)\n",
    "    else:\n",
    "        MAX_LENGTH = max_length\n",
    "    return MAX_LENGTH\n",
    "\n",
    "def setup_device():\n",
    "    \"\"\"Set up the device for training.\"\"\"\n",
    "    return torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def save_model(model, filepath):\n",
    "    \"\"\"Save the model's state dictionary.\"\"\"\n",
    "    torch.save(model.state_dict(), filepath)\n",
    "    return model\n",
    "\n",
    "def load_model(model, filepath):\n",
    "    \"\"\"Load a saved model state dictionary.\"\"\"\n",
    "    model.load_state_dict(torch.load(filepath))\n",
    "    model.eval()\n",
    "    device = setup_device()\n",
    "    model.to(device)\n",
    "    return model, device\n",
    "\n",
    "def load_dataset(filepath):\n",
    "    \"\"\"Load the dataset from a JSON file.\"\"\"\n",
    "    with open(filepath, 'r') as file:\n",
    "        dataset = [json.loads(line) for line in file]\n",
    "    return dataset\n",
    "\n",
    "def save_JSON(data, filename):\n",
    "    \"\"\"Save data to a JSON file.\"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "    return\n",
    "\n",
    "def load_JSON(filename):\n",
    "    \"\"\"Load a JSON file.\"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "@dataclass\n",
    "class tNetConfig:\n",
    "    num_vars: int\n",
    "    embedding_size: int\n",
    "\n",
    "class tNet(nn.Module):\n",
    "    def __init__(self, config: tNetConfig):\n",
    "        super(tNet, self).__init__()\n",
    "\n",
    "        self.config = config\n",
    "        self.num_vars = config.num_vars\n",
    "        self.n_embd = config.embedding_size\n",
    "\n",
    "        self.activation_func = F.relu\n",
    "\n",
    "        # Define the convolutional layers\n",
    "        self.conv1 = nn.Conv1d(self.num_vars, self.n_embd, 1)\n",
    "        self.conv2 = nn.Conv1d(self.n_embd, 2*self.n_embd, 1)\n",
    "        self.conv3 = nn.Conv1d(2*self.n_embd, 4*self.n_embd, 1)\n",
    "\n",
    "        # Define fully connected layers\n",
    "        self.fc1 = nn.Linear(4*self.n_embd, 2*self.n_embd)\n",
    "        self.fc2 = nn.Linear(2*self.n_embd, self.n_embd)\n",
    "\n",
    "        # Corrected GroupNorm initialization\n",
    "        self.input_batch_norm = nn.GroupNorm(1, self.num_vars)  # Corrected to match input channels\n",
    "        \n",
    "        # Define other GroupNorm layers\n",
    "        self.bn1 = nn.GroupNorm(1, self.n_embd)\n",
    "        self.bn2 = nn.GroupNorm(1, 2*self.n_embd)\n",
    "        self.bn3 = nn.GroupNorm(1, 4*self.n_embd)\n",
    "        self.bn4 = nn.GroupNorm(1, 2*self.n_embd)\n",
    "        self.bn5 = nn.GroupNorm(1, self.n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply normalization and convolutions\n",
    "        if len(x.shape) == 2:  # If no batch dimension\n",
    "            x = x.unsqueeze(0)  # Add batch dimension\n",
    "        \n",
    "        x = self.input_batch_norm(x)\n",
    "        x = self.activation_func(self.bn1(self.conv1(x)))\n",
    "        x = self.activation_func(self.bn2(self.conv2(x)))\n",
    "        x = self.activation_func(self.bn3(self.conv3(x)))\n",
    "\n",
    "        # Global max pooling\n",
    "        x, _ = torch.max(x, dim=2)  # Reducing along the sequence dimension (index 2)\n",
    "        assert x.size(1) == 4*self.n_embd  # Ensure correct output size\n",
    "\n",
    "        # Apply fully connected layers\n",
    "        x = self.activation_func(self.bn4(self.fc1(x)))\n",
    "        x = self.activation_func(self.bn5(self.fc2(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "def add_noise_with_data(embeddings, dataset_points, t, schedule):\n",
    "    \"\"\"Add noise to embeddings using dataset points.\"\"\"\n",
    "    alpha_t = schedule.get_alpha(t)\n",
    "    beta_t = schedule.get_beta(t)\n",
    "    noise = torch.randn_like(embeddings) * torch.sqrt(beta_t)\n",
    "    noisy_embeddings = torch.sqrt(alpha_t) * embeddings + noise + dataset_points.mean(dim=0)\n",
    "    return noisy_embeddings\n",
    "\n",
    "class CosineNoiseSchedule:\n",
    "    def __init__(self, timesteps=1000, epsilon=1e-6, device=None):\n",
    "        self.timesteps = timesteps\n",
    "        self.epsilon = epsilon\n",
    "        self.device = device\n",
    "        \n",
    "        # Create alphas using a cosine schedule\n",
    "        self.alphas = torch.cos(torch.linspace(0, math.pi/2, timesteps, device=device))**2\n",
    "        self.betas = 1.0 - self.alphas\n",
    "        self.alpha_bar = torch.maximum(torch.cumprod(self.alphas, dim=0), torch.tensor(self.epsilon, device=self.alphas.device))\n",
    "\n",
    "    def get_alpha(self, t):\n",
    "        return self.alphas[t]\n",
    "\n",
    "    def get_beta(self, t):\n",
    "        return self.betas[t]\n",
    "\n",
    "    def get_variance(self, t):\n",
    "        return self.get_beta(t) * (1 - self.get_alpha(t))\n",
    "\n",
    "    def get_alpha_bar(self, t):\n",
    "        return self.alpha_bar[t]\n",
    "\n",
    "class SymbolicRegressionDataset(Dataset):\n",
    "    def __init__(self, preprocessed_data, vocab, max_seq_len, noise_schedule):\n",
    "        self.preprocessed_data = preprocessed_data\n",
    "        self.vocab = vocab\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.noise_schedule = noise_schedule\n",
    "    \n",
    "    def add_noise(self, embeddings, dataset_points, t):\n",
    "        \"\"\"Add noise to embeddings based on data points.\"\"\"\n",
    "        return add_noise_with_data(embeddings, dataset_points, t, self.noise_schedule)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Prepare a single data point.\"\"\"\n",
    "        data_point = self.preprocessed_data[idx]\n",
    "        formula_emb = torch.tensor(data_point['formula_embedding'], dtype=torch.float32)\n",
    "        dataset_emb = torch.tensor(data_point['dataset_embedding'], dtype=torch.float32)\n",
    "        skeleton = data_point['skeleton']\n",
    "\n",
    "        # Sample a timestep t\n",
    "        t = random.randint(0, self.noise_schedule.timesteps - 1)\n",
    "        noisy_formula_emb = self.add_noise(formula_emb, dataset_emb, t)\n",
    "        return formula_emb, noisy_formula_emb, dataset_emb, t, skeleton\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.preprocessed_data)\n",
    "\n",
    "class DiffusionModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, num_heads, num_timesteps, pretrained_embeddings=None):\n",
    "        super(DiffusionModel, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_timesteps = num_timesteps\n",
    "        \n",
    "        # Initialize embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.projection = nn.Linear(embedding_dim, hidden_dim) if embedding_dim != hidden_dim else nn.Identity()\n",
    "        self.layer_norm = nn.LayerNorm(hidden_dim, eps=1e-6)\n",
    "        \n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=hidden_dim,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_layers,\n",
    "            num_decoder_layers=num_layers,\n",
    "            batch_first=False\n",
    "        )\n",
    "        \n",
    "        # Cross-attention mechanism for conditioning\n",
    "        self.cross_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim, \n",
    "            num_heads=num_heads, \n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.fc_out = nn.Linear(hidden_dim, embedding_dim)\n",
    "        \n",
    "    def forward(self, embeddings):\n",
    "        \"\"\"Standard forward pass.\"\"\"\n",
    "        embeddings = self.projection(embeddings)\n",
    "        embeddings = self.layer_norm(embeddings)\n",
    "        embeddings = embeddings.unsqueeze(0)  # Add sequence dimension\n",
    "        embeddings = self.transformer(embeddings, embeddings)\n",
    "        embeddings = embeddings.squeeze(0)  # Remove sequence dimension\n",
    "        logits = self.fc_out(embeddings)\n",
    "        return logits\n",
    "\n",
    "    def reverse_diffusion(self, noisy_formula_embeddings, dataset_embeddings, schedule):\n",
    "        \"\"\"Reverse diffusion process using attention-based conditioning.\"\"\"\n",
    "        device = noisy_formula_embeddings.device\n",
    "        batch_size, embedding_dim = noisy_formula_embeddings.size()\n",
    "        x_t = noisy_formula_embeddings\n",
    "        \n",
    "        tnet = tNet(tNetConfig(num_vars=batch_size,embedding_size=embedding_dim))\n",
    "        \n",
    "        dataset_embeddings = dataset_embeddings.unsqueeze(1)  # Add sequence dimension\n",
    "        \n",
    "        for t in reversed(range(self.num_timesteps)):\n",
    "            # Predict the noise using cross-attention\n",
    "            query = x_t.unsqueeze(1)  # Shape: [B, 1, D]\n",
    "            conditioned_embedding, _ = self.cross_attention(\n",
    "                query=query,\n",
    "                key=dataset_embeddings,\n",
    "                value=dataset_embeddings\n",
    "            )\n",
    "            x_t = conditioned_embedding.squeeze(1)  # Remove sequence dimension\n",
    "            \n",
    "            # Use conditioned_embedding to predict noise\n",
    "            predicted_noise = tnet(x_t) if tnet is not None else self.forward(x_t) \n",
    "            \n",
    "            # Extract alpha and beta values\n",
    "            alpha_t = schedule.get_alpha(t)\n",
    "            beta_t = schedule.get_beta(t)\n",
    "            \n",
    "            # Compute mean of x_{t-1}\n",
    "            mean_x_prev = (x_t - beta_t*predicted_noise)/torch.sqrt(alpha_t)\n",
    "            \n",
    "            if t > 0:\n",
    "                std_dev = torch.sqrt(beta_t)\n",
    "                noise = torch.randn_like(x_t, device=device) * std_dev\n",
    "                x_t = mean_x_prev + noise\n",
    "            else:\n",
    "                x_t = mean_x_prev\n",
    "            \n",
    "            # Clamp values\n",
    "            x_t = torch.clamp(x_t, min=-1.0, max=1.0)\n",
    "        \n",
    "        return x_t\n",
    "\n",
    "# Update the training process if needed\n",
    "def train_diffusion_model(model, train_loader, val_loader, num_epochs=10, patience_num_epochs=3):\n",
    "    device = setup_device()\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5)\n",
    "    schedule = CosineNoiseSchedule(timesteps=1000, device=device)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    num_epochs_without_improvement = 0\n",
    "    early_stopping = False\n",
    "    performance_metrics = {\"epoch_list\": [], \"train_loss_list\": [], \"val_loss_list\": []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for formula_emb, noisy_formula_emb, dataset_emb, t, skeleton in train_loader:\n",
    "            formula_emb, noisy_formula_emb, dataset_emb = formula_emb.to(device), noisy_formula_emb.to(device), dataset_emb.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            predicted_emb = model(noisy_formula_emb)\n",
    "            loss = denoising_loss(predicted_emb, formula_emb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        train_loss = total_loss / len(train_loader)\n",
    "        performance_metrics['train_loss_list'].append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for formula_emb, noisy_formula_emb, dataset_emb, t, skeleton in val_loader:\n",
    "                formula_emb, noisy_formula_emb, dataset_emb = formula_emb.to(device), noisy_formula_emb.to(device), dataset_emb.to(device)\n",
    "                predicted_emb = model.reverse_diffusion(noisy_formula_emb, dataset_emb, schedule)\n",
    "                loss = denoising_loss(predicted_emb, formula_emb)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        performance_metrics['val_loss_list'].append(val_loss)\n",
    "        performance_metrics['epoch_list'].append(epoch + 1)\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss}, Val Loss: {val_loss}')\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            save_model(model, \"best_diffusion_model.pt\")\n",
    "            num_epochs_without_improvement = 0\n",
    "        else:\n",
    "            num_epochs_without_improvement += 1\n",
    "\n",
    "        if num_epochs_without_improvement >= patience_num_epochs:\n",
    "            print(f\"Training stopped early at epoch {epoch + 1}. Best validation loss: {best_val_loss}\")\n",
    "            early_stopping = True\n",
    "            break\n",
    "\n",
    "    if not early_stopping:\n",
    "        save_model(model, \"best_diffusion_model.pt\")\n",
    "\n",
    "    return model, performance_metrics\n",
    "\n",
    "# Example of loading and preparing the dataset\n",
    "dataset = load_dataset('Data/preprocessed_data_with_embeddings.json')\n",
    "vocab = load_JSON(\"Data/vocab_embeddings.json\")  # Vocabulary is a dictionary of continuous embeddings\n",
    "\n",
    "MAX_LENGTH = determine_max_seq_len(dataset)  # Determine the max length dynamically\n",
    "\n",
    "schedule = CosineNoiseSchedule(timesteps=1000,device=setup_device())\n",
    "\n",
    "# First, perform the split on the raw dataset\n",
    "train_size = int(0.7*len(dataset))  # 70% for training\n",
    "val_size = int(0.15*len(dataset))  # 15% for validation\n",
    "test_size = len(dataset) - train_size - val_size  # 15% for testing\n",
    "\n",
    "# Perform random split\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_dataset_SR = SymbolicRegressionDataset(train_dataset, vocab, MAX_LENGTH, schedule)\n",
    "val_dataset_SR = SymbolicRegressionDataset(val_dataset, vocab, MAX_LENGTH, schedule)\n",
    "test_dataset_SR = SymbolicRegressionDataset(test_dataset, vocab, MAX_LENGTH, schedule)\n",
    "\n",
    "# Create DataLoader objects for each subset\n",
    "train_loader = DataLoader(train_dataset_SR, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset_SR, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset_SR, batch_size=16, shuffle=True)\n",
    "\n",
    "# Initialize the model\n",
    "num_heads = 4  # Number of attention heads, ensure this is a divisor of embedding_dim\n",
    "embedding_dim = 128  # The embedding dimension is 100 as per your problem\n",
    "hidden_dim = embedding_dim  # Hidden dimension stays the same for simplicity\n",
    "\n",
    "# Ensure embedding_dim is divisible by num_heads\n",
    "if embedding_dim % num_heads != 0:\n",
    "    raise ValueError(f\"embedding_dim ({embedding_dim}) must be divisible by num_heads ({num_heads}).\")\n",
    "\n",
    "model = DiffusionModel(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_layers=4,\n",
    "    num_heads=4,\n",
    "    num_timesteps=1000,\n",
    "    pretrained_embeddings=vocab,\n",
    ")\n",
    "\n",
    "model,performance_metrics_DICT = train_diffusion_model(model,train_loader,val_loader,num_epochs=100,patience_num_epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "STAT940_Final_Project_VENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
