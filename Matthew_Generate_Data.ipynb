{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Creating the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined and shuffled dataset saved to Data\\combined_dataset_5_variables_dynamic_seed20777980.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sympy\n",
    "import numpy as np\n",
    "import random\n",
    "import logging\n",
    "import re\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Constants\n",
    "PI = sympy.pi\n",
    "E = sympy.E\n",
    "PHI = (1 + sympy.sqrt(5))/2  # Golden ratio\n",
    "\n",
    "# Function to generate random constants (you can customize this list)\n",
    "def random_constants():\n",
    "    \"\"\"Randomly return a scientific constant.\"\"\"\n",
    "    constants = [PI, E, PHI, sympy.sqrt(2)]\n",
    "    return random.choice(constants)\n",
    "\n",
    "# Function to generate random coefficients (both float and integer)\n",
    "def random_coefficient():\n",
    "    \"\"\"Generate a random coefficient (either integer or float).\"\"\"\n",
    "    if random.random() < 0.5:\n",
    "        return random.randint(1, 10)  # Integer coefficients\n",
    "    else:\n",
    "        return random.uniform(0.1, 5)  # Floating-point coefficients\n",
    "\n",
    "# Function to create a dynamic list of n symbolic variables\n",
    "def generate_variables(n):\n",
    "    \"\"\"Generate a list of n symbolic variables.\"\"\"\n",
    "    symbol_list = sympy.symbols(f'x0:{n}')  # Generates x0, x1, ..., xn-1\n",
    "    return symbol_list\n",
    "\n",
    "# Function to generate a random symbolic function with scientific relevance and random coefficients\n",
    "def generate_random_function_with_relevance(variables, num_relevant_vars, complexity_range=(2, 4)):\n",
    "    \"\"\"Generate a random mathematical function using a subset of the variables.\"\"\"\n",
    "    relevant_vars = random.sample(variables, num_relevant_vars)  # Select relevant variables\n",
    "    num_ops = random.randint(*complexity_range)  # Dynamically choose number of operations\n",
    "    function = random.choice(relevant_vars)  # Start with a random relevant variable\n",
    "    for _ in range(num_ops):\n",
    "        op = random.choice([sympy.Add, sympy.Mul, sympy.sin, sympy.cos, sympy.exp, sympy.Pow])\n",
    "        if op in [sympy.Add, sympy.Mul]:\n",
    "            function = op(function, random.choice(relevant_vars + [random_constants(), random_coefficient()]))\n",
    "        elif op == sympy.Pow:\n",
    "            function = op(function, random.choice([2, 3, 4]))\n",
    "        else:\n",
    "            function = op(function)\n",
    "    return function\n",
    "\n",
    "\n",
    "# Example: Adding scientific equations, using physics-inspired forms\n",
    "def generate_physics_function(variables):\n",
    "    \"\"\"Generate physics-inspired functions, e.g., energy, velocity.\"\"\"\n",
    "    functions = [\n",
    "        random_coefficient() * variables[0]**2 + random_coefficient() * variables[1],  # Quadratic relation with random coefficients\n",
    "        sympy.sin(variables[0]) + random_coefficient() * sympy.cos(variables[1]),  # Trigonometric functions with a coefficient\n",
    "        random_coefficient() * variables[0]**3 + random_coefficient() * variables[1]**2 + random_coefficient() * 3*variables[0]*variables[1],  # Polynomial function\n",
    "        random_coefficient() * (sympy.Mul(variables[0], 9.8))  # Gravitational potential energy or force: F = ma (Newton’s second law)\n",
    "    ]\n",
    "    return random.choice(functions)  # Return a random physics-inspired function\n",
    "\n",
    "# Nguyen Dataset Generation (including physics-based functions)\n",
    "def nguyen_dataset_dynamic(n=2, num_functions=10):\n",
    "    \"\"\"Generate a dataset with dynamic functions, including physics and scientific expressions.\"\"\"\n",
    "    variables = generate_variables(n)  # Generate n variables dynamically\n",
    "    functions = []\n",
    "    for _ in range(num_functions):\n",
    "        num_relevant_vars = random.randint(1, n)  # Choose number of relevant variables randomly\n",
    "        if random.random() > 0.5:  # 50% chance to generate a random or physics-inspired function\n",
    "            functions.append(generate_physics_function(variables))\n",
    "        else:\n",
    "            functions.append(generate_random_function_with_relevance(variables, num_relevant_vars))\n",
    "    return functions\n",
    "\n",
    "# Feynman Dataset Generation\n",
    "def feynman_dataset(n=2,num_functions=10):\n",
    "    \"\"\"Generate symbolic regression functions based on Feynman dataset.\"\"\"\n",
    "    variables = generate_variables(n)\n",
    "    functions = [\n",
    "        random_coefficient()*variables[0]**2 + random_coefficient() * 2*variables[1],            # Linear + quadratic\n",
    "        random_coefficient()*sympy.sin(variables[0]) + random_coefficient() * sympy.cos(variables[1]),  # Trigonometric functions\n",
    "        random_coefficient()*variables[0]**3 + random_coefficient() * variables[1]**2 + random_coefficient() * 3*variables[0]*variables[1],  # Polynomial\n",
    "        random_coefficient()*variables[0]**4 + random_coefficient() * variables[1]**2 + random_coefficient() * variables[0]*variables[1],  # Quartic and product\n",
    "    ]\n",
    "    return functions[:num_functions]  # Return the first n functions\n",
    "\n",
    "# Livermore Dataset Generation\n",
    "def livermore_dataset(n=2,num_functions=10):\n",
    "    \"\"\"Generate symbolic regression functions based on Livermore dataset.\"\"\"\n",
    "    variables = generate_variables(n)\n",
    "    functions = [\n",
    "        random_coefficient()*variables[0]**6 + random_coefficient()*variables[1]**4 + random_coefficient()*variables[0]**2 + random_coefficient()*2*variables[1],  # Polynomial\n",
    "        random_coefficient()*variables[0]**8 + random_coefficient()*variables[1]**5 + random_coefficient()*3*variables[0]*variables[1],  # Polynomial\n",
    "        random_coefficient()*variables[0]**3 + random_coefficient()*5*variables[0]**2 + random_coefficient()*variables[1]**3 + random_coefficient()*2*variables[0]*variables[1],  # Polynomial\n",
    "        random_coefficient()*variables[0]**5 + random_coefficient()*variables[1]**4 + random_coefficient()*2*variables[0]*variables[1],  # Polynomial\n",
    "        random_coefficient()*sympy.sin(variables[0]) + random_coefficient() * sympy.cos(variables[1]) + random_coefficient() * variables[0]**2,  # Trigonometric + polynomial\n",
    "    ]\n",
    "    return functions[:num_functions]  # Return the first n functions\n",
    "\n",
    "# Evaluate the generated functions with random inputs\n",
    "def evaluate_nguyen_dataset_with_relevant_variables(functions, num_samples=100, range_vals=(-1, 1), noise_type='gaussian'):\n",
    "    \"\"\"Evaluate the functions with dynamic input variables and add noise, ensuring only relevant variables are considered.\"\"\"\n",
    "    dataset = []\n",
    "    for func in functions:\n",
    "        data = []\n",
    "        skeleton = create_skeleton(func)\n",
    "        num_vars = max([int(str(var)[1:]) for var in func.free_symbols]) + 1  # Get the highest subscript value from func.free_symbols\n",
    "        all_variables = generate_variables(num_vars)  # Generate variables from x0 to xN (including highest subscript)\n",
    "        \n",
    "        for _ in range(num_samples):\n",
    "            # Generate random values for all the variables from x0 to xN\n",
    "            inputs = {str(var): np.random.uniform(*range_vals) for var in all_variables}\n",
    "\n",
    "            # Evaluate the function using only the relevant variables (those in func.free_symbols)\n",
    "            relevant_inputs = {str(var): inputs[str(var)] for var in func.free_symbols}  # Use only relevant variables for evaluation\n",
    "            \n",
    "            try:\n",
    "                # Evaluate the function with the relevant inputs\n",
    "                result = func.evalf(subs=relevant_inputs)\n",
    "\n",
    "                # Check if the result is a real number\n",
    "                if result.is_real:\n",
    "                    output = float(result)\n",
    "                else:\n",
    "                    # If it's complex, skip or handle it (e.g., set output to NaN)\n",
    "                    logger.warning(f\"Complex result for {str(func)}: {result}. Skipping this data point.\")\n",
    "                    continue  # Skip complex results, or assign output = float('nan') if desired\n",
    "                \n",
    "                # Add noise\n",
    "                if noise_type == 'gaussian':\n",
    "                    noise = np.random.normal(0, 0.1)  # Gaussian noise with standard deviation of 0.1\n",
    "                elif noise_type == 'uniform':\n",
    "                    noise = np.random.uniform(-0.2, 0.2)  # Uniform noise in range [-0.2, 0.2]\n",
    "                else:\n",
    "                    noise = 0  # No noise\n",
    "\n",
    "                output += noise\n",
    "                data.append({\"inputs\": inputs, \"output\": output})\n",
    "\n",
    "            except (ValueError, ZeroDivisionError, OverflowError) as e:\n",
    "                logger.warning(f\"Invalid expression for {str(func)}: {e}\")\n",
    "                continue  # Skip invalid evaluations\n",
    "\n",
    "        # Convert the function to string for JSON serialization\n",
    "        dataset.append({\"function\": str(func), \"skeleton\": skeleton, \"data\": data})\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# Function to combine and shuffle datasets\n",
    "def combine_and_shuffle_datasets(datasets):\n",
    "    \"\"\"Combine multiple datasets and shuffle them.\"\"\"\n",
    "    combined = []\n",
    "    for dataset in datasets:\n",
    "        combined.extend(dataset)\n",
    "    random.shuffle(combined)  # Shuffle the combined dataset to mix all datasets well\n",
    "    return combined\n",
    "\n",
    "def create_skeleton(input_function):\n",
    "    \"\"\"\n",
    "    Convert a symbolic function into its skeleton representation by replacing:\n",
    "    - Numeric coefficients with 'C'\n",
    "    - Standalone numbers with 'C'\n",
    "    - Fractions with 'C' (except in exponents)\n",
    "    - Preserves numeric exponents like **2\n",
    "    \"\"\"\n",
    "    # Convert the symbolic function into a string\n",
    "    skeleton = str(input_function)\n",
    "\n",
    "    # Replace common mathematical constants with 'C'\n",
    "    constants_to_replace = {\n",
    "        str(sympy.E): 'C',                # Euler's number (e)\n",
    "        str(sympy.pi): 'C',              # Pi\n",
    "        str((1 + sympy.sqrt(5)) / 2): 'C', # Golden ratio (PHI)\n",
    "    }\n",
    "    for const, replacement in constants_to_replace.items():\n",
    "        skeleton = skeleton.replace(const, replacement)\n",
    "\n",
    "    # Replace standalone numbers not part of exponents\n",
    "    skeleton = re.sub(\n",
    "        r\"(?<![\\w^*])([+-]?\\d*\\.?\\d+)(?![*]{2})\",  # Excludes numbers after '**'\n",
    "        \"C\",\n",
    "        skeleton,\n",
    "    )\n",
    "\n",
    "    # Replace numeric coefficients (including preceding variables and functions)\n",
    "    def replace_numeric_coeff(match):\n",
    "        \"\"\"Replace numeric coefficients with 'C', preserving the context.\"\"\"\n",
    "        return f\"C{match.group(2)}\"\n",
    "\n",
    "    # Match numeric coefficients directly preceding variables or functions\n",
    "    skeleton = re.sub(r\"([+-]?\\d*\\.?\\d+)(\\*?[a-zA-Z(])\", replace_numeric_coeff, skeleton)\n",
    "\n",
    "    return skeleton\n",
    "    \n",
    "# Save dataset to JSON file\n",
    "def save_to_json_line_by_line(data, filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        for data_point in data:\n",
    "            json.dump(data_point, f)\n",
    "            f.write(\"\\n\")\n",
    "    return \n",
    "    \n",
    "# Save dataset to JSON file\n",
    "def save_to_json_line_by_line(data, filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        for data_point in data:\n",
    "            json.dump(data_point, f)\n",
    "            f.write(\"\\n\")\n",
    "    return \n",
    "\n",
    "# Set the random seed (for replicability)\n",
    "seed = 20777980  # You can change this seed to any integer\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Choose the number of variables and the number of functions for each dataset\n",
    "n_variables = 5  # Set the number of variables dynamically (e.g., 5 variables for testing)\n",
    "num_functions = 10  # Number of random functions to generate\n",
    "\n",
    "# Generate datasets for Nguyen, Feynman, and Livermore datasets\n",
    "nguyen_functions = nguyen_dataset_dynamic(n_variables, num_functions)\n",
    "feynman_functions = feynman_dataset(n_variables, num_functions)\n",
    "livermore_functions = livermore_dataset(n_variables, num_functions)\n",
    "\n",
    "# Evaluate the datasets with different noise models\n",
    "nguyen_dataset_evaluated = evaluate_nguyen_dataset_with_relevant_variables(nguyen_functions, num_samples=100, range_vals=(-1, 1), noise_type='gaussian')\n",
    "feynman_dataset_evaluated = evaluate_nguyen_dataset_with_relevant_variables(feynman_functions, num_samples=100, range_vals=(-1, 1), noise_type='uniform')\n",
    "livermore_dataset_evaluated = evaluate_nguyen_dataset_with_relevant_variables(livermore_functions, num_samples=100, range_vals=(-1, 1), noise_type='gaussian')\n",
    "\n",
    "# Combine and shuffle all datasets\n",
    "combined_dataset = combine_and_shuffle_datasets([nguyen_dataset_evaluated,feynman_dataset_evaluated,livermore_dataset_evaluated])\n",
    "\n",
    "# Save the combined and shuffled dataset to a JSON file\n",
    "file_path_combined = f\"Data\\combined_dataset_{n_variables}_variables_dynamic_seed{seed}.json\"\n",
    "\n",
    "save_to_json_line_by_line(combined_dataset, file_path_combined)\n",
    "\n",
    "print(f\"Combined and shuffled dataset saved to {file_path_combined}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_skeleton(input_function):\n",
    "    \"\"\"\n",
    "    Convert a symbolic function into its skeleton representation by replacing:\n",
    "    - Numeric coefficients with 'C'\n",
    "    - Standalone numbers with 'C'\n",
    "    - Fractions with 'C' (except in exponents)\n",
    "    - Preserves numeric exponents like **2\n",
    "    \"\"\"\n",
    "    # Convert the symbolic function into a string\n",
    "    skeleton = str(input_function)\n",
    "\n",
    "    # Replace common mathematical constants with 'C'\n",
    "    constants_to_replace = {\n",
    "        str(sympy.E): 'C',                # Euler's number (e)\n",
    "        str(sympy.pi): 'C',              # Pi\n",
    "        str((1 + sympy.sqrt(5)) / 2): 'C', # Golden ratio (PHI)\n",
    "    }\n",
    "    for const, replacement in constants_to_replace.items():\n",
    "        skeleton = skeleton.replace(const, replacement)\n",
    "\n",
    "    # Replace standalone numbers not part of exponents\n",
    "    skeleton = re.sub(\n",
    "        r\"(?<![\\w^*])([+-]?\\d*\\.?\\d+)(?![*]{2})\",  # Excludes numbers after '**'\n",
    "        \"C\",\n",
    "        skeleton,\n",
    "    )\n",
    "\n",
    "    # Replace numeric coefficients (including preceding variables and functions)\n",
    "    def replace_numeric_coeff(match):\n",
    "        \"\"\"Replace numeric coefficients with 'C', preserving the context.\"\"\"\n",
    "        return f\"C{match.group(2)}\"\n",
    "\n",
    "    # Match numeric coefficients directly preceding variables or functions\n",
    "    skeleton = re.sub(r\"([+-]?\\d*\\.?\\d+)(\\*?[a-zA-Z(])\", replace_numeric_coeff, skeleton)\n",
    "\n",
    "    return skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function: E*x4*(cos(x2) + 7), skeleton: C*xC*(cos(x2) + C), correct_skeleton: C*x4*(cos(x2) + C)\n"
     ]
    }
   ],
   "source": [
    "input_function = \"E*x4*(cos(x2) + 7)\"\n",
    "\n",
    "skeleton = create_skeleton(input_function)\n",
    "\n",
    "print(f\"function: {input_function}, skeleton: {skeleton}, correct_skeleton: C*x4*(cos(x2) + C)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 *Improved* - Tree Based Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sympy\n",
    "import numpy as np\n",
    "import random\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Constants\n",
    "PI = sympy.pi\n",
    "E = sympy.E\n",
    "PHI = (1 + sympy.sqrt(5)) / 2  # Golden ratio\n",
    "\n",
    "# Function to generate random constants (you can customize this list)\n",
    "def random_constants():\n",
    "    \"\"\"Randomly return a scientific constant.\"\"\"\n",
    "    constants = [PI, E, PHI, sympy.sqrt(2)]\n",
    "    return random.choice(constants)\n",
    "\n",
    "# Function to generate random coefficients (both float and integer)\n",
    "def random_coefficient():\n",
    "    \"\"\"Generate a random coefficient (either integer or float).\"\"\"\n",
    "    if random.random() < 0.5:\n",
    "        return random.randint(1, 10)  # Integer coefficients\n",
    "    else:\n",
    "        return random.uniform(0.1, 5)  # Floating-point coefficients\n",
    "\n",
    "# Function to create a dynamic list of n symbolic variables\n",
    "def generate_variables(n):\n",
    "    \"\"\"Generate a list of n symbolic variables.\"\"\"\n",
    "    symbol_list = sympy.symbols(f'x0:{n}')  # Generates x0, x1, ..., xn-1\n",
    "    return symbol_list\n",
    "\n",
    "# Function to build a tree-based symbolic expression\n",
    "def build_expression_tree(variables, max_depth=3):\n",
    "    \"\"\"Recursively build a symbolic expression tree.\"\"\"\n",
    "    # Base case: leaf nodes are either variables or constants\n",
    "    if max_depth == 0:\n",
    "        return random.choice(list(variables) + [random_constants(), random_coefficient()])\n",
    "    \n",
    "    # Internal nodes: operators\n",
    "    op = random.choice([sympy.Add, sympy.Mul, sympy.sin, sympy.cos, sympy.Pow, sympy.exp])\n",
    "    \n",
    "    # For unary operations (e.g., sin, cos, exp), only one argument is needed\n",
    "    if op in [sympy.sin, sympy.cos, sympy.exp]:\n",
    "        return op(build_expression_tree(variables, max_depth - 1))\n",
    "    \n",
    "    # For binary operations (e.g., Add, Mul, Pow), two arguments are needed\n",
    "    left = build_expression_tree(variables, max_depth - 1)\n",
    "    right = build_expression_tree(variables, max_depth - 1)\n",
    "    \n",
    "    return op(left, right)\n",
    "\n",
    "# Function to generate a random symbolic function with a tree structure\n",
    "def generate_random_function_with_tree_structure(variables, max_depth=3):\n",
    "    \"\"\"Generate a random mathematical function using a tree-based structure.\"\"\"\n",
    "    return build_expression_tree(variables, max_depth)\n",
    "\n",
    "# Function to generate a random physics-inspired function using a tree-based structure\n",
    "def generate_physics_function(variables, max_depth=3):\n",
    "    \"\"\"Generate physics-inspired functions using a tree-based structure.\"\"\"\n",
    "    functions = [\n",
    "        random_coefficient() * variables[0]**2 + random_coefficient() * variables[1],  # Quadratic relation with random coefficients\n",
    "        sympy.sin(variables[0]) + random_coefficient() * sympy.cos(variables[1]),  # Trigonometric functions with a coefficient\n",
    "        random_coefficient() * variables[0]**3 + random_coefficient() * variables[1]**2 + random_coefficient() * 3 * variables[0] * variables[1],  # Polynomial function\n",
    "        random_coefficient() * (sympy.Mul(variables[0], 9.8))  # Gravitational potential energy or force: F = ma (Newton’s second law)\n",
    "    ]\n",
    "    \n",
    "    return random.choice(functions)  # Return a random physics-inspired function\n",
    "\n",
    "# Nguyen Dataset Generation (including physics-based functions)\n",
    "def nguyen_dataset_dynamic(n=2, num_functions=10, max_depth=3):\n",
    "    \"\"\"Generate a dataset with dynamic functions, including physics and scientific expressions.\"\"\"\n",
    "    variables = generate_variables(n)  # Generate n variables dynamically\n",
    "    functions = []\n",
    "    for _ in range(num_functions):\n",
    "        num_relevant_vars = random.randint(1, n)  # Choose number of relevant variables randomly\n",
    "        if random.random() > 0.5:  # 50% chance to generate a random or physics-inspired function\n",
    "            functions.append(generate_physics_function(variables, max_depth))\n",
    "        else:\n",
    "            functions.append(generate_random_function_with_tree_structure(variables, max_depth))\n",
    "    return functions\n",
    "\n",
    "# Feynman Dataset Generation\n",
    "def feynman_dataset(n=2, num_functions=10, max_depth=3):\n",
    "    \"\"\"Generate symbolic regression functions based on Feynman dataset.\"\"\"\n",
    "    variables = generate_variables(n)\n",
    "    functions = [\n",
    "        random_coefficient() * variables[0]**2 + random_coefficient() * 2 * variables[1],            # Linear + quadratic\n",
    "        random_coefficient() * sympy.sin(variables[0]) + random_coefficient() * sympy.cos(variables[1]),  # Trigonometric functions\n",
    "        random_coefficient() * variables[0]**3 + random_coefficient() * variables[1]**2 + random_coefficient() * 3 * variables[0] * variables[1],  # Polynomial\n",
    "        random_coefficient() * variables[0]**4 + random_coefficient() * variables[1]**2 + random_coefficient() * variables[0] * variables[1],  # Quartic and product\n",
    "    ]\n",
    "    return [generate_random_function_with_tree_structure(variables, max_depth) for _ in range(num_functions)]  # Return tree-based functions\n",
    "\n",
    "# Livermore Dataset Generation\n",
    "def livermore_dataset(n=2, num_functions=10, max_depth=3):\n",
    "    \"\"\"Generate symbolic regression functions based on Livermore dataset.\"\"\"\n",
    "    variables = generate_variables(n)\n",
    "    functions = [\n",
    "        random_coefficient() * variables[0]**6 + random_coefficient() * variables[1]**4 + random_coefficient() * variables[0]**2 + random_coefficient() * 2 * variables[1],  # Polynomial\n",
    "        random_coefficient() * variables[0]**8 + random_coefficient() * variables[1]**5 + random_coefficient() * 3 * variables[0] * variables[1],  # Polynomial\n",
    "        random_coefficient() * variables[0]**3 + random_coefficient() * 5 * variables[0]**2 + random_coefficient() * variables[1]**3 + random_coefficient() * 2 * variables[0] * variables[1],  # Polynomial\n",
    "        random_coefficient() * variables[0]**5 + random_coefficient() * variables[1]**4 + random_coefficient() * 2 * variables[0] * variables[1],  # Polynomial\n",
    "        random_coefficient() * sympy.sin(variables[0]) + random_coefficient() * sympy.cos(variables[1]) + random_coefficient() * variables[0]**2,  # Trigonometric + polynomial\n",
    "    ]\n",
    "    return [generate_random_function_with_tree_structure(variables, max_depth) for _ in range(num_functions)]  # Return tree-based functions\n",
    "\n",
    "# Evaluate the dataset with relevant variables\n",
    "def evaluate_dataset_with_relevant_variables(functions, num_samples=100, range_vals=(-1, 1), noise_type='gaussian'):\n",
    "    \"\"\"Evaluate the functions with dynamic input variables and add noise, ensuring only relevant variables are considered.\"\"\"\n",
    "    dataset = []\n",
    "    \n",
    "    for func in functions:\n",
    "        data = []\n",
    "        num_vars = max([int(str(var)[1:]) for var in func.free_symbols]) + 1  # Get the highest subscript value from func.free_symbols\n",
    "        all_variables = generate_variables(num_vars)  # Generate variables from x0 to xN (including highest subscript)\n",
    "        \n",
    "        for _ in range(num_samples):\n",
    "            # Generate random values for all the variables from x0 to xN\n",
    "            inputs = {str(var): np.random.uniform(*range_vals) for var in all_variables}\n",
    "\n",
    "            # Evaluate the function using only the relevant variables (those in func.free_symbols)\n",
    "            relevant_inputs = {str(var): inputs[str(var)] for var in func.free_symbols}  # Use only relevant variables for evaluation\n",
    "            \n",
    "            try:\n",
    "                # Evaluate the function with the relevant inputs\n",
    "                result = func.evalf(subs=relevant_inputs)\n",
    "\n",
    "                # Check if the result is a real number\n",
    "                if result.is_real:\n",
    "                    output = float(result)\n",
    "                else:\n",
    "                    # If it's complex, skip or handle it (e.g., set output to NaN)\n",
    "                    logger.warning(f\"Complex result for {str(func)}: {result}. Skipping this data point.\")\n",
    "                    continue  # Skip complex results, or assign output = float('nan') if desired\n",
    "                \n",
    "                # Add noise\n",
    "                if noise_type == 'gaussian':\n",
    "                    noise = np.random.normal(0, 0.1)  # Gaussian noise with standard deviation of 0.1\n",
    "                elif noise_type == 'uniform':\n",
    "                    noise = np.random.uniform(-0.2, 0.2)  # Uniform noise in range [-0.2, 0.2]\n",
    "                else:\n",
    "                    noise = 0  # No noise\n",
    "\n",
    "                output += noise\n",
    "                data.append({\"inputs\": inputs, \"output\": output})\n",
    "\n",
    "            except (ValueError, ZeroDivisionError, OverflowError) as e:\n",
    "                logger.warning(f\"Invalid expression for {str(func)}: {e}\")\n",
    "                continue  # Skip invalid evaluations\n",
    "\n",
    "        # Convert the function to string for JSON serialization\n",
    "        dataset.append({\"function\": str(func), \"data\": data})\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# Function to combine and shuffle datasets\n",
    "def combine_and_shuffle_datasets(datasets):\n",
    "    \"\"\"Combine multiple datasets and shuffle them.\"\"\"\n",
    "    combined = []\n",
    "    for dataset in datasets:\n",
    "        combined.extend(dataset)\n",
    "    random.shuffle(combined)  # Shuffle the combined dataset to mix all datasets well\n",
    "    return combined\n",
    "\n",
    "# Save dataset to JSON file\n",
    "def save_to_json_line_by_line(data, filename):\n",
    "    \"\"\"Save data to a file in JSON format, line-by-line.\"\"\"\n",
    "    with open(filename, \"w\") as f:\n",
    "        for data_point in data:\n",
    "            json.dump(data_point, f)\n",
    "            f.write(\"\\n\")\n",
    "    return\n",
    "\n",
    "# Set the random seed (for replicability)\n",
    "seed = 20777980  # You can change this seed to any integer\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Choose the number of variables and the number of functions for each dataset\n",
    "n_variables = 5  # Set the number of variables (e.g., x0, x1, x2, ...)\n",
    "num_functions = 50  # Number of functions per dataset\n",
    "max_depth = 3  # Max depth for the function trees\n",
    "\n",
    "# Generate each dataset\n",
    "nguyen_data = nguyen_dataset_dynamic(n=n_variables, num_functions=num_functions, max_depth=max_depth)\n",
    "feynman_data = feynman_dataset(n=n_variables, num_functions=num_functions, max_depth=max_depth)\n",
    "livermore_data = livermore_dataset(n=n_variables, num_functions=num_functions, max_depth=max_depth)\n",
    "\n",
    "# Evaluate datasets\n",
    "datasets_to_combine = []\n",
    "datasets_to_combine.append(evaluate_dataset_with_relevant_variables(nguyen_data, num_samples=100, range_vals=(-1, 1), noise_type='gaussian'))\n",
    "datasets_to_combine.append(evaluate_dataset_with_relevant_variables(feynman_data, num_samples=100, range_vals=(-1, 1), noise_type='gaussian'))\n",
    "datasets_to_combine.append(evaluate_dataset_with_relevant_variables(livermore_data, num_samples=100, range_vals=(-1, 1), noise_type='gaussian'))\n",
    "\n",
    "# Combine and shuffle all datasets\n",
    "combined_data = combine_and_shuffle_datasets(datasets_to_combine)\n",
    "\n",
    "# Save to a JSON file\n",
    "save_to_json_line_by_line(combined_data, \"Data\\combined_dataset_tree.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "STAT940_Final_Project_VENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
