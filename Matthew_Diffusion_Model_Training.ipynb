{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Diffusion Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import Dataset, DataLoader, random_split\n",
    "# import random\n",
    "# import numpy as np\n",
    "# import json\n",
    "# import math\n",
    "\n",
    "# # Set the random seed for replicability\n",
    "# seed = 20777980\n",
    "# random.seed(seed)\n",
    "# np.random.seed(seed)\n",
    "# torch.manual_seed(seed)\n",
    "# if torch.cuda.is_available():\n",
    "#     torch.cuda.manual_seed(seed)\n",
    "\n",
    "# def determine_max_seq_len(data, max_length='max_length'):\n",
    "#     \"\"\"Calculate the max sequence length dynamically if 'max_length' is used as an argument.\"\"\"\n",
    "#     if max_length == 'max_length':\n",
    "#         MAX_LENGTH = max(len(dp[\"tokens\"]) for dp in data)\n",
    "#     else:\n",
    "#         MAX_LENGTH = max_length\n",
    "#     return MAX_LENGTH\n",
    "\n",
    "# def setup_device():\n",
    "#     \"\"\"Set up the device for training.\"\"\"\n",
    "#     return torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# def save_model(model, filepath):\n",
    "#     \"\"\"Save the model's state dictionary.\"\"\"\n",
    "#     torch.save(model.state_dict(), filepath)\n",
    "#     return model\n",
    "\n",
    "# def load_model(model, filepath):\n",
    "#     \"\"\"Load a saved model state dictionary.\"\"\"\n",
    "#     model.load_state_dict(torch.load(filepath))\n",
    "#     model.eval()\n",
    "#     device = setup_device()\n",
    "#     model.to(device)\n",
    "#     return model, device\n",
    "\n",
    "# def load_dataset(filepath):\n",
    "#     \"\"\"Load the dataset from a JSON file.\"\"\"\n",
    "#     with open(filepath, 'r') as file:\n",
    "#         dataset = [json.loads(line) for line in file]\n",
    "#     return dataset\n",
    "\n",
    "# def save_JSON(data, filename):\n",
    "#     \"\"\"Save data to a JSON file.\"\"\"\n",
    "#     with open(filename, 'w') as f:\n",
    "#         json.dump(data, f)\n",
    "#     return\n",
    "\n",
    "# def load_JSON(filename):\n",
    "#     \"\"\"Load a JSON file.\"\"\"\n",
    "#     with open(filename, 'r') as f:\n",
    "#         data = json.load(f)\n",
    "#     return data\n",
    "\n",
    "# class CosineNoiseSchedule:\n",
    "#     def __init__(self, timesteps=1000, epsilon=1e-6, device=None):\n",
    "#         self.timesteps = timesteps\n",
    "#         self.epsilon = epsilon\n",
    "#         self.device = device\n",
    "        \n",
    "#         # Create alphas using a cosine schedule\n",
    "#         self.alphas = torch.cos(torch.linspace(0, math.pi / 2, timesteps, device=device)) ** 2\n",
    "#         self.betas = 1.0 - self.alphas\n",
    "#         self.alpha_bar = torch.maximum(torch.cumprod(self.alphas, dim=0), torch.tensor(self.epsilon, device=self.alphas.device))\n",
    "\n",
    "#     def get_alpha(self, t):\n",
    "#         return self.alphas[t]\n",
    "\n",
    "#     def get_beta(self, t):\n",
    "#         return self.betas[t]\n",
    "\n",
    "#     def get_variance(self, t):\n",
    "#         return self.get_beta(t) * (1 - self.get_alpha(t))\n",
    "\n",
    "#     def get_alpha_bar(self, t):\n",
    "#         return self.alpha_bar[t]\n",
    "\n",
    "# class SymbolicRegressionDataset(Dataset):\n",
    "#     def __init__(self, data, vocab, max_seq_len, noise_schedule):\n",
    "#         self.data = data\n",
    "#         self.vocab = vocab  # Add vocab here\n",
    "#         self.max_seq_len = max_seq_len\n",
    "#         self.noise_schedule = noise_schedule\n",
    "\n",
    "#     def get_input_embeddings(self, tokens):\n",
    "#         embeddings = torch.stack([torch.tensor(token) for token in tokens])\n",
    "#         padded_embeddings = nn.functional.pad(embeddings, (0, self.max_seq_len - embeddings.size(0)))\n",
    "#         padded_embeddings = padded_embeddings.transpose(0,1)\n",
    "#         return padded_embeddings\n",
    "\n",
    "#     def add_noise(self, token_embeddings, t, schedule):\n",
    "#         noise_level = torch.sqrt(schedule.get_variance(t))\n",
    "#         noise = torch.normal(mean=0, std=noise_level, size=token_embeddings.shape).to(token_embeddings.device)\n",
    "#         return token_embeddings + noise\n",
    "    \n",
    "#     # def add_noise(self, token_embeddings, t, schedule):\n",
    "#     #     alpha_t = schedule.get_alpha(t)\n",
    "#     #     beta_t = schedule.get_beta(t)\n",
    "                \n",
    "#     #     noisy_embeddings = torch.sqrt(alpha_t)*token_embeddings + torch.sqrt(beta_t)*torch.randn_like(token_embeddings)\n",
    "#     #     return noisy_embeddings\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         data_point = self.data[idx]\n",
    "#         tokens = data_point['tokens']\n",
    "#         current_data = data_point['data']\n",
    "#         # Map symbols to embeddings using vocab\n",
    "#         x = torch.tensor(current_data['x'], dtype=torch.float32)\n",
    "#         y = torch.tensor(current_data['y'], dtype=torch.float32)\n",
    "#         mask = torch.tensor(current_data['mask'], dtype=torch.float32)\n",
    "#         token_embeddings = self.get_input_embeddings(tokens)\n",
    "        \n",
    "#         t = random.randint(0, self.noise_schedule.timesteps - 1)\n",
    "#         noisy_token_embeddings = self.add_noise(token_embeddings, t, self.noise_schedule)\n",
    "        \n",
    "#         noisy_x = self.add_noise(x, t, self.noise_schedule)  # Fix: using the dataset's add_noise method\n",
    "#         noisy_y = self.add_noise(y, t, self.noise_schedule)  # Fix: using the dataset's add_noise method\n",
    "        \n",
    "#         skeleton = data_point['skeleton']\n",
    "        \n",
    "#         return token_embeddings, noisy_token_embeddings, noisy_x, noisy_y, t, mask, skeleton\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "\n",
    "# class DiffusionModel(nn.Module):\n",
    "#     def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, num_heads, num_timesteps, max_seq_len=5000, pretrained_embeddings=None):\n",
    "#         super(DiffusionModel, self).__init__()\n",
    "#         self.vocab_size = vocab_size\n",
    "#         self.embedding_dim = embedding_dim\n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.num_timesteps = num_timesteps\n",
    "\n",
    "#         if pretrained_embeddings is not None:\n",
    "#             pretrained_embeddings = torch.tensor(list(pretrained_embeddings.values()), dtype=torch.float32)\n",
    "#             if pretrained_embeddings.size(1) != embedding_dim:\n",
    "#                 raise ValueError(\n",
    "#                     f\"Pretrained embeddings size {pretrained_embeddings.size(1)} does not match the required embedding_dim {embedding_dim}.\"\n",
    "#                 )\n",
    "#             self.embedding = nn.Parameter(pretrained_embeddings)\n",
    "#         else:\n",
    "#             self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "#         self.projection = nn.Linear(embedding_dim, hidden_dim) if embedding_dim != hidden_dim else nn.Identity()\n",
    "#         self.layer_norm = nn.LayerNorm(hidden_dim, eps=1e-6)\n",
    "\n",
    "#         self.transformer = nn.Transformer(\n",
    "#             d_model=hidden_dim,\n",
    "#             nhead=num_heads,\n",
    "#             num_encoder_layers=num_layers,\n",
    "#             num_decoder_layers=num_layers,\n",
    "#             batch_first=False\n",
    "#         )\n",
    "        \n",
    "#         self.fc_out = nn.Linear(hidden_dim, embedding_dim)\n",
    "\n",
    "#     def forward(self, embeddings):\n",
    "#         batch_size, hidden_dim, seq_len = embeddings.shape\n",
    "#         if self.embedding_dim != self.hidden_dim:\n",
    "#             embeddings = self.projection(embeddings)\n",
    "#         embeddings = embeddings.transpose(1, 2)\n",
    "#         embeddings = self.layer_norm(embeddings)\n",
    "#         embeddings = embeddings.transpose(0, 1)\n",
    "#         embeddings = self.transformer(embeddings, embeddings)\n",
    "#         embeddings = embeddings.transpose(0, 1)\n",
    "#         logits = self.fc_out(embeddings)\n",
    "#         logits = logits.transpose(1, 2)\n",
    "#         return logits\n",
    "\n",
    "#     def add_noise(self, token_embeddings, t, schedule):\n",
    "#         noise_level = torch.sqrt(schedule.get_variance(t))\n",
    "#         noise = torch.normal(mean=0, std=noise_level, size=token_embeddings.shape).to(token_embeddings.device)\n",
    "#         return token_embeddings + noise\n",
    "    \n",
    "#     # def add_noise(self, token_embeddings, t, schedule):\n",
    "#     #     alpha_t = schedule.get_alpha(t)\n",
    "#     #     beta_t = schedule.get_beta(t)\n",
    "                \n",
    "#     #     noisy_embeddings = torch.sqrt(alpha_t)*token_embeddings + torch.sqrt(beta_t)*torch.randn_like(token_embeddings)\n",
    "#     #     return noisy_embeddings\n",
    "    \n",
    "#     def reverse_diffusion(self, noisy_input, schedule):\n",
    "#         x_t = noisy_input\n",
    "#         device = x_t.device\n",
    "#         for t in reversed(range(self.num_timesteps)):\n",
    "#             predicted_noise = self.forward(x_t)\n",
    "#             alpha_t = schedule.get_alpha(t)\n",
    "#             beta_t = schedule.get_beta(t)\n",
    "#             mean_x_prev = (x_t - beta_t * predicted_noise) / torch.sqrt(alpha_t)\n",
    "#             if t > 0:\n",
    "#                 std_dev = torch.sqrt(beta_t)\n",
    "#                 noise = torch.randn_like(x_t, device=device) * std_dev\n",
    "#                 x_t = mean_x_prev + noise\n",
    "#             else:\n",
    "#                 x_t = mean_x_prev\n",
    "#             x_t = torch.clamp(x_t, min=-1.0, max=1.0)\n",
    "#         return x_t\n",
    "\n",
    "# def denoising_loss(predicted_embeddings, clean_embeddings):\n",
    "#     return nn.MSELoss()(predicted_embeddings, clean_embeddings)\n",
    "\n",
    "# def train_diffusion_model(model, train_loader, val_loader, num_epochs=10, patience_num_epochs=3):\n",
    "#     device = setup_device()\n",
    "#     model = model.to(device)\n",
    "#     optimizer = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)\n",
    "#     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode='min',patience=2,factor=0.5)\n",
    "#     schedule = CosineNoiseSchedule(timesteps=1000, device=device)\n",
    "\n",
    "#     best_val_loss = float('inf')\n",
    "#     num_epochs_without_improvement = 0\n",
    "#     early_stopping = False\n",
    "#     performance_metrics = {\"epoch_list\": [], \"train_loss_list\": [], \"val_loss_list\": []}\n",
    "    \n",
    "#     for epoch in range(num_epochs):\n",
    "#         model.train()\n",
    "#         total_loss = 0.0\n",
    "#         for token_embeddings, noisy_token_embeddings, x, y, t, mask, skeleton in train_loader:\n",
    "#             token_embeddings, noisy_token_embeddings, x, y, mask = token_embeddings.to(device), noisy_token_embeddings.to(device), x.to(device), y.to(device), mask.to(device)\n",
    "#             mask = mask.to(device) if mask is not None else None\n",
    "#             optimizer.zero_grad()\n",
    "#             predicted_embeddings = model(noisy_token_embeddings)\n",
    "#             loss = denoising_loss(predicted_embeddings, token_embeddings)\n",
    "#             loss.backward()\n",
    "#             torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "#             optimizer.step()\n",
    "#             total_loss += loss.item()\n",
    "        \n",
    "#         train_loss = total_loss/len(train_loader)\n",
    "#         performance_metrics['train_loss_list'].append(train_loss)\n",
    "\n",
    "#         model.eval()\n",
    "#         val_loss = 0.0\n",
    "#         with torch.no_grad():\n",
    "#             for token_embeddings, noisy_token_embeddings, x, y, t, mask, skeleton in val_loader:\n",
    "#                 token_embeddings, noisy_token_embeddings, x, y, mask = token_embeddings.to(device), noisy_token_embeddings.to(device), x.to(device), y.to(device), mask.to(device)\n",
    "#                 mask = mask.to(device) if mask is not None else None\n",
    "\n",
    "#                 # Forward pass\n",
    "#                 denoised_token_embeddings = model.reverse_diffusion(noisy_token_embeddings, schedule)\n",
    "                \n",
    "#                 # Compute loss\n",
    "#                 loss = denoising_loss(denoised_token_embeddings, token_embeddings)\n",
    "#                 val_loss += loss.item()\n",
    "        \n",
    "#         val_loss = val_loss / len(val_loader)\n",
    "#         performance_metrics['val_loss_list'].append(val_loss)\n",
    "#         performance_metrics['epoch_list'].append(epoch + 1)\n",
    "\n",
    "#         print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss}, Val Loss: {val_loss}')\n",
    "\n",
    "#         scheduler.step(val_loss)\n",
    "\n",
    "#         if val_loss < best_val_loss:\n",
    "#             best_val_loss = val_loss\n",
    "#             save_model(model, \"Data/best_diffusion_model.pt\")\n",
    "#             num_epochs_without_improvement = 0\n",
    "#         else:\n",
    "#             num_epochs_without_improvement += 1\n",
    "\n",
    "#         if num_epochs_without_improvement >= patience_num_epochs:\n",
    "#             print(f\"Training stopped early at epoch {epoch + 1}. Best validation loss: {best_val_loss}\")\n",
    "#             early_stopping = True\n",
    "#             break\n",
    "        \n",
    "#     if early_stopping == False:\n",
    "#         save_model(model, \"Data/best_diffusion_model.pt\")\n",
    "\n",
    "#     return model, performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example of loading and preparing the dataset\n",
    "# dataset = load_dataset('Data/preprocessed_data_with_embeddings.json')\n",
    "# vocab = load_JSON(\"Data/vocab_embeddings.json\")  # Vocabulary is a dictionary of continuous embeddings\n",
    "\n",
    "# MAX_LENGTH = determine_max_seq_len(dataset)  # Determine the max length dynamically\n",
    "\n",
    "# schedule = CosineNoiseSchedule(timesteps=1000,device=setup_device())\n",
    "\n",
    "# # First, perform the split on the raw dataset\n",
    "# train_size = int(0.7*len(dataset))  # 70% for training\n",
    "# val_size = int(0.15*len(dataset))  # 15% for validation\n",
    "# test_size = len(dataset) - train_size - val_size  # 15% for testing\n",
    "\n",
    "# # Perform random split\n",
    "# train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# train_dataset_SR = SymbolicRegressionDataset(train_dataset, vocab, MAX_LENGTH, schedule)\n",
    "# val_dataset_SR = SymbolicRegressionDataset(val_dataset, vocab, MAX_LENGTH, schedule)\n",
    "# test_dataset_SR = SymbolicRegressionDataset(test_dataset, vocab, MAX_LENGTH, schedule)\n",
    "\n",
    "# # Create DataLoader objects for each subset\n",
    "# train_loader = DataLoader(train_dataset_SR, batch_size=16, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset_SR, batch_size=16, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset_SR, batch_size=16, shuffle=True)\n",
    "\n",
    "# # Initialize the model\n",
    "# num_heads = 4  # Number of attention heads, ensure this is a divisor of embedding_dim\n",
    "# embedding_dim = 100  # The embedding dimension is 100 as per your problem\n",
    "# hidden_dim = embedding_dim  # Hidden dimension stays the same for simplicity\n",
    "\n",
    "# # Ensure embedding_dim is divisible by num_heads\n",
    "# if embedding_dim % num_heads != 0:\n",
    "#     raise ValueError(f\"embedding_dim ({embedding_dim}) must be divisible by num_heads ({num_heads}).\")\n",
    "\n",
    "# model = DiffusionModel(\n",
    "#     vocab_size=len(vocab),\n",
    "#     embedding_dim=embedding_dim,\n",
    "#     hidden_dim=hidden_dim,\n",
    "#     num_layers=4,\n",
    "#     num_heads=4,\n",
    "#     num_timesteps=1000,\n",
    "#     pretrained_embeddings=vocab\n",
    "# )\n",
    "\n",
    "# model,performance_metrics_DICT = train_diffusion_model(model,train_loader,val_loader,num_epochs=10,patience_num_epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# #Visualize the train and validation loss\n",
    "# def plot_train_valid(model_name,performance_metrics_DICT):\n",
    "#     plt.figure();\n",
    "#     plt.plot(performance_metrics_DICT['epoch_list'], performance_metrics_DICT['train_loss_list'], label=f'Train Loss', color='blue', linestyle='--', marker='o');\n",
    "#     plt.plot(performance_metrics_DICT['epoch_list'], performance_metrics_DICT['val_loss_list'], label=f'Validation Loss', color='green', linestyle='-', marker='x');\n",
    "#     plt.title(f'{model_name} Training and Validation Loss');\n",
    "#     plt.xlabel('Epochs');\n",
    "#     plt.ylabel('Loss');\n",
    "#     plt.legend();\n",
    "#     plt.grid();\n",
    "#     plt.xlim(0,max(performance_metrics_DICT['epoch_list'])+1);\n",
    "#     return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'Diffusion Model'\n",
    "\n",
    "# plot_train_valid(model_name,performance_metrics_DICT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def decode_embeddings_to_tokens(embeddings, vocab):\n",
    "#     batch_size, embedding_dim, seq_length = embeddings.shape\n",
    "#     vocab_embeddings = torch.stack([torch.tensor(embed) for embed in vocab.values()])  # Shape: [embedding_dim, num_symbols]\n",
    "\n",
    "#     # Reshape vocab_embeddings to shape: [num_symbols, embedding_dim] for broadcasting    \n",
    "#     # Compute the pairwise distance between each embedding in the sequence and all vocab embeddings\n",
    "#     # embeddings: [batch_size, embedding_dim, seq_length]\n",
    "#     # vocab_embeddings: [num_symbols, embedding_dim]\n",
    "    \n",
    "#     # To compute pairwise distances, we need to reshape embeddings to [batch_size * seq_length, embedding_dim]\n",
    "#     embeddings_flattened = embeddings.view(batch_size * seq_length, embedding_dim)\n",
    "    \n",
    "#     # Compute pairwise distances using cdist (shape: [batch_size * seq_length, num_symbols])\n",
    "#     distances = torch.cdist(embeddings_flattened, vocab_embeddings)  # Shape: [batch_size * seq_length, num_symbols]\n",
    "\n",
    "#     # Reshape distances back to [batch_size, seq_length, num_symbols]\n",
    "#     distances = distances.view(batch_size, seq_length, -1)\n",
    "    \n",
    "#     # Find the index of the closest token for each position in the sequence\n",
    "#     closest_token_indices = torch.argmin(distances, dim=-1)  # Shape: [batch_size, seq_length]\n",
    "    \n",
    "#     # Convert indices to tokens\n",
    "#     decoded_tokens = []\n",
    "#     for batch_idx in range(batch_size):\n",
    "#         tokens = [list(vocab.keys())[idx.item()] for idx in closest_token_indices[batch_idx]]\n",
    "#         decoded_tokens.append(tokens)\n",
    "\n",
    "#     return decoded_tokens\n",
    "\n",
    "# def evaluate_diffusion_model(model, test_loader, vocab, schedule, device):\n",
    "#     model.eval()  # Set the model to evaluation mode\n",
    "#     total_test_loss = 0.0\n",
    "#     decoded_formulas = []\n",
    "#     actual_formulas = []\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for token_embeddings, noisy_token_embeddings, x, y, t, mask, skeleton_list in test_loader:\n",
    "#             token_embeddings, noisy_token_embeddings, x, y, mask = token_embeddings.to(device), noisy_token_embeddings.to(device), x.to(device), y.to(device), mask.to(device)\n",
    "#             # Get the predicted denoised embeddings\n",
    "#             t = random.randint(0, model.num_timesteps - 1)  # Random timestep for diffusion\n",
    "#             pred_embeddings = model.reverse_diffusion(noisy_token_embeddings, schedule)\n",
    "\n",
    "#             # Calculate the loss (MSE between predicted and target embeddings)\n",
    "#             loss = denoising_loss(pred_embeddings, noisy_token_embeddings)\n",
    "#             total_test_loss += loss.item()\n",
    "\n",
    "#             # Now, we need to decode the denoised embeddings back to tokens\n",
    "#             decoded_tokens_list = decode_embeddings_to_tokens(pred_embeddings, vocab)\n",
    "\n",
    "#             # Convert the decoded tokens to a formula string\n",
    "#             predicted_formula = [\"\".join(decoded_tokens).replace('<PAD>', '').replace('+', ' + ') for decoded_tokens in decoded_tokens_list]\n",
    "#             decoded_formulas.append(predicted_formula)\n",
    "\n",
    "#             # Assuming target embeddings have a corresponding ground truth formula (you can adjust this part)\n",
    "#             actual_formula = list(skeleton_list)\n",
    "#             actual_formulas.append(actual_formula)\n",
    "\n",
    "#     # Calculate average test loss\n",
    "#     avg_test_loss = total_test_loss / len(test_loader)\n",
    "#     return avg_test_loss, decoded_formulas, actual_formulas\n",
    "\n",
    "# # Example of loading and preparing the dataset\n",
    "# dataset = load_dataset('Data/preprocessed_data_with_embeddings.json')\n",
    "# vocab = load_JSON(\"Data/vocab_embeddings.json\")  # Vocabulary is a dictionary of continuous embeddings\n",
    "\n",
    "# MAX_LENGTH = determine_max_seq_len(dataset)  # Determine the max length dynamically\n",
    "\n",
    "# schedule = CosineNoiseSchedule(timesteps=1000,device=setup_device())\n",
    "\n",
    "# # First, perform the split on the raw dataset\n",
    "# train_size = int(0.7*len(dataset))  # 70% for training\n",
    "# val_size = int(0.15*len(dataset))  # 15% for validation\n",
    "# test_size = len(dataset) - train_size - val_size  # 15% for testing\n",
    "\n",
    "# # Perform random split\n",
    "# train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# train_dataset_SR = SymbolicRegressionDataset(train_dataset, vocab, MAX_LENGTH, schedule)\n",
    "# val_dataset_SR = SymbolicRegressionDataset(val_dataset, vocab, MAX_LENGTH, schedule)\n",
    "# test_dataset_SR = SymbolicRegressionDataset(test_dataset, vocab, MAX_LENGTH, schedule)\n",
    "\n",
    "# # Create DataLoader objects for each subset\n",
    "# train_loader = DataLoader(train_dataset_SR, batch_size=16, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset_SR, batch_size=16, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset_SR, batch_size=16, shuffle=True)\n",
    "\n",
    "# # Initialize the model\n",
    "# num_heads = 4  # Number of attention heads, ensure this is a divisor of embedding_dim\n",
    "# embedding_dim = 100  # The embedding dimension is 100 as per your problem\n",
    "# hidden_dim = embedding_dim  # Hidden dimension stays the same for simplicity\n",
    "\n",
    "# # Ensure embedding_dim is divisible by num_heads\n",
    "# if embedding_dim % num_heads != 0:\n",
    "#     raise ValueError(f\"embedding_dim ({embedding_dim}) must be divisible by num_heads ({num_heads}).\")\n",
    "\n",
    "# model = DiffusionModel(\n",
    "#     vocab_size=len(vocab),\n",
    "#     embedding_dim=embedding_dim,\n",
    "#     hidden_dim=hidden_dim,\n",
    "#     num_layers=4,\n",
    "#     num_heads=4,\n",
    "#     num_timesteps=1000,\n",
    "#     pretrained_embeddings=vocab\n",
    "# )\n",
    "\n",
    "# # Example: Evaluate the model on the test set\n",
    "# model, device = load_model(model, \"Data/best_diffusion_model.pt\")\n",
    "# test_loss, decoded_formulas, actual_formulas = evaluate_diffusion_model(model, test_loader, vocab, schedule, device)\n",
    "\n",
    "# # Print out the average test loss\n",
    "# print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "# # Print out the first few decoded formulas and their corresponding actual formulas\n",
    "# for predicted, actual in zip(decoded_formulas[:5], actual_formulas[:5]):\n",
    "#     print(f\"Predicted Formula: {predicted}\")\n",
    "#     print(f\"Actual Formula: {actual}\")\n",
    "#     print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternate Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "\n",
    "# Set the random seed for replicability\n",
    "seed = 20777980\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "def determine_max_seq_len(data, max_length='max_length'):\n",
    "    \"\"\"Calculate the max sequence length dynamically if 'max_length' is used as an argument.\"\"\"\n",
    "    if max_length == 'max_length':\n",
    "        MAX_LENGTH = max(len(dp[\"tokens\"]) for dp in data)\n",
    "    else:\n",
    "        MAX_LENGTH = max_length\n",
    "    return MAX_LENGTH\n",
    "\n",
    "def setup_device():\n",
    "    \"\"\"Set up the device for training.\"\"\"\n",
    "    return torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def save_model(model, filepath):\n",
    "    \"\"\"Save the model's state dictionary.\"\"\"\n",
    "    torch.save(model.state_dict(), filepath)\n",
    "    return model\n",
    "\n",
    "def load_model(model, filepath):\n",
    "    \"\"\"Load a saved model state dictionary.\"\"\"\n",
    "    model.load_state_dict(torch.load(filepath))\n",
    "    model.eval()\n",
    "    device = setup_device()\n",
    "    model.to(device)\n",
    "    return model, device\n",
    "\n",
    "def load_dataset(filepath):\n",
    "    \"\"\"Load the dataset from a JSON file.\"\"\"\n",
    "    with open(filepath, 'r') as file:\n",
    "        dataset = [json.loads(line) for line in file]\n",
    "    return dataset\n",
    "\n",
    "def load_dataset_torch(filepath):\n",
    "    loaded_data = torch.load(filepath)\n",
    "    formula_embeddings = loaded_data['formula_embeddings']\n",
    "    dataset_embeddings = loaded_data['dataset_embeddings']\n",
    "    return formula_embeddings,dataset_embeddings\n",
    "\n",
    "def save_JSON(data, filename):\n",
    "    \"\"\"Save data to a JSON file.\"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "    return\n",
    "\n",
    "def load_JSON(filename):\n",
    "    \"\"\"Load a JSON file.\"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "class CosineNoiseSchedule:\n",
    "    def __init__(self, timesteps=1000, epsilon=1e-6, device=None):\n",
    "        self.timesteps = timesteps\n",
    "        self.epsilon = epsilon\n",
    "        self.device = device\n",
    "        \n",
    "        # Create alphas using a cosine schedule\n",
    "        self.alphas = torch.cos(torch.linspace(0, math.pi / 2, timesteps, device=device)) ** 2\n",
    "        self.betas = 1.0 - self.alphas\n",
    "        self.alpha_bar = torch.maximum(torch.cumprod(self.alphas, dim=0), torch.tensor(self.epsilon, device=self.alphas.device))\n",
    "\n",
    "    def get_alpha(self, t):\n",
    "        return self.alphas[t]\n",
    "\n",
    "    def get_beta(self, t):\n",
    "        return self.betas[t]\n",
    "\n",
    "    def get_variance(self, t):\n",
    "        return self.get_beta(t) * (1 - self.get_alpha(t))\n",
    "\n",
    "    def get_alpha_bar(self, t):\n",
    "        return self.alpha_bar[t]\n",
    "\n",
    "class SymbolicRegressionDataset(Dataset):\n",
    "    def __init__(self, data, vocab, max_seq_len, noise_schedule):\n",
    "        self.data = data\n",
    "        self.vocab = vocab  # Add vocab here\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.noise_schedule = noise_schedule\n",
    "\n",
    "    def get_input_embeddings(self, tokens):\n",
    "        embeddings = torch.stack([torch.tensor(token) for token in tokens])\n",
    "        padded_embeddings = nn.functional.pad(embeddings, (0, self.max_seq_len - embeddings.size(0)))\n",
    "        padded_embeddings = padded_embeddings.transpose(0,1)\n",
    "        return padded_embeddings\n",
    "\n",
    "    def add_noise(self, token_embeddings, t, schedule):\n",
    "        noise_level = torch.sqrt(schedule.get_variance(t))\n",
    "        noise = torch.normal(mean=0, std=noise_level, size=token_embeddings.shape).to(token_embeddings.device)\n",
    "        return token_embeddings + noise\n",
    "    \n",
    "    # def add_noise(self, token_embeddings, t, schedule):\n",
    "    #     alpha_t = schedule.get_alpha(t)\n",
    "    #     beta_t = schedule.get_beta(t)\n",
    "                \n",
    "    #     noisy_embeddings = torch.sqrt(alpha_t)*token_embeddings + torch.sqrt(beta_t)*torch.randn_like(token_embeddings)\n",
    "    #     return noisy_embeddings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_point = self.data[idx]\n",
    "        tokens = data_point['tokens']\n",
    "        current_data = data_point['data']\n",
    "        # Map symbols to embeddings using vocab\n",
    "        x = torch.tensor(current_data['x'], dtype=torch.float32)\n",
    "        y = torch.tensor(current_data['y'], dtype=torch.float32)\n",
    "        mask = torch.tensor(current_data['mask'], dtype=torch.float32)\n",
    "        token_embeddings = self.get_input_embeddings(tokens)\n",
    "        \n",
    "        t = random.randint(0, self.noise_schedule.timesteps - 1)\n",
    "        noisy_token_embeddings = self.add_noise(token_embeddings, t, self.noise_schedule)\n",
    "        \n",
    "        noisy_x = self.add_noise(x, t, self.noise_schedule)  # Fix: using the dataset's add_noise method\n",
    "        noisy_y = self.add_noise(y, t, self.noise_schedule)  # Fix: using the dataset's add_noise method\n",
    "        \n",
    "        skeleton = data_point['skeleton']\n",
    "        \n",
    "        return token_embeddings, noisy_token_embeddings, noisy_x, noisy_y, t, mask, skeleton\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "class DiffusionModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, num_heads, num_timesteps, max_seq_len=5000, pretrained_embeddings=None):\n",
    "        super(DiffusionModel, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_timesteps = num_timesteps\n",
    "\n",
    "        if pretrained_embeddings is not None:\n",
    "            pretrained_embeddings = torch.tensor(list(pretrained_embeddings.values()), dtype=torch.float32)\n",
    "            if pretrained_embeddings.size(1) != embedding_dim:\n",
    "                raise ValueError(\n",
    "                    f\"Pretrained embeddings size {pretrained_embeddings.size(1)} does not match the required embedding_dim {embedding_dim}.\"\n",
    "                )\n",
    "            self.embedding = nn.Parameter(pretrained_embeddings)\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        self.projection = nn.Linear(embedding_dim, hidden_dim) if embedding_dim != hidden_dim else nn.Identity()\n",
    "        self.layer_norm = nn.LayerNorm(hidden_dim, eps=1e-6)\n",
    "\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=hidden_dim,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_layers,\n",
    "            num_decoder_layers=num_layers,\n",
    "            batch_first=False\n",
    "        )\n",
    "        \n",
    "        self.fc_out = nn.Linear(hidden_dim, embedding_dim)\n",
    "\n",
    "    def forward(self, embeddings):\n",
    "        batch_size, hidden_dim, seq_len = embeddings.shape\n",
    "        if self.embedding_dim != self.hidden_dim:\n",
    "            embeddings = self.projection(embeddings)\n",
    "        embeddings = embeddings.transpose(1, 2)\n",
    "        embeddings = self.layer_norm(embeddings)\n",
    "        embeddings = embeddings.transpose(0, 1)\n",
    "        embeddings = self.transformer(embeddings, embeddings)\n",
    "        embeddings = embeddings.transpose(0, 1)\n",
    "        logits = self.fc_out(embeddings)\n",
    "        logits = logits.transpose(1, 2)\n",
    "        return logits\n",
    "\n",
    "    def add_noise(self, token_embeddings, t, schedule):\n",
    "        noise_level = torch.sqrt(schedule.get_variance(t))\n",
    "        noise = torch.normal(mean=0, std=noise_level, size=token_embeddings.shape).to(token_embeddings.device)\n",
    "        return token_embeddings + noise\n",
    "    \n",
    "    # def add_noise(self, token_embeddings, t, schedule):\n",
    "    #     alpha_t = schedule.get_alpha(t)\n",
    "    #     beta_t = schedule.get_beta(t)\n",
    "                \n",
    "    #     noisy_embeddings = torch.sqrt(alpha_t)*token_embeddings + torch.sqrt(beta_t)*torch.randn_like(token_embeddings)\n",
    "    #     return noisy_embeddings\n",
    "    \n",
    "    def reverse_diffusion(self, noisy_input, schedule):\n",
    "        x_t = noisy_input\n",
    "        device = x_t.device\n",
    "        for t in reversed(range(self.num_timesteps)):\n",
    "            predicted_noise = self.forward(x_t)\n",
    "            alpha_t = schedule.get_alpha(t)\n",
    "            beta_t = schedule.get_beta(t)\n",
    "            mean_x_prev = (x_t - beta_t * predicted_noise) / torch.sqrt(alpha_t)\n",
    "            if t > 0:\n",
    "                std_dev = torch.sqrt(beta_t)\n",
    "                noise = torch.randn_like(x_t, device=device) * std_dev\n",
    "                x_t = mean_x_prev + noise\n",
    "            else:\n",
    "                x_t = mean_x_prev\n",
    "            x_t = torch.clamp(x_t, min=-1.0, max=1.0)\n",
    "        return x_t\n",
    "\n",
    "def denoising_loss(predicted_embeddings, clean_embeddings):\n",
    "    return nn.MSELoss()(predicted_embeddings, clean_embeddings)\n",
    "\n",
    "def train_diffusion_model(model, train_loader, val_loader, num_epochs=10, patience_num_epochs=3):\n",
    "    device = setup_device()\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode='min',patience=2,factor=0.5)\n",
    "    schedule = CosineNoiseSchedule(timesteps=1000, device=device)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    num_epochs_without_improvement = 0\n",
    "    early_stopping = False\n",
    "    performance_metrics = {\"epoch_list\": [], \"train_loss_list\": [], \"val_loss_list\": []}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for token_embeddings, noisy_token_embeddings, x, y, t, mask, skeleton in train_loader:\n",
    "            token_embeddings, noisy_token_embeddings, x, y, mask = token_embeddings.to(device), noisy_token_embeddings.to(device), x.to(device), y.to(device), mask.to(device)\n",
    "            mask = mask.to(device) if mask is not None else None\n",
    "            optimizer.zero_grad()\n",
    "            predicted_embeddings = model(noisy_token_embeddings)\n",
    "            loss = denoising_loss(predicted_embeddings, token_embeddings)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        train_loss = total_loss/len(train_loader)\n",
    "        performance_metrics['train_loss_list'].append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for token_embeddings, noisy_token_embeddings, x, y, t, mask, skeleton in val_loader:\n",
    "                token_embeddings, noisy_token_embeddings, x, y, mask = token_embeddings.to(device), noisy_token_embeddings.to(device), x.to(device), y.to(device), mask.to(device)\n",
    "                mask = mask.to(device) if mask is not None else None\n",
    "\n",
    "                # Forward pass\n",
    "                denoised_token_embeddings = model.reverse_diffusion(noisy_token_embeddings, schedule)\n",
    "                \n",
    "                # Compute loss\n",
    "                loss = denoising_loss(denoised_token_embeddings, token_embeddings)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        performance_metrics['val_loss_list'].append(val_loss)\n",
    "        performance_metrics['epoch_list'].append(epoch + 1)\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss}, Val Loss: {val_loss}')\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            save_model(model, \"Data/best_diffusion_model.pt\")\n",
    "            num_epochs_without_improvement = 0\n",
    "        else:\n",
    "            num_epochs_without_improvement += 1\n",
    "\n",
    "        if num_epochs_without_improvement >= patience_num_epochs:\n",
    "            print(f\"Training stopped early at epoch {epoch + 1}. Best validation loss: {best_val_loss}\")\n",
    "            early_stopping = True\n",
    "            break\n",
    "        \n",
    "    if early_stopping == False:\n",
    "        save_model(model, \"Data/best_diffusion_model.pt\")\n",
    "\n",
    "    return model, performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of loading and preparing the dataset\n",
    "dataset = load_dataset('Data/preprocessed_data_with_embeddings.json')\n",
    "vocab = load_JSON(\"Data/vocab_embeddings.json\")  # Vocabulary is a dictionary of continuous embeddings\n",
    "\n",
    "MAX_LENGTH = determine_max_seq_len(dataset)  # Determine the max length dynamically\n",
    "\n",
    "schedule = CosineNoiseSchedule(timesteps=1000,device=setup_device())\n",
    "\n",
    "# First, perform the split on the raw dataset\n",
    "train_size = int(0.7*len(dataset))  # 70% for training\n",
    "val_size = int(0.15*len(dataset))  # 15% for validation\n",
    "test_size = len(dataset) - train_size - val_size  # 15% for testing\n",
    "\n",
    "# Perform random split\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_dataset_SR = SymbolicRegressionDataset(train_dataset, vocab, MAX_LENGTH, schedule)\n",
    "val_dataset_SR = SymbolicRegressionDataset(val_dataset, vocab, MAX_LENGTH, schedule)\n",
    "test_dataset_SR = SymbolicRegressionDataset(test_dataset, vocab, MAX_LENGTH, schedule)\n",
    "\n",
    "# Create DataLoader objects for each subset\n",
    "train_loader = DataLoader(train_dataset_SR, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset_SR, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset_SR, batch_size=16, shuffle=True)\n",
    "\n",
    "# Initialize the model\n",
    "num_heads = 4  # Number of attention heads, ensure this is a divisor of embedding_dim\n",
    "embedding_dim = 100  # The embedding dimension is 100 as per your problem\n",
    "hidden_dim = embedding_dim  # Hidden dimension stays the same for simplicity\n",
    "\n",
    "# Ensure embedding_dim is divisible by num_heads\n",
    "if embedding_dim % num_heads != 0:\n",
    "    raise ValueError(f\"embedding_dim ({embedding_dim}) must be divisible by num_heads ({num_heads}).\")\n",
    "\n",
    "model = DiffusionModel(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_layers=4,\n",
    "    num_heads=4,\n",
    "    num_timesteps=1000,\n",
    "    pretrained_embeddings=vocab\n",
    ")\n",
    "\n",
    "model,performance_metrics_DICT = train_diffusion_model(model,train_loader,val_loader,num_epochs=10,patience_num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_formulas = 100\n",
    "max_seq_len = 20\n",
    "embedding_dim = 128\n",
    "\n",
    "# Token embeddings (for formulas) - Example data\n",
    "tokens = torch.randn(num_formulas, max_seq_len, embedding_dim)  # [num_formulas, seq_len, embedding_dim]\n",
    "\n",
    "# Example mask for formula tokens (1 for valid token, 0 for padding)\n",
    "token_mask = torch.randint(0, 2, (num_formulas, max_seq_len))  # [num_formulas, seq_len]\n",
    "\n",
    "# Example dataset features x (with NaN values) for 100 samples and 5 variables\n",
    "x = torch.tensor([\n",
    "    [-0.45891708, -0.33787646, np.nan, np.nan, np.nan],\n",
    "    [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "])  # [num_samples, num_vars]\n",
    "\n",
    "# Replace NaN with 0 (or another placeholder if needed)\n",
    "x = torch.nan_to_num(x, nan=0.0)  # Handle NaN values in x\n",
    "\n",
    "# Step 3: Apply Mask to Tokenized Formula Embeddings\n",
    "\n",
    "# Step 4: Pass Tokenized Formula Embeddings and Dataset Features Through TNet\n",
    "\n",
    "# Initialize TNet with configuration\n",
    "config_tokens = tNetConfig(num_vars=tokens.shape[1], embedding_size=128)  # num_vars = number of dataset features, embedding_size = 256\n",
    "tnet_tokens = tNet(config_tokens)\n",
    "\n",
    "config_data = tNetConfig(num_vars=x.shape[1], embedding_size=128)  # num_vars = number of dataset features, embedding_size = 256\n",
    "tnet_data = tNet(config_data)\n",
    "\n",
    "# Reshape inputs for TNet (Conv1D expects [batch_size, num_features, seq_len])\n",
    "masked_tokens = tokens  # [num_formulas, embedding_dim, seq_len]\n",
    "masked_x = x.unsqueeze(0).transpose(2,1)\n",
    "\n",
    "# Pass token embeddings and dataset features through TNet\n",
    "formula_embeddings = tnet_tokens(masked_tokens)  # Shape: [num_formulas, embedding_size]\n",
    "dataset_embeddings = tnet_data(masked_x)  # Shape: [batch_size, embedding_size]\n",
    "\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "STAT940_Final_Project_VENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
