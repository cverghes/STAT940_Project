{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Diffusion Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.23779887557029725, Val Loss: 0.4486483931541443\n",
      "Epoch 2/100, Train Loss: 0.10243501961231231, Val Loss: 0.4412689507007599\n",
      "Epoch 3/100, Train Loss: 0.059051104635000226, Val Loss: 0.43448907136917114\n",
      "Epoch 4/100, Train Loss: 0.03806477934122086, Val Loss: 0.42765307426452637\n",
      "Epoch 5/100, Train Loss: 0.028167488798499108, Val Loss: 0.42596903443336487\n",
      "Epoch 6/100, Train Loss: 0.023289132118225097, Val Loss: 0.4268840551376343\n",
      "Epoch 7/100, Train Loss: 0.02140187583863735, Val Loss: 0.42439475655555725\n",
      "Epoch 8/100, Train Loss: 0.019652978330850602, Val Loss: 0.4292699992656708\n",
      "Epoch 9/100, Train Loss: 0.01858958601951599, Val Loss: 0.42538952827453613\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "from torch.nn import functional as F\n",
    "from dataclasses import dataclass\n",
    "import pdb\n",
    "\n",
    "# Set the random seed for replicability\n",
    "seed = 940\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "def determine_max_seq_len(data, max_length='max_length'):\n",
    "    \"\"\"Calculate the max sequence length dynamically if 'max_length' is used as an argument.\"\"\"\n",
    "    if max_length == 'max_length':\n",
    "        MAX_LENGTH = max(len(dp[\"tokens\"]) for dp in data)\n",
    "    else:\n",
    "        MAX_LENGTH = max_length\n",
    "    return MAX_LENGTH\n",
    "\n",
    "def setup_device():\n",
    "    \"\"\"Set up the device for training.\"\"\"\n",
    "    return torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def save_model(model, filepath):\n",
    "    \"\"\"Save the model's state dictionary.\"\"\"\n",
    "    torch.save(model.state_dict(), filepath)\n",
    "    return model\n",
    "\n",
    "def load_model(model, filepath):\n",
    "    \"\"\"Load a saved model state dictionary.\"\"\"\n",
    "    model.load_state_dict(torch.load(filepath))\n",
    "    model.eval()\n",
    "    device = setup_device()\n",
    "    model.to(device)\n",
    "    return model, device\n",
    "\n",
    "def load_dataset(filepath):\n",
    "    \"\"\"Load the dataset from a JSON file.\"\"\"\n",
    "    with open(filepath, 'r') as file:\n",
    "        dataset = [json.loads(line) for line in file]\n",
    "    return dataset\n",
    "\n",
    "def save_JSON(data, filename):\n",
    "    \"\"\"Save data to a JSON file.\"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "    return\n",
    "\n",
    "def load_JSON(filename):\n",
    "    \"\"\"Load a JSON file.\"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "@dataclass\n",
    "class tNetConfig:\n",
    "    num_vars: int\n",
    "    embedding_size: int\n",
    "\n",
    "class tNet(nn.Module):\n",
    "    def __init__(self, config: tNetConfig):\n",
    "        super(tNet, self).__init__()\n",
    "\n",
    "        self.config = config\n",
    "        self.num_vars = config.num_vars\n",
    "        self.n_embd = config.embedding_size\n",
    "\n",
    "        self.activation_func = F.relu\n",
    "\n",
    "        # Define the convolutional layers\n",
    "        self.conv1 = nn.Conv1d(self.num_vars, self.n_embd, 1)\n",
    "        self.conv2 = nn.Conv1d(self.n_embd, 2*self.n_embd, 1)\n",
    "        self.conv3 = nn.Conv1d(2*self.n_embd, 4*self.n_embd, 1)\n",
    "\n",
    "        # Define fully connected layers\n",
    "        self.fc1 = nn.Linear(4*self.n_embd, 2*self.n_embd)\n",
    "        self.fc2 = nn.Linear(2*self.n_embd, self.n_embd)\n",
    "\n",
    "        # Corrected GroupNorm initialization\n",
    "        self.input_batch_norm = nn.GroupNorm(1, self.num_vars)  # Corrected to match input channels\n",
    "        \n",
    "        # Define other GroupNorm layers\n",
    "        self.bn1 = nn.GroupNorm(1, self.n_embd)\n",
    "        self.bn2 = nn.GroupNorm(1, 2*self.n_embd)\n",
    "        self.bn3 = nn.GroupNorm(1, 4*self.n_embd)\n",
    "        self.bn4 = nn.GroupNorm(1, 2*self.n_embd)\n",
    "        self.bn5 = nn.GroupNorm(1, self.n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply normalization and convolutions\n",
    "        x = self.input_batch_norm(x)\n",
    "        x = self.activation_func(self.bn1(self.conv1(x)))\n",
    "        x = self.activation_func(self.bn2(self.conv2(x)))\n",
    "        x = self.activation_func(self.bn3(self.conv3(x)))\n",
    "\n",
    "        # Global max pooling\n",
    "        x, _ = torch.max(x, dim=2)  # Reducing along the sequence dimension (index 2)\n",
    "        assert x.size(1) == 4*self.n_embd  # Ensure correct output size\n",
    "\n",
    "        # Apply fully connected layers\n",
    "        x = self.activation_func(self.bn4(self.fc1(x)))\n",
    "        x = self.activation_func(self.bn5(self.fc2(x)))\n",
    "        return x\n",
    "\n",
    "class CosineNoiseSchedule:\n",
    "    def __init__(self, timesteps=1000, epsilon=1e-6, device=None):\n",
    "        self.timesteps = timesteps\n",
    "        self.epsilon = epsilon\n",
    "        self.device = device\n",
    "        \n",
    "        # Create alphas using a cosine schedule\n",
    "        self.alphas = torch.cos(torch.linspace(0, math.pi / 2, timesteps, device=device)) ** 2\n",
    "        self.betas = 1.0 - self.alphas\n",
    "        self.alpha_bar = torch.maximum(torch.cumprod(self.alphas, dim=0), torch.tensor(self.epsilon, device=self.alphas.device))\n",
    "\n",
    "    def get_alpha(self, t):\n",
    "        return self.alphas[t]\n",
    "\n",
    "    def get_beta(self, t):\n",
    "        return self.betas[t]\n",
    "\n",
    "    def get_variance(self, t):\n",
    "        return self.get_beta(t) * (1 - self.get_alpha(t))\n",
    "\n",
    "    def get_alpha_bar(self, t):\n",
    "        return self.alpha_bar[t]\n",
    "\n",
    "class SymbolicRegressionDataset(Dataset):\n",
    "    def __init__(self, data, vocab, max_seq_len, noise_schedule):\n",
    "        self.data = data\n",
    "        self.vocab = vocab  # Add vocab here\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.noise_schedule = noise_schedule\n",
    "\n",
    "    def get_input_embeddings(self, tokens):\n",
    "        embeddings = torch.stack([torch.tensor(token) for token in tokens])\n",
    "        padded_embeddings = nn.functional.pad(embeddings, (0, self.max_seq_len - embeddings.size(0)))\n",
    "        padded_embeddings = padded_embeddings.transpose(0,1)\n",
    "        return padded_embeddings\n",
    "    \n",
    "    def add_noise(self, token_embeddings, t, schedule):\n",
    "        alpha_t = schedule.get_alpha(t)\n",
    "        beta_t = schedule.get_beta(t)\n",
    "                \n",
    "        noisy_embeddings = torch.sqrt(alpha_t)*token_embeddings + torch.sqrt(beta_t)*torch.randn_like(token_embeddings)\n",
    "        return noisy_embeddings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_point = self.data[idx]\n",
    "        tokens = data_point['tokens']\n",
    "        current_data = data_point['data']\n",
    "        # Map symbols to embeddings using vocab\n",
    "        x = torch.tensor(current_data['x'], dtype=torch.float32)\n",
    "        y = torch.tensor(current_data['y'], dtype=torch.float32)\n",
    "        mask = torch.tensor(current_data['mask'], dtype=torch.float32)\n",
    "        token_embeddings = self.get_input_embeddings(tokens)\n",
    "        \n",
    "        t = random.randint(0, self.noise_schedule.timesteps - 1)\n",
    "        noisy_token_embeddings = self.add_noise(token_embeddings, t, self.noise_schedule)\n",
    "        \n",
    "        noisy_x = self.add_noise(x, t, self.noise_schedule)  # Fix: using the dataset's add_noise method\n",
    "        noisy_y = self.add_noise(y, t, self.noise_schedule)  # Fix: using the dataset's add_noise method\n",
    "        \n",
    "        skeleton = data_point['skeleton']\n",
    "        \n",
    "        return token_embeddings, noisy_token_embeddings, noisy_x, noisy_y, t, mask, skeleton\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "class DiffusionModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, num_heads, num_timesteps, max_seq_len=5000, pretrained_embeddings=None, tnet_config=None):\n",
    "        super(DiffusionModel, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.tnet = tNet(tnet_config) if tnet_config is not None else None\n",
    "\n",
    "        if pretrained_embeddings is not None:\n",
    "            pretrained_embeddings = torch.tensor(list(pretrained_embeddings.values()), dtype=torch.float32)\n",
    "            if pretrained_embeddings.size(1) != embedding_dim:\n",
    "                raise ValueError(\n",
    "                    f\"Pretrained embeddings size {pretrained_embeddings.size(1)} does not match the required embedding_dim {embedding_dim}.\"\n",
    "                )\n",
    "            self.embedding = nn.Parameter(pretrained_embeddings)\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        self.projection = nn.Linear(embedding_dim, hidden_dim) if embedding_dim != hidden_dim else nn.Identity()\n",
    "        self.layer_norm = nn.LayerNorm(hidden_dim, eps=1e-6)\n",
    "\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=hidden_dim,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_layers,\n",
    "            num_decoder_layers=num_layers,\n",
    "            batch_first=False\n",
    "        )\n",
    "        \n",
    "        self.fc_out = nn.Linear(hidden_dim, embedding_dim)\n",
    "\n",
    "    def forward(self, embeddings):\n",
    "        batch_size, hidden_dim, seq_len = embeddings.shape\n",
    "        if self.embedding_dim != self.hidden_dim:\n",
    "            embeddings = self.projection(embeddings)\n",
    "        embeddings = embeddings.transpose(1, 2)\n",
    "        embeddings = self.layer_norm(embeddings)\n",
    "        embeddings = embeddings.transpose(0, 1)\n",
    "        embeddings = self.transformer(embeddings, embeddings)\n",
    "        embeddings = embeddings.transpose(0, 1)\n",
    "        logits = self.fc_out(embeddings)\n",
    "        logits = logits.transpose(1, 2)\n",
    "        return logits\n",
    "    \n",
    "    def add_noise(self, token_embeddings, t, schedule):\n",
    "        alpha_t = schedule.get_alpha(t)\n",
    "        beta_t = schedule.get_beta(t)\n",
    "                \n",
    "        noisy_embeddings = torch.sqrt(alpha_t)*token_embeddings + torch.sqrt(beta_t)*torch.randn_like(token_embeddings)\n",
    "        return noisy_embeddings\n",
    "    \n",
    "    def reverse_diffusion(self, noisy_input, schedule):\n",
    "        x_t = noisy_input\n",
    "        device = x_t.device\n",
    "        for t in reversed(range(self.num_timesteps)):\n",
    "            predicted_noise = self.tnet(x_t) if self.tnet is not None else self.forward(x_t)\n",
    "            #predicted_noise = self.forward(x_t)\n",
    "            alpha_t = schedule.get_alpha(t)\n",
    "            beta_t = schedule.get_beta(t)\n",
    "            mean_x_prev = (x_t - beta_t * predicted_noise) / torch.sqrt(alpha_t)\n",
    "            if t > 0:\n",
    "                std_dev = torch.sqrt(beta_t)\n",
    "                noise = torch.randn_like(x_t, device=device) * std_dev\n",
    "                x_t = mean_x_prev + noise\n",
    "            else:\n",
    "                x_t = mean_x_prev\n",
    "            x_t = torch.clamp(x_t, min=-1.0, max=1.0)\n",
    "        return x_t\n",
    "\n",
    "def denoising_loss(predicted_embeddings, clean_embeddings):\n",
    "    return nn.MSELoss()(predicted_embeddings, clean_embeddings)\n",
    "\n",
    "def train_diffusion_model(model, train_loader, val_loader, num_epochs=10, patience_num_epochs=3):\n",
    "    device = setup_device()\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    #optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)\n",
    "    #scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode='min',patience=2,factor=0.5)\n",
    "    schedule = CosineNoiseSchedule(timesteps=1000, device=device)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    num_epochs_without_improvement = 0\n",
    "    early_stopping = False\n",
    "    performance_metrics = {\"epoch_list\": [], \"train_loss_list\": [], \"val_loss_list\": []}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for token_embeddings, noisy_token_embeddings, x, y, t, mask, skeleton in train_loader:\n",
    "            token_embeddings, noisy_token_embeddings, x, y, mask = token_embeddings.to(device), noisy_token_embeddings.to(device), x.to(device), y.to(device), mask.to(device)\n",
    "            mask = mask.to(device) if mask is not None else None\n",
    "            optimizer.zero_grad()\n",
    "            predicted_embeddings = model(noisy_token_embeddings)\n",
    "            loss = denoising_loss(predicted_embeddings, token_embeddings)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        train_loss = total_loss/len(train_loader)\n",
    "        performance_metrics['train_loss_list'].append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for token_embeddings, noisy_token_embeddings, x, y, t, mask, skeleton in val_loader:\n",
    "                token_embeddings, noisy_token_embeddings, x, y, mask = token_embeddings.to(device), noisy_token_embeddings.to(device), x.to(device), y.to(device), mask.to(device)\n",
    "                mask = mask.to(device) if mask is not None else None\n",
    "\n",
    "                # Forward pass\n",
    "                denoised_token_embeddings = model.reverse_diffusion(noisy_token_embeddings, schedule)\n",
    "                \n",
    "                # Compute loss\n",
    "                loss = denoising_loss(denoised_token_embeddings, token_embeddings)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        performance_metrics['val_loss_list'].append(val_loss)\n",
    "        performance_metrics['epoch_list'].append(epoch + 1)\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss}, Val Loss: {val_loss}')\n",
    "\n",
    "        #scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            save_model(model, \"Data/best_diffusion_model_method1.pt\")\n",
    "            num_epochs_without_improvement = 0\n",
    "        else:\n",
    "            num_epochs_without_improvement += 1\n",
    "\n",
    "        if num_epochs_without_improvement >= patience_num_epochs:\n",
    "            print(f\"Training stopped early at epoch {epoch + 1}. Best validation loss: {best_val_loss}\")\n",
    "            early_stopping = True\n",
    "            break\n",
    "        \n",
    "    if early_stopping == False:\n",
    "        save_model(model, \"Data/best_diffusion_model_method1.pt\")\n",
    "\n",
    "    return model, performance_metrics\n",
    "\n",
    "# Example of loading and preparing the dataset\n",
    "dataset = load_dataset('Data/preprocessed_data_with_embeddings.json')\n",
    "vocab = load_JSON(\"Data/vocab_embeddings.json\")  # Vocabulary is a dictionary of continuous embeddings\n",
    "\n",
    "MAX_LENGTH = determine_max_seq_len(dataset)  # Determine the max length dynamically\n",
    "\n",
    "schedule = CosineNoiseSchedule(timesteps=1000,device=setup_device())\n",
    "\n",
    "# First, perform the split on the raw dataset\n",
    "train_size = int(0.7*len(dataset))  # 70% for training\n",
    "val_size = int(0.15*len(dataset))  # 15% for validation\n",
    "test_size = len(dataset) - train_size - val_size  # 15% for testing\n",
    "\n",
    "# Perform random split\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_dataset_SR = SymbolicRegressionDataset(train_dataset, vocab, MAX_LENGTH, schedule)\n",
    "val_dataset_SR = SymbolicRegressionDataset(val_dataset, vocab, MAX_LENGTH, schedule)\n",
    "test_dataset_SR = SymbolicRegressionDataset(test_dataset, vocab, MAX_LENGTH, schedule)\n",
    "\n",
    "# Create DataLoader objects for each subset\n",
    "train_loader = DataLoader(train_dataset_SR, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset_SR, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset_SR, batch_size=16, shuffle=True)\n",
    "\n",
    "# Initialize the model\n",
    "num_heads = 4  # Number of attention heads, ensure this is a divisor of embedding_dim\n",
    "embedding_dim = 100  # The embedding dimension is 100 as per your problem\n",
    "hidden_dim = embedding_dim  # Hidden dimension stays the same for simplicity\n",
    "\n",
    "# Ensure embedding_dim is divisible by num_heads\n",
    "if embedding_dim % num_heads != 0:\n",
    "    raise ValueError(f\"embedding_dim ({embedding_dim}) must be divisible by num_heads ({num_heads}).\")\n",
    "\n",
    "model = DiffusionModel(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_layers=4,\n",
    "    num_heads=4,\n",
    "    num_timesteps=1000,\n",
    "    pretrained_embeddings=vocab\n",
    ")\n",
    "\n",
    "model,performance_metrics_DICT = train_diffusion_model(model,train_loader,val_loader,num_epochs=100,patience_num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Visualize the train and validation loss\n",
    "def plot_train_valid(model_name,performance_metrics_DICT):\n",
    "    plt.figure();\n",
    "    plt.plot(performance_metrics_DICT['epoch_list'], performance_metrics_DICT['train_loss_list'], label=f'Train Loss', color='blue', linestyle='--', marker='o');\n",
    "    plt.plot(performance_metrics_DICT['epoch_list'], performance_metrics_DICT['val_loss_list'], label=f'Validation Loss', color='green', linestyle='-', marker='x');\n",
    "    plt.title(f'{model_name} Training and Validation Loss');\n",
    "    plt.xlabel('Epochs');\n",
    "    plt.ylabel('Loss');\n",
    "    plt.legend();\n",
    "    plt.grid();\n",
    "    plt.xlim(0,max(performance_metrics_DICT['epoch_list'])+1);\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Diffusion Model'\n",
    "\n",
    "plot_train_valid(model_name,performance_metrics_DICT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_embeddings_to_tokens(embeddings, vocab):\n",
    "    batch_size, embedding_dim, seq_length = embeddings.shape\n",
    "    vocab_embeddings = torch.stack([torch.tensor(embed) for embed in vocab.values()])  # Shape: [embedding_dim, num_symbols]\n",
    "\n",
    "    # Reshape vocab_embeddings to shape: [num_symbols, embedding_dim] for broadcasting    \n",
    "    # Compute the pairwise distance between each embedding in the sequence and all vocab embeddings\n",
    "    # embeddings: [batch_size, embedding_dim, seq_length]\n",
    "    # vocab_embeddings: [num_symbols, embedding_dim]\n",
    "    \n",
    "    # To compute pairwise distances, we need to reshape embeddings to [batch_size * seq_length, embedding_dim]\n",
    "    embeddings_flattened = embeddings.view(batch_size * seq_length, embedding_dim)\n",
    "    \n",
    "    # Compute pairwise distances using cdist (shape: [batch_size * seq_length, num_symbols])\n",
    "    distances = torch.cdist(embeddings_flattened, vocab_embeddings)  # Shape: [batch_size * seq_length, num_symbols]\n",
    "\n",
    "    # Reshape distances back to [batch_size, seq_length, num_symbols]\n",
    "    distances = distances.view(batch_size, seq_length, -1)\n",
    "    \n",
    "    # Find the index of the closest token for each position in the sequence\n",
    "    closest_token_indices = torch.argmin(distances, dim=-1)  # Shape: [batch_size, seq_length]\n",
    "    \n",
    "    # Convert indices to tokens\n",
    "    decoded_tokens = []\n",
    "    for batch_idx in range(batch_size):\n",
    "        tokens = [list(vocab.keys())[idx.item()] for idx in closest_token_indices[batch_idx]]\n",
    "        decoded_tokens.append(tokens)\n",
    "\n",
    "    return decoded_tokens\n",
    "\n",
    "def evaluate_diffusion_model(model, test_loader, vocab, schedule, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_test_loss = 0.0\n",
    "    decoded_formulas = []\n",
    "    actual_formulas = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for token_embeddings, noisy_token_embeddings, x, y, t, mask, skeleton_list in test_loader:\n",
    "            token_embeddings, noisy_token_embeddings, x, y, mask = token_embeddings.to(device), noisy_token_embeddings.to(device), x.to(device), y.to(device), mask.to(device)\n",
    "            # Get the predicted denoised embeddings\n",
    "            t = random.randint(0, model.num_timesteps - 1)  # Random timestep for diffusion\n",
    "            pred_embeddings = model.reverse_diffusion(noisy_token_embeddings, schedule)\n",
    "\n",
    "            # Calculate the loss (MSE between predicted and target embeddings)\n",
    "            loss = denoising_loss(pred_embeddings, noisy_token_embeddings)\n",
    "            total_test_loss += loss.item()\n",
    "\n",
    "            # Now, we need to decode the denoised embeddings back to tokens\n",
    "            decoded_tokens_list = decode_embeddings_to_tokens(pred_embeddings, vocab)\n",
    "\n",
    "            # Convert the decoded tokens to a formula string\n",
    "            predicted_formula = [\"\".join(decoded_tokens).replace('<PAD>', '').replace('+', ' + ') for decoded_tokens in decoded_tokens_list]\n",
    "            decoded_formulas.append(predicted_formula)\n",
    "\n",
    "            # Assuming target embeddings have a corresponding ground truth formula (you can adjust this part)\n",
    "            actual_formula = list(skeleton_list)\n",
    "            actual_formulas.append(actual_formula)\n",
    "\n",
    "    # Calculate average test loss\n",
    "    avg_test_loss = total_test_loss/len(test_loader)\n",
    "    return avg_test_loss, decoded_formulas, actual_formulas\n",
    "\n",
    "# Example of loading and preparing the dataset\n",
    "dataset = load_dataset('Data/preprocessed_data_with_embeddings.json')\n",
    "vocab = load_JSON(\"Data/vocab_embeddings.json\")  # Vocabulary is a dictionary of continuous embeddings\n",
    "\n",
    "MAX_LENGTH = determine_max_seq_len(dataset)  # Determine the max length dynamically\n",
    "\n",
    "schedule = CosineNoiseSchedule(timesteps=1000,device=setup_device())\n",
    "\n",
    "# First, perform the split on the raw dataset\n",
    "train_size = int(0.7*len(dataset))  # 70% for training\n",
    "val_size = int(0.15*len(dataset))  # 15% for validation\n",
    "test_size = len(dataset) - train_size - val_size  # 15% for testing\n",
    "\n",
    "# Perform random split\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_dataset_SR = SymbolicRegressionDataset(train_dataset, vocab, MAX_LENGTH, schedule)\n",
    "val_dataset_SR = SymbolicRegressionDataset(val_dataset, vocab, MAX_LENGTH, schedule)\n",
    "test_dataset_SR = SymbolicRegressionDataset(test_dataset, vocab, MAX_LENGTH, schedule)\n",
    "\n",
    "# Create DataLoader objects for each subset\n",
    "train_loader = DataLoader(train_dataset_SR, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset_SR, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset_SR, batch_size=16, shuffle=True)\n",
    "\n",
    "# Initialize the model\n",
    "num_heads = 4  # Number of attention heads, ensure this is a divisor of embedding_dim\n",
    "embedding_dim = 100  # The embedding dimension is 100 as per your problem\n",
    "hidden_dim = embedding_dim  # Hidden dimension stays the same for simplicity\n",
    "\n",
    "# Ensure embedding_dim is divisible by num_heads\n",
    "if embedding_dim % num_heads != 0:\n",
    "    raise ValueError(f\"embedding_dim ({embedding_dim}) must be divisible by num_heads ({num_heads}).\")\n",
    "\n",
    "model = DiffusionModel(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_layers=4,\n",
    "    num_heads=4,\n",
    "    num_timesteps=1000,\n",
    "    pretrained_embeddings=vocab\n",
    ")\n",
    "\n",
    "# Example: Evaluate the model on the test set\n",
    "model, device = load_model(model, \"Data/best_diffusion_model_method1.pt\")\n",
    "test_loss, decoded_formulas, actual_formulas = evaluate_diffusion_model(model, test_loader, vocab, schedule, device)\n",
    "\n",
    "# Print out the average test loss\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "# Print out the first few decoded formulas and their corresponding actual formulas\n",
    "for predicted, actual in zip(decoded_formulas[:5], actual_formulas[:5]):\n",
    "    print(f\"Predicted Formula: {predicted}\")\n",
    "    print(f\"Actual Formula: {actual}\")\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternate Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "from torch.nn import functional as F\n",
    "from dataclasses import dataclass\n",
    "import pdb\n",
    "\n",
    "# Set the random seed for replicability\n",
    "seed = 940\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "def determine_max_seq_len(data, max_length='max_length'):\n",
    "    \"\"\"Calculate the max sequence length dynamically if 'max_length' is used as an argument.\"\"\"\n",
    "    if max_length == 'max_length':\n",
    "        MAX_LENGTH = max(len(dp[\"tokens\"]) for dp in data)\n",
    "    else:\n",
    "        MAX_LENGTH = max_length\n",
    "    return MAX_LENGTH\n",
    "\n",
    "def setup_device():\n",
    "    \"\"\"Set up the device for training.\"\"\"\n",
    "    return torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def save_model(model, filepath):\n",
    "    \"\"\"Save the model's state dictionary.\"\"\"\n",
    "    torch.save(model.state_dict(), filepath)\n",
    "    return model\n",
    "\n",
    "def load_model(model, filepath):\n",
    "    \"\"\"Load a saved model state dictionary.\"\"\"\n",
    "    model.load_state_dict(torch.load(filepath))\n",
    "    model.eval()\n",
    "    device = setup_device()\n",
    "    model.to(device)\n",
    "    return model, device\n",
    "\n",
    "def load_dataset(filepath):\n",
    "    \"\"\"Load the dataset from a JSON file.\"\"\"\n",
    "    with open(filepath, 'r') as file:\n",
    "        dataset = [json.loads(line) for line in file]\n",
    "    return dataset\n",
    "\n",
    "def load_dataset_torch(filepath):\n",
    "    loaded_data = torch.load(filepath)\n",
    "    formula_embeddings = loaded_data['formula_embeddings']\n",
    "    dataset_embeddings = loaded_data['dataset_embeddings']\n",
    "    return formula_embeddings,dataset_embeddings\n",
    "\n",
    "def save_JSON(data, filename):\n",
    "    \"\"\"Save data to a JSON file.\"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "    return\n",
    "\n",
    "def load_JSON(filename):\n",
    "    \"\"\"Load a JSON file.\"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "@dataclass\n",
    "class tNetConfig:\n",
    "    num_vars: int\n",
    "    embedding_size: int\n",
    "\n",
    "class tNet(nn.Module):\n",
    "    def __init__(self, config: tNetConfig):\n",
    "        super(tNet, self).__init__()\n",
    "\n",
    "        self.config = config\n",
    "        self.num_vars = config.num_vars\n",
    "        self.n_embd = config.embedding_size\n",
    "\n",
    "        self.activation_func = F.relu\n",
    "\n",
    "        # Define the convolutional layers\n",
    "        self.conv1 = nn.Conv1d(self.num_vars, self.n_embd, 1)\n",
    "        self.conv2 = nn.Conv1d(self.n_embd, 2*self.n_embd, 1)\n",
    "        self.conv3 = nn.Conv1d(2*self.n_embd, 4*self.n_embd, 1)\n",
    "\n",
    "        # Define fully connected layers\n",
    "        self.fc1 = nn.Linear(4*self.n_embd, 2*self.n_embd)\n",
    "        self.fc2 = nn.Linear(2*self.n_embd, self.n_embd)\n",
    "\n",
    "        # Corrected GroupNorm initialization\n",
    "        self.input_batch_norm = nn.GroupNorm(1, self.num_vars)  # Corrected to match input channels\n",
    "        \n",
    "        # Define other GroupNorm layers\n",
    "        self.bn1 = nn.GroupNorm(1, self.n_embd)\n",
    "        self.bn2 = nn.GroupNorm(1, 2*self.n_embd)\n",
    "        self.bn3 = nn.GroupNorm(1, 4*self.n_embd)\n",
    "        self.bn4 = nn.GroupNorm(1, 2*self.n_embd)\n",
    "        self.bn5 = nn.GroupNorm(1, self.n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply normalization and convolutions\n",
    "        if len(x.shape) == 2:  # If no batch dimension\n",
    "            x = x.unsqueeze(0)  # Add batch dimension\n",
    "        \n",
    "        x = self.input_batch_norm(x)\n",
    "        x = self.activation_func(self.bn1(self.conv1(x)))\n",
    "        x = self.activation_func(self.bn2(self.conv2(x)))\n",
    "        x = self.activation_func(self.bn3(self.conv3(x)))\n",
    "\n",
    "        # Global max pooling\n",
    "        x, _ = torch.max(x, dim=2)  # Reducing along the sequence dimension (index 2)\n",
    "        assert x.size(1) == 4*self.n_embd  # Ensure correct output size\n",
    "\n",
    "        # Apply fully connected layers\n",
    "        x = self.activation_func(self.bn4(self.fc1(x)))\n",
    "        x = self.activation_func(self.bn5(self.fc2(x)))\n",
    "        return x\n",
    "\n",
    "class CosineNoiseSchedule:\n",
    "    def __init__(self, timesteps=1000, epsilon=1e-6, device=None):\n",
    "        self.timesteps = timesteps\n",
    "        self.epsilon = epsilon\n",
    "        self.device = device\n",
    "        \n",
    "        # Create alphas using a cosine schedule\n",
    "        self.alphas = torch.cos(torch.linspace(0, math.pi/2, timesteps, device=device))**2\n",
    "        self.betas = 1.0 - self.alphas\n",
    "        self.alpha_bar = torch.maximum(torch.cumprod(self.alphas, dim=0), torch.tensor(self.epsilon, device=self.alphas.device))\n",
    "\n",
    "    def get_alpha(self, t):\n",
    "        return self.alphas[t]\n",
    "\n",
    "    def get_beta(self, t):\n",
    "        return self.betas[t]\n",
    "\n",
    "    def get_variance(self, t):\n",
    "        return self.get_beta(t) * (1 - self.get_alpha(t))\n",
    "\n",
    "    def get_alpha_bar(self, t):\n",
    "        return self.alpha_bar[t]\n",
    "\n",
    "class SymbolicRegressionDataset(Dataset):\n",
    "    def __init__(self, preprocessed_data, vocab, max_seq_len, noise_schedule):\n",
    "        self.preprocessed_data = preprocessed_data\n",
    "        self.vocab = vocab  # Add vocab here\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.noise_schedule = noise_schedule\n",
    "    \n",
    "    def add_noise(self, embeddings, t):\n",
    "        \"\"\"Add noise to the embeddings based on the cosine noise schedule.\"\"\"\n",
    "        alpha_t = self.noise_schedule.get_alpha(t)\n",
    "        beta_t = self.noise_schedule.get_beta(t)\n",
    "        noise = torch.randn_like(embeddings)*torch.sqrt(beta_t)\n",
    "        noisy_embeddings = torch.sqrt(alpha_t)*embeddings + noise\n",
    "        return noisy_embeddings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Prepare a single data point.\"\"\"\n",
    "        data_point = self.preprocessed_data[idx]\n",
    "        formula_emb = torch.tensor(data_point['formula_embedding'], dtype=torch.float32)\n",
    "        dataset_emb =  torch.tensor(data_point['dataset_embedding'], dtype=torch.float32)\n",
    "        skeleton = data_point['skeleton']\n",
    "\n",
    "        # Sample a timestep t\n",
    "        t = random.randint(0, self.noise_schedule.timesteps - 1)\n",
    "        noisy_formula_emb = self.add_noise(formula_emb, t)\n",
    "        return formula_emb, noisy_formula_emb, dataset_emb, t, skeleton\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.preprocessed_data)\n",
    "\n",
    "class DiffusionModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, num_heads, num_timesteps, max_seq_len=5000, pretrained_embeddings=None):\n",
    "        super(DiffusionModel, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_timesteps = num_timesteps\n",
    "                \n",
    "        # Initialize embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.projection = nn.Linear(embedding_dim, hidden_dim) if embedding_dim != hidden_dim else nn.Identity()\n",
    "        self.layer_norm = nn.LayerNorm(hidden_dim, eps=1e-6)\n",
    "\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=hidden_dim,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_layers,\n",
    "            num_decoder_layers=num_layers,\n",
    "            batch_first=False\n",
    "        )\n",
    "        \n",
    "        # Cross-attention mechanism for conditioning\n",
    "        self.cross_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim, \n",
    "            num_heads=num_heads, \n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.fc_out = nn.Linear(hidden_dim, embedding_dim)\n",
    "        \n",
    "    def forward(self, embeddings):\n",
    "        # Process embeddings\n",
    "        batch_size, embedding_dim = embeddings.shape\n",
    "        embeddings = self.projection(embeddings)\n",
    "        embeddings = self.layer_norm(embeddings)\n",
    "        embeddings = embeddings.unsqueeze(0)  # Shape: (1, batch_size, hidden_dim)\n",
    "        embeddings = self.transformer(embeddings, embeddings)  # Shape: (1, batch_size, hidden_dim)\n",
    "        embeddings = embeddings.squeeze(0)  # Shape: (batch_size, hidden_dim)\n",
    "        logits = self.fc_out(embeddings)  # Shape: (batch_size, output_dim)\n",
    "        return logits\n",
    "\n",
    "    def reverse_diffusion(self, noisy_formula_embeddings, dataset_embeddings, schedule):\n",
    "        \"\"\"Reverse diffusion process using attention-based conditioning.\"\"\"\n",
    "        device = noisy_formula_embeddings.device\n",
    "        batch_size, embedding_dim = noisy_formula_embeddings.size()\n",
    "        x_t = noisy_formula_embeddings\n",
    "        \n",
    "        tnet = tNet(tNetConfig(num_vars=batch_size,embedding_size=embedding_dim))\n",
    "        \n",
    "        # Expand dimensions for cross-attention\n",
    "        dataset_embeddings = dataset_embeddings.unsqueeze(1)  # Add sequence dimension (e.g., [B, D] -> [B, 1, D])\n",
    "        \n",
    "        for t in reversed(range(self.num_timesteps)):\n",
    "            # Predict the noise using cross-attention\n",
    "            query = x_t.unsqueeze(1)  # [B, 1, D]\n",
    "            conditioned_embedding, _ = self.cross_attention(\n",
    "                query=query,\n",
    "                key=dataset_embeddings,\n",
    "                value=dataset_embeddings\n",
    "            )\n",
    "            x_t = conditioned_embedding.squeeze(1)  # Remove sequence dimension\n",
    "            \n",
    "            # Use conditioned_embedding to predict noise\n",
    "            predicted_noise = tnet(x_t) if tnet is not None else self.forward(x_t) \n",
    "\n",
    "            # Extract alpha and beta values from schedule\n",
    "            alpha_t = schedule.get_alpha(t)\n",
    "            beta_t = schedule.get_beta(t)\n",
    "            \n",
    "            # Compute mean of x_{t-1}\n",
    "            mean_x_prev = (x_t - beta_t * predicted_noise) / torch.sqrt(alpha_t)\n",
    "            \n",
    "            if t > 0:\n",
    "                std_dev = torch.sqrt(beta_t)\n",
    "                noise = torch.randn_like(x_t, device=device) * std_dev\n",
    "                x_t = mean_x_prev + noise\n",
    "            else:\n",
    "                x_t = mean_x_prev\n",
    "            \n",
    "            # Clamp values to avoid out-of-bound values\n",
    "            x_t = torch.clamp(x_t, min=-1.0, max=1.0)\n",
    "        \n",
    "        return x_t\n",
    "\n",
    "def denoising_loss(predicted_embeddings, clean_embeddings):\n",
    "    return nn.MSELoss()(predicted_embeddings, clean_embeddings)\n",
    "\n",
    "def train_diffusion_model(model, train_loader, val_loader, num_epochs=10, patience_num_epochs=3):\n",
    "    device = setup_device()\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5)\n",
    "    schedule = CosineNoiseSchedule(timesteps=1000, device=device)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    num_epochs_without_improvement = 0\n",
    "    early_stopping = False\n",
    "    performance_metrics = {\"epoch_list\": [], \"train_loss_list\": [], \"val_loss_list\": []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for formula_emb, noisy_formula_emb, dataset_emb, t, skeleton in train_loader:\n",
    "            formula_emb, noisy_formula_emb, dataset_emb = formula_emb.to(device), noisy_formula_emb.to(device), dataset_emb.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Predict the denoised formula embeddings using the model\n",
    "            predicted_emb = model(noisy_formula_emb)\n",
    "\n",
    "            # Compute the loss using the original clean formula embeddings\n",
    "            loss = denoising_loss(predicted_emb, formula_emb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        train_loss = total_loss/len(train_loader)\n",
    "        performance_metrics['train_loss_list'].append(train_loss)\n",
    "\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        val_loss = 0.0\n",
    "        total_correct = 0\n",
    "        num_samples = 0\n",
    "\n",
    "        with torch.no_grad():  # No gradients needed during validation\n",
    "            for formula_emb, noisy_formula_emb, dataset_emb, t, skeleton in val_loader:\n",
    "                formula_emb, noisy_formula_emb, dataset_emb = formula_emb.to(device), noisy_formula_emb.to(device), dataset_emb.to(device)\n",
    "                predicted_emb = model.reverse_diffusion(noisy_formula_emb, dataset_emb, schedule)\n",
    "                loss = denoising_loss(predicted_emb, formula_emb)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                num_samples += formula_emb.size(0)\n",
    "\n",
    "        val_loss = val_loss/len(val_loader)\n",
    "        performance_metrics['val_loss_list'].append(val_loss)\n",
    "        performance_metrics['epoch_list'].append(epoch + 1)\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss}, Val Loss: {val_loss}')\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            save_model(model, \"best_diffusion_model_method2.pt\")\n",
    "            num_epochs_without_improvement = 0\n",
    "        else:\n",
    "            num_epochs_without_improvement += 1\n",
    "\n",
    "        if num_epochs_without_improvement >= patience_num_epochs:\n",
    "            print(f\"Training stopped early at epoch {epoch + 1}. Best validation loss: {best_val_loss}\")\n",
    "            early_stopping = True\n",
    "            break\n",
    "\n",
    "    if not early_stopping:\n",
    "        save_model(model, \"best_diffusion_model_method2.pt\")\n",
    "\n",
    "    return model, performance_metrics\n",
    "\n",
    "# Example of loading and preparing the dataset\n",
    "dataset = load_dataset('Data/preprocessed_data_with_embeddings.json')\n",
    "vocab = load_JSON(\"Data/vocab_embeddings.json\")  # Vocabulary is a dictionary of continuous embeddings\n",
    "\n",
    "MAX_LENGTH = determine_max_seq_len(dataset)  # Determine the max length dynamically\n",
    "\n",
    "schedule = CosineNoiseSchedule(timesteps=1000,device=setup_device())\n",
    "\n",
    "# First, perform the split on the raw dataset\n",
    "train_size = int(0.7*len(dataset))  # 70% for training\n",
    "val_size = int(0.15*len(dataset))  # 15% for validation\n",
    "test_size = len(dataset) - train_size - val_size  # 15% for testing\n",
    "\n",
    "# Perform random split\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_dataset_SR = SymbolicRegressionDataset(train_dataset, vocab, MAX_LENGTH, schedule)\n",
    "val_dataset_SR = SymbolicRegressionDataset(val_dataset, vocab, MAX_LENGTH, schedule)\n",
    "test_dataset_SR = SymbolicRegressionDataset(test_dataset, vocab, MAX_LENGTH, schedule)\n",
    "\n",
    "# Create DataLoader objects for each subset\n",
    "train_loader = DataLoader(train_dataset_SR, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset_SR, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset_SR, batch_size=16, shuffle=True)\n",
    "\n",
    "# Initialize the model\n",
    "num_heads = 4  # Number of attention heads, ensure this is a divisor of embedding_dim\n",
    "embedding_dim = 128  # The embedding dimension is 100 as per your problem\n",
    "hidden_dim = embedding_dim  # Hidden dimension stays the same for simplicity\n",
    "\n",
    "# Ensure embedding_dim is divisible by num_heads\n",
    "if embedding_dim % num_heads != 0:\n",
    "    raise ValueError(f\"embedding_dim ({embedding_dim}) must be divisible by num_heads ({num_heads}).\")\n",
    "\n",
    "model = DiffusionModel(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_layers=4,\n",
    "    num_heads=4,\n",
    "    num_timesteps=1000,\n",
    "    pretrained_embeddings=vocab,\n",
    ")\n",
    "\n",
    "model,performance_metrics_DICT = train_diffusion_model(model,train_loader,val_loader,num_epochs=100,patience_num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.7206235289573669, Val Loss: 0.6199209690093994\n",
      "Epoch 2/100, Train Loss: 0.4656024813652039, Val Loss: 0.6199209690093994\n",
      "Epoch 3/100, Train Loss: 0.33785690665245055, Val Loss: 0.6199209690093994\n",
      "Epoch 4/100, Train Loss: 0.2589802086353302, Val Loss: 0.6199209690093994\n",
      "Epoch 5/100, Train Loss: 0.21497848331928254, Val Loss: 0.6199209690093994\n",
      "Epoch 6/100, Train Loss: 0.19425413012504578, Val Loss: 0.6199209690093994\n",
      "Epoch 7/100, Train Loss: 0.1795389920473099, Val Loss: 0.6199209690093994\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 363\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding_dim (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00membedding_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) must be divisible by num_heads (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_heads\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    353\u001b[0m model \u001b[38;5;241m=\u001b[39m DiffusionModel(\n\u001b[0;32m    354\u001b[0m     vocab_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(vocab),\n\u001b[0;32m    355\u001b[0m     embedding_dim\u001b[38;5;241m=\u001b[39membedding_dim,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    360\u001b[0m     pretrained_embeddings\u001b[38;5;241m=\u001b[39mvocab,\n\u001b[0;32m    361\u001b[0m )\n\u001b[1;32m--> 363\u001b[0m model,performance_metrics_DICT \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_diffusion_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mpatience_num_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[27], line 291\u001b[0m, in \u001b[0;36mtrain_diffusion_model\u001b[1;34m(model, train_loader, val_loader, num_epochs, patience_num_epochs)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m formula_emb, noisy_formula_emb, dataset_emb, t, skeleton \u001b[38;5;129;01min\u001b[39;00m val_loader:\n\u001b[0;32m    290\u001b[0m     formula_emb, noisy_formula_emb, dataset_emb \u001b[38;5;241m=\u001b[39m formula_emb\u001b[38;5;241m.\u001b[39mto(device), noisy_formula_emb\u001b[38;5;241m.\u001b[39mto(device), dataset_emb\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m--> 291\u001b[0m     predicted_emb \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreverse_diffusion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoisy_formula_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschedule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    292\u001b[0m     loss \u001b[38;5;241m=\u001b[39m denoising_loss(predicted_emb, formula_emb)\n\u001b[0;32m    293\u001b[0m     val_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "Cell \u001b[1;32mIn[27], line 236\u001b[0m, in \u001b[0;36mDiffusionModel.reverse_diffusion\u001b[1;34m(self, noisy_formula_embeddings, dataset_embeddings, schedule)\u001b[0m\n\u001b[0;32m    233\u001b[0m x_t \u001b[38;5;241m=\u001b[39m conditioned_embedding\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Remove sequence dimension\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;66;03m# Use conditioned_embedding to predict noise\u001b[39;00m\n\u001b[1;32m--> 236\u001b[0m predicted_noise \u001b[38;5;241m=\u001b[39m \u001b[43mtnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m tnet \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(x_t) \n\u001b[0;32m    238\u001b[0m \u001b[38;5;66;03m# Extract alpha and beta values\u001b[39;00m\n\u001b[0;32m    239\u001b[0m alpha_t \u001b[38;5;241m=\u001b[39m schedule\u001b[38;5;241m.\u001b[39mget_alpha(t)\n",
      "File \u001b[1;32mc:\\Users\\matth\\OneDrive - University of Waterloo\\Documents\\Python Files\\Environments\\STAT940_Final_Project_VENV\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\matth\\OneDrive - University of Waterloo\\Documents\\Python Files\\Environments\\STAT940_Final_Project_VENV\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[27], line 106\u001b[0m, in \u001b[0;36mtNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    104\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)))\n\u001b[0;32m    105\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)))\n\u001b[1;32m--> 106\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn3(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# Global max pooling\u001b[39;00m\n\u001b[0;32m    109\u001b[0m x, _ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(x, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Reducing along the sequence dimension (index 2)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matth\\OneDrive - University of Waterloo\\Documents\\Python Files\\Environments\\STAT940_Final_Project_VENV\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\matth\\OneDrive - University of Waterloo\\Documents\\Python Files\\Environments\\STAT940_Final_Project_VENV\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\matth\\OneDrive - University of Waterloo\\Documents\\Python Files\\Environments\\STAT940_Final_Project_VENV\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:375\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\matth\\OneDrive - University of Waterloo\\Documents\\Python Files\\Environments\\STAT940_Final_Project_VENV\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:370\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(\n\u001b[0;32m    360\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    361\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    369\u001b[0m     )\n\u001b[1;32m--> 370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "from torch.nn import functional as F\n",
    "from dataclasses import dataclass\n",
    "import pdb\n",
    "\n",
    "# Set the random seed for replicability\n",
    "seed = 940\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "def determine_max_seq_len(data, max_length='max_length'):\n",
    "    \"\"\"Calculate the max sequence length dynamically if 'max_length' is used as an argument.\"\"\"\n",
    "    if max_length == 'max_length':\n",
    "        MAX_LENGTH = max(len(dp[\"tokens\"]) for dp in data)\n",
    "    else:\n",
    "        MAX_LENGTH = max_length\n",
    "    return MAX_LENGTH\n",
    "\n",
    "def setup_device():\n",
    "    \"\"\"Set up the device for training.\"\"\"\n",
    "    return torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def save_model(model, filepath):\n",
    "    \"\"\"Save the model's state dictionary.\"\"\"\n",
    "    torch.save(model.state_dict(), filepath)\n",
    "    return model\n",
    "\n",
    "def load_model(model, filepath):\n",
    "    \"\"\"Load a saved model state dictionary.\"\"\"\n",
    "    model.load_state_dict(torch.load(filepath))\n",
    "    model.eval()\n",
    "    device = setup_device()\n",
    "    model.to(device)\n",
    "    return model, device\n",
    "\n",
    "def load_dataset(filepath):\n",
    "    \"\"\"Load the dataset from a JSON file.\"\"\"\n",
    "    with open(filepath, 'r') as file:\n",
    "        dataset = [json.loads(line) for line in file]\n",
    "    return dataset\n",
    "\n",
    "def save_JSON(data, filename):\n",
    "    \"\"\"Save data to a JSON file.\"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "    return\n",
    "\n",
    "def load_JSON(filename):\n",
    "    \"\"\"Load a JSON file.\"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "@dataclass\n",
    "class tNetConfig:\n",
    "    num_vars: int\n",
    "    embedding_size: int\n",
    "\n",
    "class tNet(nn.Module):\n",
    "    def __init__(self, config: tNetConfig):\n",
    "        super(tNet, self).__init__()\n",
    "\n",
    "        self.config = config\n",
    "        self.num_vars = config.num_vars\n",
    "        self.n_embd = config.embedding_size\n",
    "\n",
    "        self.activation_func = F.relu\n",
    "\n",
    "        # Define the convolutional layers\n",
    "        self.conv1 = nn.Conv1d(self.num_vars, self.n_embd, 1)\n",
    "        self.conv2 = nn.Conv1d(self.n_embd, 2*self.n_embd, 1)\n",
    "        self.conv3 = nn.Conv1d(2*self.n_embd, 4*self.n_embd, 1)\n",
    "\n",
    "        # Define fully connected layers\n",
    "        self.fc1 = nn.Linear(4*self.n_embd, 2*self.n_embd)\n",
    "        self.fc2 = nn.Linear(2*self.n_embd, self.n_embd)\n",
    "\n",
    "        # Corrected GroupNorm initialization\n",
    "        self.input_batch_norm = nn.GroupNorm(1, self.num_vars)  # Corrected to match input channels\n",
    "        \n",
    "        # Define other GroupNorm layers\n",
    "        self.bn1 = nn.GroupNorm(1, self.n_embd)\n",
    "        self.bn2 = nn.GroupNorm(1, 2*self.n_embd)\n",
    "        self.bn3 = nn.GroupNorm(1, 4*self.n_embd)\n",
    "        self.bn4 = nn.GroupNorm(1, 2*self.n_embd)\n",
    "        self.bn5 = nn.GroupNorm(1, self.n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply normalization and convolutions\n",
    "        if len(x.shape) == 2:  # If no batch dimension\n",
    "            x = x.unsqueeze(0)  # Add batch dimension\n",
    "        \n",
    "        x = self.input_batch_norm(x)\n",
    "        x = self.activation_func(self.bn1(self.conv1(x)))\n",
    "        x = self.activation_func(self.bn2(self.conv2(x)))\n",
    "        x = self.activation_func(self.bn3(self.conv3(x)))\n",
    "\n",
    "        # Global max pooling\n",
    "        x, _ = torch.max(x, dim=2)  # Reducing along the sequence dimension (index 2)\n",
    "        assert x.size(1) == 4*self.n_embd  # Ensure correct output size\n",
    "\n",
    "        # Apply fully connected layers\n",
    "        x = self.activation_func(self.bn4(self.fc1(x)))\n",
    "        x = self.activation_func(self.bn5(self.fc2(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "def add_noise_with_data(embeddings, dataset_points, t, schedule):\n",
    "    \"\"\"Add noise to embeddings using dataset points.\"\"\"\n",
    "    alpha_t = schedule.get_alpha(t)\n",
    "    beta_t = schedule.get_beta(t)\n",
    "    noise = torch.randn_like(embeddings) * torch.sqrt(beta_t)\n",
    "    noisy_embeddings = torch.sqrt(alpha_t) * embeddings + noise + dataset_points.mean(dim=0)\n",
    "    return noisy_embeddings\n",
    "\n",
    "class CosineNoiseSchedule:\n",
    "    def __init__(self, timesteps=1000, epsilon=1e-6, device=None):\n",
    "        self.timesteps = timesteps\n",
    "        self.epsilon = epsilon\n",
    "        self.device = device\n",
    "        \n",
    "        # Create alphas using a cosine schedule\n",
    "        self.alphas = torch.cos(torch.linspace(0, math.pi/2, timesteps, device=device))**2\n",
    "        self.betas = 1.0 - self.alphas\n",
    "        self.alpha_bar = torch.maximum(torch.cumprod(self.alphas, dim=0), torch.tensor(self.epsilon, device=self.alphas.device))\n",
    "\n",
    "    def get_alpha(self, t):\n",
    "        return self.alphas[t]\n",
    "\n",
    "    def get_beta(self, t):\n",
    "        return self.betas[t]\n",
    "\n",
    "    def get_variance(self, t):\n",
    "        return self.get_beta(t) * (1 - self.get_alpha(t))\n",
    "\n",
    "    def get_alpha_bar(self, t):\n",
    "        return self.alpha_bar[t]\n",
    "\n",
    "class SymbolicRegressionDataset(Dataset):\n",
    "    def __init__(self, preprocessed_data, vocab, max_seq_len, noise_schedule):\n",
    "        self.preprocessed_data = preprocessed_data\n",
    "        self.vocab = vocab\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.noise_schedule = noise_schedule\n",
    "    \n",
    "    def add_noise(self, embeddings, dataset_points, t):\n",
    "        \"\"\"Add noise to embeddings based on data points.\"\"\"\n",
    "        return add_noise_with_data(embeddings, dataset_points, t, self.noise_schedule)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Prepare a single data point.\"\"\"\n",
    "        data_point = self.preprocessed_data[idx]\n",
    "        formula_emb = torch.tensor(data_point['formula_embedding'], dtype=torch.float32)\n",
    "        dataset_emb = torch.tensor(data_point['dataset_embedding'], dtype=torch.float32)\n",
    "        skeleton = data_point['skeleton']\n",
    "\n",
    "        # Sample a timestep t\n",
    "        t = random.randint(0, self.noise_schedule.timesteps - 1)\n",
    "        noisy_formula_emb = self.add_noise(formula_emb, dataset_emb, t)\n",
    "        return formula_emb, noisy_formula_emb, dataset_emb, t, skeleton\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.preprocessed_data)\n",
    "\n",
    "class DiffusionModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, num_heads, num_timesteps, pretrained_embeddings=None):\n",
    "        super(DiffusionModel, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_timesteps = num_timesteps\n",
    "        \n",
    "        # Initialize embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.projection = nn.Linear(embedding_dim, hidden_dim) if embedding_dim != hidden_dim else nn.Identity()\n",
    "        self.layer_norm = nn.LayerNorm(hidden_dim, eps=1e-6)\n",
    "        \n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=hidden_dim,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_layers,\n",
    "            num_decoder_layers=num_layers,\n",
    "            batch_first=False\n",
    "        )\n",
    "        \n",
    "        # Cross-attention mechanism for conditioning\n",
    "        self.cross_attention = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim, \n",
    "            num_heads=num_heads, \n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.fc_out = nn.Linear(hidden_dim, embedding_dim)\n",
    "        \n",
    "    def forward(self, embeddings):\n",
    "        \"\"\"Standard forward pass.\"\"\"\n",
    "        embeddings = self.projection(embeddings)\n",
    "        embeddings = self.layer_norm(embeddings)\n",
    "        embeddings = embeddings.unsqueeze(0)  # Add sequence dimension\n",
    "        embeddings = self.transformer(embeddings, embeddings)\n",
    "        embeddings = embeddings.squeeze(0)  # Remove sequence dimension\n",
    "        logits = self.fc_out(embeddings)\n",
    "        return logits\n",
    "\n",
    "    def reverse_diffusion(self, noisy_formula_embeddings, dataset_embeddings, schedule):\n",
    "        \"\"\"Reverse diffusion process using attention-based conditioning.\"\"\"\n",
    "        device = noisy_formula_embeddings.device\n",
    "        batch_size, embedding_dim = noisy_formula_embeddings.size()\n",
    "        x_t = noisy_formula_embeddings\n",
    "        \n",
    "        tnet = tNet(tNetConfig(num_vars=batch_size,embedding_size=embedding_dim))\n",
    "        \n",
    "        dataset_embeddings = dataset_embeddings.unsqueeze(1)  # Add sequence dimension\n",
    "        \n",
    "        for t in reversed(range(self.num_timesteps)):\n",
    "            # Predict the noise using cross-attention\n",
    "            query = x_t.unsqueeze(1)  # Shape: [B, 1, D]\n",
    "            conditioned_embedding, _ = self.cross_attention(\n",
    "                query=query,\n",
    "                key=dataset_embeddings,\n",
    "                value=dataset_embeddings\n",
    "            )\n",
    "            x_t = conditioned_embedding.squeeze(1)  # Remove sequence dimension\n",
    "            \n",
    "            # Use conditioned_embedding to predict noise\n",
    "            predicted_noise = tnet(x_t) if tnet is not None else self.forward(x_t) \n",
    "            \n",
    "            # Extract alpha and beta values\n",
    "            alpha_t = schedule.get_alpha(t)\n",
    "            beta_t = schedule.get_beta(t)\n",
    "            \n",
    "            # Compute mean of x_{t-1}\n",
    "            mean_x_prev = (x_t - beta_t*predicted_noise)/torch.sqrt(alpha_t)\n",
    "            \n",
    "            if t > 0:\n",
    "                std_dev = torch.sqrt(beta_t)\n",
    "                noise = torch.randn_like(x_t, device=device) * std_dev\n",
    "                x_t = mean_x_prev + noise\n",
    "            else:\n",
    "                x_t = mean_x_prev\n",
    "            \n",
    "            # Clamp values\n",
    "            x_t = torch.clamp(x_t, min=-1.0, max=1.0)\n",
    "        \n",
    "        return x_t\n",
    "\n",
    "# Update the training process if needed\n",
    "def train_diffusion_model(model, train_loader, val_loader, num_epochs=10, patience_num_epochs=3):\n",
    "    device = setup_device()\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5)\n",
    "    schedule = CosineNoiseSchedule(timesteps=1000, device=device)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    num_epochs_without_improvement = 0\n",
    "    early_stopping = False\n",
    "    performance_metrics = {\"epoch_list\": [], \"train_loss_list\": [], \"val_loss_list\": []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for formula_emb, noisy_formula_emb, dataset_emb, t, skeleton in train_loader:\n",
    "            formula_emb, noisy_formula_emb, dataset_emb = formula_emb.to(device), noisy_formula_emb.to(device), dataset_emb.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            predicted_emb = model(noisy_formula_emb)\n",
    "            loss = denoising_loss(predicted_emb, formula_emb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        train_loss = total_loss / len(train_loader)\n",
    "        performance_metrics['train_loss_list'].append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for formula_emb, noisy_formula_emb, dataset_emb, t, skeleton in val_loader:\n",
    "                formula_emb, noisy_formula_emb, dataset_emb = formula_emb.to(device), noisy_formula_emb.to(device), dataset_emb.to(device)\n",
    "                predicted_emb = model.reverse_diffusion(noisy_formula_emb, dataset_emb, schedule)\n",
    "                loss = denoising_loss(predicted_emb, formula_emb)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        performance_metrics['val_loss_list'].append(val_loss)\n",
    "        performance_metrics['epoch_list'].append(epoch + 1)\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss}, Val Loss: {val_loss}')\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            save_model(model, \"best_diffusion_model.pt\")\n",
    "            num_epochs_without_improvement = 0\n",
    "        else:\n",
    "            num_epochs_without_improvement += 1\n",
    "\n",
    "        if num_epochs_without_improvement >= patience_num_epochs:\n",
    "            print(f\"Training stopped early at epoch {epoch + 1}. Best validation loss: {best_val_loss}\")\n",
    "            early_stopping = True\n",
    "            break\n",
    "\n",
    "    if not early_stopping:\n",
    "        save_model(model, \"best_diffusion_model.pt\")\n",
    "\n",
    "    return model, performance_metrics\n",
    "\n",
    "# Example of loading and preparing the dataset\n",
    "dataset = load_dataset('Data/preprocessed_data_with_embeddings.json')\n",
    "vocab = load_JSON(\"Data/vocab_embeddings.json\")  # Vocabulary is a dictionary of continuous embeddings\n",
    "\n",
    "MAX_LENGTH = determine_max_seq_len(dataset)  # Determine the max length dynamically\n",
    "\n",
    "schedule = CosineNoiseSchedule(timesteps=1000,device=setup_device())\n",
    "\n",
    "# First, perform the split on the raw dataset\n",
    "train_size = int(0.7*len(dataset))  # 70% for training\n",
    "val_size = int(0.15*len(dataset))  # 15% for validation\n",
    "test_size = len(dataset) - train_size - val_size  # 15% for testing\n",
    "\n",
    "# Perform random split\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_dataset_SR = SymbolicRegressionDataset(train_dataset, vocab, MAX_LENGTH, schedule)\n",
    "val_dataset_SR = SymbolicRegressionDataset(val_dataset, vocab, MAX_LENGTH, schedule)\n",
    "test_dataset_SR = SymbolicRegressionDataset(test_dataset, vocab, MAX_LENGTH, schedule)\n",
    "\n",
    "# Create DataLoader objects for each subset\n",
    "train_loader = DataLoader(train_dataset_SR, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset_SR, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset_SR, batch_size=16, shuffle=True)\n",
    "\n",
    "# Initialize the model\n",
    "num_heads = 4  # Number of attention heads, ensure this is a divisor of embedding_dim\n",
    "embedding_dim = 128  # The embedding dimension is 100 as per your problem\n",
    "hidden_dim = embedding_dim  # Hidden dimension stays the same for simplicity\n",
    "\n",
    "# Ensure embedding_dim is divisible by num_heads\n",
    "if embedding_dim % num_heads != 0:\n",
    "    raise ValueError(f\"embedding_dim ({embedding_dim}) must be divisible by num_heads ({num_heads}).\")\n",
    "\n",
    "model = DiffusionModel(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_layers=4,\n",
    "    num_heads=4,\n",
    "    num_timesteps=1000,\n",
    "    pretrained_embeddings=vocab,\n",
    ")\n",
    "\n",
    "model,performance_metrics_DICT = train_diffusion_model(model,train_loader,val_loader,num_epochs=100,patience_num_epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "STAT940_Final_Project_VENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
