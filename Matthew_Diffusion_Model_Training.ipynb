{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Diffusion Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import Dataset, DataLoader, random_split\n",
    "# import random\n",
    "# import numpy as np\n",
    "# import json\n",
    "# import math\n",
    "\n",
    "# # Set the random seed (for replicability)\n",
    "# seed = 20777980\n",
    "# random.seed(seed)\n",
    "# np.random.seed(seed)\n",
    "# torch.manual_seed(seed)\n",
    "# if torch.cuda.is_available():\n",
    "#     torch.cuda.manual_seed(seed)\n",
    "\n",
    "# def determine_max_seq_len(data, max_length='max_length'):\n",
    "#     \"\"\"Calculate the max sequence length dynamically if 'max_length' is used as argument.\"\"\"\n",
    "#     if max_length == 'max_length':\n",
    "#         MAX_LENGTH = max(len(dp[\"tokens\"]) for dp in data)\n",
    "#     else:\n",
    "#         MAX_LENGTH = max_length\n",
    "#     return MAX_LENGTH\n",
    "\n",
    "# def setup_device():\n",
    "#     device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     return device\n",
    "\n",
    "# def save_model(model, filepath):\n",
    "#     torch.save(model.state_dict(), filepath)\n",
    "#     return model\n",
    "\n",
    "# def load_model(model, filepath):\n",
    "#     model.load_state_dict(torch.load(filepath))\n",
    "#     model.eval()\n",
    "#     device = setup_device()\n",
    "#     model.to(device)\n",
    "#     return model, device\n",
    "\n",
    "# def load_dataset(file_path):\n",
    "#     \"\"\"Load the dataset from a JSON file.\"\"\"\n",
    "#     with open(file_path, 'r') as file:\n",
    "#         dataset = [json.loads(line) for line in file]\n",
    "#     return dataset\n",
    "\n",
    "# def save_JSON(data, filename):\n",
    "#     with open(filename, 'w') as f:\n",
    "#         json.dump(data, f)\n",
    "#     return\n",
    "\n",
    "# def load_JSON(filename):\n",
    "#     \"\"\"Load a JSON file.\"\"\"\n",
    "#     with open(filename, 'r') as f:\n",
    "#         data = json.load(f)\n",
    "#     return data\n",
    "\n",
    "# class CosineNoiseSchedule:\n",
    "#     def __init__(self, timesteps=1000, epsilon=1e-6, device=None):\n",
    "#         self.timesteps = timesteps\n",
    "#         self.epsilon = epsilon\n",
    "#         self.device = device\n",
    "        \n",
    "#         # Create alphas using a cosine schedule\n",
    "#         self.alphas = torch.cos(torch.linspace(0, math.pi / 2, timesteps, device=device)) ** 2\n",
    "#         self.betas = 1.0 - self.alphas\n",
    "#         self.alpha_bar = torch.maximum(torch.cumprod(self.alphas, dim=0), torch.tensor(self.epsilon, device=self.alphas.device))\n",
    "\n",
    "#     def get_alpha(self, t):\n",
    "#         return self.alphas[t]\n",
    "\n",
    "#     def get_beta(self, t):\n",
    "#         return self.betas[t]\n",
    "\n",
    "#     def get_variance(self, t):\n",
    "#         return self.get_beta(t) * (1 - self.get_alpha(t))\n",
    "\n",
    "#     def get_alpha_bar(self, t):\n",
    "#         return self.alpha_bar[t]\n",
    "\n",
    "# class DiffusionModel(nn.Module):\n",
    "#     def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, num_heads, num_timesteps, max_seq_len=5000, pretrained_embeddings=None):\n",
    "#         super(DiffusionModel, self).__init__()\n",
    "\n",
    "#         self.vocab_size = vocab_size\n",
    "#         self.embedding_dim = embedding_dim\n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.num_timesteps = num_timesteps\n",
    "\n",
    "#         # Use pre-trained embeddings if available, otherwise initialize embeddings randomly\n",
    "#         if pretrained_embeddings is not None:\n",
    "#             pretrained_embeddings = torch.tensor(list(pretrained_embeddings.values()), dtype=torch.float32)\n",
    "#             if pretrained_embeddings.size(1) != embedding_dim:\n",
    "#                 raise ValueError(\n",
    "#                     f\"Pretrained embeddings size {pretrained_embeddings.size(1)} does not match the required embedding_dim {embedding_dim}.\"\n",
    "#                 )\n",
    "#             self.embedding = nn.Parameter(pretrained_embeddings)\n",
    "#         else:\n",
    "#             self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "#         # Projection layer to map from embedding_dim to hidden_dim if needed\n",
    "#         self.projection = nn.Linear(embedding_dim, hidden_dim) if embedding_dim != hidden_dim else nn.Identity()\n",
    "\n",
    "#         # Layer normalization\n",
    "#         self.layer_norm = nn.LayerNorm(hidden_dim, eps=1e-6)\n",
    "\n",
    "#         # Transformer setup\n",
    "#         self.transformer = nn.Transformer(\n",
    "#             d_model=hidden_dim,\n",
    "#             nhead=num_heads,\n",
    "#             num_encoder_layers=num_layers,\n",
    "#             num_decoder_layers=num_layers,\n",
    "#             batch_first=False  # Standard transformer expects (seq_len, batch_size, hidden_dim)\n",
    "#         )\n",
    "        \n",
    "#         # Fully connected output layer to map back to embedding_dim\n",
    "#         self.fc_out = nn.Linear(hidden_dim, embedding_dim)\n",
    "\n",
    "#     def forward(self, embeddings):\n",
    "#         # embeddings expected to have shape (batch_size, hidden_dim, seq_len)\n",
    "#         batch_size, hidden_dim, seq_len = embeddings.shape\n",
    "\n",
    "#         # If embedding_dim != hidden_dim, apply projection\n",
    "#         if self.embedding_dim != self.hidden_dim:\n",
    "#             embeddings = self.projection(embeddings)  # (batch_size, hidden_dim, seq_len)\n",
    "\n",
    "#         embeddings = embeddings.transpose(1, 2)\n",
    "        \n",
    "#         # Apply layer normalization\n",
    "#         embeddings = self.layer_norm(embeddings)  # (batch_size, hidden_dim, seq_len)\n",
    "        \n",
    "#         embeddings = embeddings.transpose(0, 1)\n",
    "        \n",
    "#         # Directly feed into Transformer, assuming it's modified to work with (batch_size, hidden_dim, seq_len)\n",
    "#         transformer_output = self.transformer(embeddings, embeddings)  # (batch_size, hidden_dim, seq_len)\n",
    "\n",
    "#         embeddings = embeddings.transpose(0, 1)\n",
    "        \n",
    "#         # Output layer to project back to embedding_dim\n",
    "#         logits = self.fc_out(transformer_output)  # (batch_size, hidden_dim, seq_len)\n",
    "\n",
    "#         logits = logits.transpose(0, 1).transpose(1, 2)\n",
    "        \n",
    "#         return logits\n",
    "\n",
    "#     def add_noise(self, token_embeddings, t, schedule):\n",
    "#         noisy_embeddings = token_embeddings.clone()\n",
    "#         noise_level = torch.sqrt(schedule.get_variance(t))\n",
    "\n",
    "#         # Vectorized noise addition for the batch\n",
    "#         noise = torch.normal(mean=0, std=noise_level, size=noisy_embeddings.shape).to(noisy_embeddings.device)\n",
    "#         noisy_embeddings = noisy_embeddings + noise\n",
    "#         return noisy_embeddings\n",
    "    \n",
    "#     def reverse_diffusion(self, noisy_input, schedule):\n",
    "#         x_t = noisy_input\n",
    "#         device = x_t.device\n",
    "\n",
    "#         for t in reversed(range(self.num_timesteps)):\n",
    "#             # Dynamically add positional encodings\n",
    "\n",
    "#             # Predict the noise at timestep t\n",
    "#             predicted_noise = self.forward(x_t)\n",
    "\n",
    "#             # Get schedule parameters\n",
    "#             alpha_t = schedule.get_alpha(t)\n",
    "#             beta_t = schedule.get_beta(t)\n",
    "\n",
    "#             # Compute the mean of x_{t-1}\n",
    "#             mean_x_prev = (x_t - beta_t*predicted_noise)/torch.sqrt(alpha_t)\n",
    "\n",
    "#             # Add stochastic Gaussian noise for intermediate steps\n",
    "#             if t > 0:\n",
    "#                 variance = beta_t\n",
    "#                 std_dev = torch.sqrt(variance)\n",
    "#                 noise = torch.randn_like(x_t, device=device) * std_dev\n",
    "#                 x_t = mean_x_prev + noise\n",
    "#             else:\n",
    "#                 x_t = mean_x_prev\n",
    "\n",
    "#             # Clamp the outputs to valid range\n",
    "#             x_t = torch.clamp(x_t, min=-1.0, max=1.0)\n",
    "\n",
    "#         return x_t\n",
    "\n",
    "# # Optimized loss function (MSE)\n",
    "# def denoising_loss(predicted_embeddings, clean_embeddings):\n",
    "#     \"\"\"MSE loss function for continuous embeddings.\"\"\"\n",
    "#     return nn.MSELoss()(predicted_embeddings,clean_embeddings)\n",
    "\n",
    "# class SymbolicRegressionDataset(Dataset):\n",
    "#     def __init__(self, data, vocab, max_seq_len, noise_schedule):\n",
    "#         self.data = data\n",
    "#         self.vocab = vocab\n",
    "#         self.max_seq_len = max_seq_len\n",
    "#         self.noise_schedule = noise_schedule\n",
    "\n",
    "#     def get_input_embeddings(self, tokens):\n",
    "#         \"\"\"Convert tokens to their continuous embeddings and pad to max_seq_len.\"\"\"\n",
    "#         embeddings = torch.stack([torch.tensor(token) for token in tokens])  # Default to 0 if token not in vocab\n",
    "#         padded_embeddings = torch.zeros((self.max_seq_len, embeddings.shape[1]))  # Assuming 2D embeddings\n",
    "#         padded_embeddings[:embeddings.size(0), :] = embeddings  # Pad sequences with zeros\n",
    "#         return padded_embeddings\n",
    "\n",
    "#     def add_noise(self, token_ids, t, schedule):\n",
    "#         \"\"\"Add noise to embeddings.\"\"\"\n",
    "#         noisy_embeddings = token_ids.clone()\n",
    "#         noise_level = torch.sqrt(schedule.get_variance(t))\n",
    "\n",
    "#         # Precompute noise for batch and apply it\n",
    "#         noise = torch.normal(mean=0.0, std=noise_level, size=noisy_embeddings.shape).to(noisy_embeddings.device)\n",
    "#         noisy_token_embeddings = noisy_embeddings + noise\n",
    "#         return torch.clamp(noisy_token_embeddings, min=0.0, max=1.0)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         data_point = self.data[idx]\n",
    "#         tokens = data_point['tokens']\n",
    "#         token_embeddings = self.get_input_embeddings(tokens)\n",
    "\n",
    "#         t = random.randint(0, self.noise_schedule.timesteps - 1)\n",
    "#         noisy_token_embeddings = self.add_noise(token_embeddings, t, self.noise_schedule)\n",
    "\n",
    "#         # Return noisy and clean embeddings in proper shape\n",
    "#         return noisy_token_embeddings.transpose(0, 1), token_embeddings.transpose(0, 1)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "\n",
    "# # Optimized training loop\n",
    "# def train_diffusion_model(model, train_loader, val_loader, num_epochs=10, patience_num_epochs=3):\n",
    "#     device = setup_device()\n",
    "#     model = model.to(device)\n",
    "#     optimizer = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)\n",
    "#     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode='min',patience=2,factor=0.5)\n",
    "#     schedule = CosineNoiseSchedule(timesteps=1000, device=device)\n",
    "    \n",
    "#     best_val_loss = float('inf')\n",
    "#     num_epochs_without_improvement = 0\n",
    "#     early_stopping = False\n",
    "#     performance_metrics = {\"epoch_list\": [], \"train_loss_list\": [], \"val_loss_list\": []}\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         model.train()\n",
    "#         total_loss = 0.0\n",
    "#         for noisy_tokens, target_embeddings in train_loader:\n",
    "#             noisy_tokens, target_embeddings = noisy_tokens.to(device), target_embeddings.to(device)\n",
    "#             optimizer.zero_grad()\n",
    "#             pred_embeddings = model(noisy_tokens)\n",
    "#             loss = denoising_loss(pred_embeddings, target_embeddings)\n",
    "#             loss.backward()\n",
    "#             torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "#             optimizer.step()\n",
    "\n",
    "#             total_loss += loss.item()\n",
    "        \n",
    "#         train_loss = total_loss / len(train_loader)\n",
    "#         performance_metrics['train_loss_list'].append(train_loss)\n",
    "        \n",
    "#         # Validation phase with reverse diffusion\n",
    "#         model.eval()\n",
    "#         val_loss = 0.0\n",
    "#         with torch.no_grad():\n",
    "#             for noisy_tokens, target_embeddings in val_loader:\n",
    "#                 noisy_tokens, target_embeddings = noisy_tokens.to(device), target_embeddings.to(device)\n",
    "\n",
    "#                 pred_embeddings = model.reverse_diffusion(noisy_tokens, schedule)\n",
    "#                 loss = denoising_loss(pred_embeddings, target_embeddings)\n",
    "#                 val_loss += loss.item()\n",
    "        \n",
    "#         val_loss = val_loss / len(val_loader)\n",
    "#         performance_metrics['val_loss_list'].append(val_loss)\n",
    "#         performance_metrics['epoch_list'].append(epoch + 1)\n",
    "\n",
    "#         print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss}, Val Loss: {val_loss}')\n",
    "\n",
    "#         scheduler.step(val_loss)\n",
    "\n",
    "#         if val_loss < best_val_loss:\n",
    "#             best_val_loss = val_loss\n",
    "#             save_model(model, \"best_diffusion_model.pt\")\n",
    "#             num_epochs_without_improvement = 0\n",
    "#         else:\n",
    "#             num_epochs_without_improvement += 1\n",
    "\n",
    "#         if num_epochs_without_improvement >= patience_num_epochs:\n",
    "#             print(f\"Training stopped early at epoch {epoch + 1}. Best validation loss: {best_val_loss}\")\n",
    "#             early_stopping = True\n",
    "#             break\n",
    "\n",
    "#     return model, performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example of loading and preparing the dataset\n",
    "# dataset = load_dataset('Data/preprocessed_data_with_embeddings.json')\n",
    "# vocab = load_JSON(\"Data/vocab_embeddings.json\")  # Vocabulary is a dictionary of continuous embeddings\n",
    "\n",
    "# MAX_LENGTH = determine_max_seq_len(dataset)  # Determine the max length dynamically\n",
    "\n",
    "# schedule = CosineNoiseSchedule(timesteps=1000,device=setup_device())\n",
    "\n",
    "# # First, perform the split on the raw dataset\n",
    "# train_size = int(0.7 * len(dataset))  # 70% for training\n",
    "# val_size = int(0.15 * len(dataset))  # 15% for validation\n",
    "# test_size = len(dataset) - train_size - val_size  # 15% for testing\n",
    "\n",
    "# # Perform random split\n",
    "# train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# train_dataset_SR = SymbolicRegressionDataset(train_dataset, vocab, MAX_LENGTH, schedule)\n",
    "# val_dataset_SR = SymbolicRegressionDataset(val_dataset, vocab, MAX_LENGTH, schedule)\n",
    "# test_dataset_SR = SymbolicRegressionDataset(test_dataset, vocab, MAX_LENGTH, schedule)\n",
    "\n",
    "# # Create DataLoader objects for each subset\n",
    "# train_loader = DataLoader(train_dataset_SR, batch_size=16, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset_SR, batch_size=16, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset_SR, batch_size=16, shuffle=True)\n",
    "\n",
    "# # Initialize the model\n",
    "# num_heads = 4  # Number of attention heads, ensure this is a divisor of embedding_dim\n",
    "# embedding_dim = 100  # The embedding dimension is 100 as per your problem\n",
    "# hidden_dim = embedding_dim  # Hidden dimension stays the same for simplicity\n",
    "\n",
    "# # Ensure embedding_dim is divisible by num_heads\n",
    "# if embedding_dim % num_heads != 0:\n",
    "#     raise ValueError(f\"embedding_dim ({embedding_dim}) must be divisible by num_heads ({num_heads}).\")\n",
    "\n",
    "# model = DiffusionModel(\n",
    "#     vocab_size=len(vocab),\n",
    "#     embedding_dim=embedding_dim,\n",
    "#     hidden_dim=hidden_dim,\n",
    "#     num_layers=4,\n",
    "#     num_heads=4,\n",
    "#     num_timesteps=1000,\n",
    "#     pretrained_embeddings=vocab\n",
    "# )\n",
    "\n",
    "# model,performance_metrics_DICT = train_diffusion_model(model,train_loader,val_loader,num_epochs=10,patience_num_epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# #Visualize the train and validation loss\n",
    "# def plot_train_valid(model_name,performance_metrics_DICT):\n",
    "#     plt.figure();\n",
    "#     plt.plot(performance_metrics_DICT['epoch_list'], performance_metrics_DICT['train_loss_list'], label=f'Train Loss', color='blue', linestyle='--', marker='o');\n",
    "#     plt.plot(performance_metrics_DICT['epoch_list'], performance_metrics_DICT['val_loss_list'], label=f'Validation Loss', color='green', linestyle='-', marker='x');\n",
    "#     plt.title(f'{model_name} Training and Validation Loss');\n",
    "#     plt.xlabel('Epochs');\n",
    "#     plt.ylabel('Loss');\n",
    "#     plt.legend();\n",
    "#     plt.grid();\n",
    "#     plt.xlim(0,max(performance_metrics_DICT['epoch_list'])+1);\n",
    "#     return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'Diffusion Model'\n",
    "\n",
    "# plot_train_valid(model_name,performance_metrics_DICT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def decode_embeddings_to_tokens(embeddings, vocab):\n",
    "#     vocab_embeddings = torch.stack([torch.tensor(embed) for embed in vocab.values()])\n",
    "    \n",
    "#     decoded_tokens = []\n",
    "#     for embedding in embeddings:\n",
    "#         # Compute the distance between the embedding and all vocab embeddings\n",
    "#         distances = torch.norm(embedding - vocab_embeddings, dim=1)\n",
    "#         closest_token_idx = torch.argmin(distances).item()\n",
    "#         closest_token = list(vocab.keys())[closest_token_idx]\n",
    "#         decoded_tokens.append(closest_token)\n",
    "    \n",
    "#     return decoded_tokens\n",
    "\n",
    "# def evaluate_diffusion_model(model, test_loader, vocab, schedule, device):\n",
    "#     model.eval()  # Set the model to evaluation mode\n",
    "#     total_test_loss = 0.0\n",
    "#     decoded_formulas = []\n",
    "#     actual_formulas = []\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for noisy_embeddings, target_embeddings in test_loader:\n",
    "#             # Get the predicted denoised embeddings\n",
    "#             t = random.randint(0, model.num_timesteps - 1)  # Random timestep for diffusion\n",
    "#             pred_embeddings = model.reverse_diffusion(noisy_embeddings, schedule)\n",
    "\n",
    "#             # Calculate the loss (MSE between predicted and target embeddings)\n",
    "#             loss = denoising_loss(pred_embeddings, target_embeddings)\n",
    "#             total_test_loss += loss.item()\n",
    "\n",
    "#             # Now, we need to decode the denoised embeddings back to tokens\n",
    "#             decoded_tokens = decode_embeddings_to_tokens(pred_embeddings, vocab)\n",
    "\n",
    "#             # Convert the decoded tokens to a formula string\n",
    "#             predicted_formula = \" \".join(decoded_tokens)\n",
    "#             decoded_formulas.append(predicted_formula)\n",
    "\n",
    "#             # Assuming target embeddings have a corresponding ground truth formula (you can adjust this part)\n",
    "#             actual_formula = decode_embeddings_to_tokens(target_embeddings, vocab)\n",
    "#             actual_formulas.append(\" \".join(actual_formula))\n",
    "\n",
    "#     # Calculate average test loss\n",
    "#     avg_test_loss = total_test_loss / len(test_loader)\n",
    "#     return avg_test_loss, decoded_formulas, actual_formulas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example of loading and preparing the dataset\n",
    "# dataset = load_dataset('Data/preprocessed_data_with_embeddings.json')\n",
    "# vocab = load_JSON(\"Data/vocab_embeddings.json\")  # Vocabulary is a dictionary of continuous embeddings\n",
    "\n",
    "# MAX_LENGTH = determine_max_seq_len(dataset)  # Determine the max length dynamically\n",
    "\n",
    "# schedule = CosineNoiseSchedule(timesteps=1000,device=setup_device())\n",
    "\n",
    "# # First, perform the split on the raw dataset\n",
    "# train_size = int(0.7 * len(dataset))  # 70% for training\n",
    "# val_size = int(0.15 * len(dataset))  # 15% for validation\n",
    "# test_size = len(dataset) - train_size - val_size  # 15% for testing\n",
    "\n",
    "# # Perform random split\n",
    "# train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# # Initialize the SymbolicRegressionDataset with the schedule for each subset\n",
    "# train_dataset_SR = SymbolicRegressionDataset(train_dataset, vocab, MAX_LENGTH, schedule)\n",
    "# val_dataset_SR = SymbolicRegressionDataset(val_dataset, vocab, MAX_LENGTH, schedule)\n",
    "# test_dataset_SR = SymbolicRegressionDataset(test_dataset, vocab, MAX_LENGTH, schedule)\n",
    "\n",
    "# # Create DataLoader objects for each subset\n",
    "# train_loader = DataLoader(train_dataset_SR, batch_size=16, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset_SR, batch_size=16, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset_SR, batch_size=16, shuffle=True)\n",
    "\n",
    "# # Initialize the model\n",
    "# num_heads = 4  # Number of attention heads, ensure this is a divisor of embedding_dim\n",
    "# embedding_dim = 100  # The embedding dimension is 100 as per your problem\n",
    "# hidden_dim = embedding_dim  # Hidden dimension stays the same for simplicity\n",
    "\n",
    "# # Ensure embedding_dim is divisible by num_heads\n",
    "# if embedding_dim % num_heads != 0:\n",
    "#     raise ValueError(f\"embedding_dim ({embedding_dim}) must be divisible by num_heads ({num_heads}).\")\n",
    "\n",
    "# model = DiffusionModel(\n",
    "#     vocab_size=len(vocab),\n",
    "#     embedding_dim=embedding_dim,\n",
    "#     hidden_dim=hidden_dim,\n",
    "#     num_layers=6,\n",
    "#     num_heads=num_heads,\n",
    "#     num_timesteps=1000,\n",
    "#     pretrained_embeddings=vocab\n",
    "# )\n",
    "\n",
    "# model, device = load_model(model, 'Data/best_diffusion_model.pt')\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example: Evaluate the model on the test set\n",
    "# test_loss, decoded_formulas, actual_formulas = evaluate_diffusion_model(model, test_loader, vocab, schedule, device)\n",
    "\n",
    "# # Print out the average test loss\n",
    "# print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "# # Print out the first few decoded formulas and their corresponding actual formulas\n",
    "# for predicted, actual in zip(decoded_formulas[:5], actual_formulas[:5]):\n",
    "#     print(f\"Predicted Formula: {predicted}\")\n",
    "#     print(f\"Actual Formula: {actual}\")\n",
    "#     print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Attempt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "\n",
    "# Set the random seed for replicability\n",
    "seed = 20777980\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "def determine_max_seq_len(data, max_length='max_length'):\n",
    "    \"\"\"Calculate the max sequence length dynamically if 'max_length' is used as an argument.\"\"\"\n",
    "    if max_length == 'max_length':\n",
    "        MAX_LENGTH = max(len(dp[\"tokens\"]) for dp in data)\n",
    "    else:\n",
    "        MAX_LENGTH = max_length\n",
    "    return MAX_LENGTH\n",
    "\n",
    "def setup_device():\n",
    "    \"\"\"Set up the device for training.\"\"\"\n",
    "    return torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def save_model(model, filepath):\n",
    "    \"\"\"Save the model's state dictionary.\"\"\"\n",
    "    torch.save(model.state_dict(), filepath)\n",
    "    return model\n",
    "\n",
    "def load_model(model, filepath):\n",
    "    \"\"\"Load a saved model state dictionary.\"\"\"\n",
    "    model.load_state_dict(torch.load(filepath))\n",
    "    model.eval()\n",
    "    device = setup_device()\n",
    "    model.to(device)\n",
    "    return model, device\n",
    "\n",
    "def load_dataset(file_path):\n",
    "    \"\"\"Load the dataset from a JSON file.\"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        dataset = [json.loads(line) for line in file]\n",
    "    return dataset\n",
    "\n",
    "def save_JSON(data, filename):\n",
    "    \"\"\"Save data to a JSON file.\"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "    return\n",
    "\n",
    "def load_JSON(filename):\n",
    "    \"\"\"Load a JSON file.\"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "class CosineNoiseSchedule:\n",
    "    def __init__(self, timesteps=1000, epsilon=1e-6, device=None):\n",
    "        self.timesteps = timesteps\n",
    "        self.epsilon = epsilon\n",
    "        self.device = device\n",
    "        \n",
    "        # Create alphas using a cosine schedule\n",
    "        self.alphas = torch.cos(torch.linspace(0, math.pi / 2, timesteps, device=device)) ** 2\n",
    "        self.betas = 1.0 - self.alphas\n",
    "        self.alpha_bar = torch.maximum(torch.cumprod(self.alphas, dim=0), torch.tensor(self.epsilon, device=self.alphas.device))\n",
    "\n",
    "    def get_alpha(self, t):\n",
    "        return self.alphas[t]\n",
    "\n",
    "    def get_beta(self, t):\n",
    "        return self.betas[t]\n",
    "\n",
    "    def get_variance(self, t):\n",
    "        return self.get_beta(t) * (1 - self.get_alpha(t))\n",
    "\n",
    "    def get_alpha_bar(self, t):\n",
    "        return self.alpha_bar[t]\n",
    "\n",
    "class DiffusionModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, num_heads, num_timesteps, max_seq_len=5000, pretrained_embeddings=None):\n",
    "        super(DiffusionModel, self).__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_timesteps = num_timesteps\n",
    "\n",
    "        if pretrained_embeddings is not None:\n",
    "            pretrained_embeddings = torch.tensor(list(pretrained_embeddings.values()), dtype=torch.float32)\n",
    "            if pretrained_embeddings.size(1) != embedding_dim:\n",
    "                raise ValueError(\n",
    "                    f\"Pretrained embeddings size {pretrained_embeddings.size(1)} does not match the required embedding_dim {embedding_dim}.\"\n",
    "                )\n",
    "            self.embedding = nn.Parameter(pretrained_embeddings)\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        self.projection = nn.Linear(embedding_dim, hidden_dim) if embedding_dim != hidden_dim else nn.Identity()\n",
    "        self.layer_norm = nn.LayerNorm(hidden_dim, eps=1e-6)\n",
    "\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=hidden_dim,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_layers,\n",
    "            num_decoder_layers=num_layers,\n",
    "            batch_first=False\n",
    "        )\n",
    "        \n",
    "        self.fc_out = nn.Linear(hidden_dim, embedding_dim)\n",
    "\n",
    "    def forward(self, embeddings):\n",
    "        batch_size, hidden_dim, seq_len = embeddings.shape\n",
    "        if self.embedding_dim != self.hidden_dim:\n",
    "            embeddings = self.projection(embeddings)\n",
    "        embeddings = embeddings.transpose(1, 2)\n",
    "        embeddings = self.layer_norm(embeddings)\n",
    "        embeddings = embeddings.transpose(0, 1)\n",
    "        transformer_output = self.transformer(embeddings, embeddings)\n",
    "        embeddings = embeddings.transpose(0, 1)\n",
    "        logits = self.fc_out(transformer_output)\n",
    "        logits = logits.transpose(0, 1).transpose(1, 2)\n",
    "        return logits\n",
    "\n",
    "    def add_noise(self, token_embeddings, t, schedule):\n",
    "        noise_level = torch.sqrt(schedule.get_variance(t))\n",
    "        noise = torch.normal(mean=0, std=noise_level, size=token_embeddings.shape).to(token_embeddings.device)\n",
    "        return token_embeddings + noise\n",
    "    \n",
    "    def reverse_diffusion(self, noisy_input, schedule):\n",
    "        x_t = noisy_input\n",
    "        device = x_t.device\n",
    "        for t in reversed(range(self.num_timesteps)):\n",
    "            predicted_noise = self.forward(x_t)\n",
    "            alpha_t = schedule.get_alpha(t)\n",
    "            beta_t = schedule.get_beta(t)\n",
    "            mean_x_prev = (x_t - beta_t * predicted_noise) / torch.sqrt(alpha_t)\n",
    "            if t > 0:\n",
    "                std_dev = torch.sqrt(beta_t)\n",
    "                noise = torch.randn_like(x_t, device=device) * std_dev\n",
    "                x_t = mean_x_prev + noise\n",
    "            else:\n",
    "                x_t = mean_x_prev\n",
    "            x_t = torch.clamp(x_t, min=-1.0, max=1.0)\n",
    "        return x_t\n",
    "\n",
    "def denoising_loss(predicted_embeddings, clean_embeddings, mask):\n",
    "    \"\"\"Masked MSE loss.\"\"\"\n",
    "    masked_pred = predicted_embeddings * mask\n",
    "    masked_clean = clean_embeddings * mask\n",
    "    return nn.MSELoss()(masked_pred, masked_clean)\n",
    "\n",
    "class SymbolicRegressionDataset(Dataset):\n",
    "    def __init__(self, data, vocab, max_seq_len, noise_schedule):\n",
    "        self.data = data\n",
    "        self.vocab = vocab  # Add vocab here\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.noise_schedule = noise_schedule\n",
    "\n",
    "    def get_input_embeddings(self, tokens):\n",
    "        embeddings = torch.stack([torch.tensor(token) for token in tokens])\n",
    "        padded_embeddings = torch.zeros((self.max_seq_len, embeddings.shape[1]))\n",
    "        padded_embeddings[:embeddings.size(0), :] = embeddings\n",
    "        padded_embeddings = padded_embeddings.transpose(0, 1)\n",
    "        return padded_embeddings\n",
    "\n",
    "    def add_noise(self, token_ids, t, schedule):\n",
    "        noisy_embeddings = token_ids.clone()\n",
    "        noise_level = torch.sqrt(schedule.get_variance(t))\n",
    "\n",
    "        # Precompute noise for batch and apply it\n",
    "        noise = torch.normal(mean=0.0, std=noise_level, size=noisy_embeddings.shape).to(noisy_embeddings.device)\n",
    "        noisy_token_embeddings = noisy_embeddings + noise\n",
    "        return torch.clamp(noisy_token_embeddings, min=0.0, max=1.0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_point = self.data[idx]\n",
    "        tokens = data_point['tokens']\n",
    "        current_data = data_point['data']\n",
    "        # Map symbols to embeddings using vocab\n",
    "        x = torch.tensor(current_data['x'], dtype=torch.float32)\n",
    "        y = torch.tensor(current_data['y'], dtype=torch.float32)\n",
    "        mask = torch.tensor(current_data['mask'], dtype=torch.float32)\n",
    "        token_embeddings = self.get_input_embeddings(tokens)\n",
    "        \n",
    "        t = random.randint(0, self.noise_schedule.timesteps - 1)\n",
    "        noisy_token_embeddings = self.add_noise(token_embeddings, t, self.noise_schedule)\n",
    "        noisy_x = x.clone()\n",
    "        noisy_x[mask == 1] = self.noise_schedule.add_noise(x[mask == 1], t)\n",
    "        noisy_y = y.clone()\n",
    "        noisy_y = self.noise_schedule.add_noise(y, t)\n",
    "        return token_embeddings, noisy_token_embeddings, noisy_x, noisy_y, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "def train_diffusion_model(model, train_loader, val_loader, num_epochs=10, patience_num_epochs=3):\n",
    "    device = setup_device()\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)\n",
    "    schedule = CosineNoiseSchedule(timesteps=1000, device=device)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    num_epochs_without_improvement = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for noisy_x, y, mask in train_loader:\n",
    "            noisy_x, y, mask = noisy_x.to(device), y.to(device), mask.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred_y = model(noisy_x)\n",
    "            loss = denoising_loss(pred_y, y, mask)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        val_loss = 0.0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for noisy_x, y, mask in val_loader:\n",
    "                noisy_x, y, mask = noisy_x.to(device), y.to(device), mask.to(device)\n",
    "                pred_y = model(noisy_x)\n",
    "                val_loss += denoising_loss(pred_y, y, mask).item()\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            save_model(model, \"best_model.pt\")\n",
    "        else:\n",
    "            num_epochs_without_improvement += 1\n",
    "            if num_epochs_without_improvement >= patience_num_epochs:\n",
    "                break\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "must be real number, not dict",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 45\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding_dim (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00membedding_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) must be divisible by num_heads (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_heads\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     35\u001b[0m model \u001b[38;5;241m=\u001b[39m DiffusionModel(\n\u001b[0;32m     36\u001b[0m     vocab_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(vocab),\n\u001b[0;32m     37\u001b[0m     embedding_dim\u001b[38;5;241m=\u001b[39membedding_dim,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     42\u001b[0m     pretrained_embeddings\u001b[38;5;241m=\u001b[39mvocab\n\u001b[0;32m     43\u001b[0m )\n\u001b[1;32m---> 45\u001b[0m model,performance_metrics_DICT \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_diffusion_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mpatience_num_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 212\u001b[0m, in \u001b[0;36mtrain_diffusion_model\u001b[1;34m(model, train_loader, val_loader, num_epochs, patience_num_epochs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m    211\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m--> 212\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnoisy_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnoisy_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnoisy_x\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\matth\\OneDrive - University of Waterloo\\Documents\\Python Files\\Environments\\STAT940_Final_Project_VENV\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\matth\\OneDrive - University of Waterloo\\Documents\\Python Files\\Environments\\STAT940_Final_Project_VENV\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\matth\\OneDrive - University of Waterloo\\Documents\\Python Files\\Environments\\STAT940_Final_Project_VENV\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\matth\\OneDrive - University of Waterloo\\Documents\\Python Files\\Environments\\STAT940_Final_Project_VENV\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[15], line 185\u001b[0m, in \u001b[0;36mSymbolicRegressionDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    183\u001b[0m current_data \u001b[38;5;241m=\u001b[39m data_point[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# Map symbols to embeddings using vocab\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(current_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m    187\u001b[0m mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(current_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m'\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[1;31mTypeError\u001b[0m: must be real number, not dict"
     ]
    }
   ],
   "source": [
    "# Example of loading and preparing the dataset\n",
    "dataset = load_dataset('Data/preprocessed_data_with_embeddings.json')\n",
    "vocab = load_JSON(\"Data/vocab_embeddings.json\")  # Vocabulary is a dictionary of continuous embeddings\n",
    "\n",
    "MAX_LENGTH = determine_max_seq_len(dataset)  # Determine the max length dynamically\n",
    "\n",
    "schedule = CosineNoiseSchedule(timesteps=1000,device=setup_device())\n",
    "\n",
    "# First, perform the split on the raw dataset\n",
    "train_size = int(0.7*len(dataset))  # 70% for training\n",
    "val_size = int(0.15*len(dataset))  # 15% for validation\n",
    "test_size = len(dataset) - train_size - val_size  # 15% for testing\n",
    "\n",
    "# Perform random split\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_dataset_SR = SymbolicRegressionDataset(train_dataset, vocab, MAX_LENGTH, schedule)\n",
    "val_dataset_SR = SymbolicRegressionDataset(val_dataset, vocab, MAX_LENGTH, schedule)\n",
    "test_dataset_SR = SymbolicRegressionDataset(test_dataset, vocab, MAX_LENGTH, schedule)\n",
    "\n",
    "# Create DataLoader objects for each subset\n",
    "train_loader = DataLoader(train_dataset_SR, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset_SR, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset_SR, batch_size=16, shuffle=True)\n",
    "\n",
    "# Initialize the model\n",
    "num_heads = 4  # Number of attention heads, ensure this is a divisor of embedding_dim\n",
    "embedding_dim = 100  # The embedding dimension is 100 as per your problem\n",
    "hidden_dim = embedding_dim  # Hidden dimension stays the same for simplicity\n",
    "\n",
    "# Ensure embedding_dim is divisible by num_heads\n",
    "if embedding_dim % num_heads != 0:\n",
    "    raise ValueError(f\"embedding_dim ({embedding_dim}) must be divisible by num_heads ({num_heads}).\")\n",
    "\n",
    "model = DiffusionModel(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_layers=4,\n",
    "    num_heads=4,\n",
    "    num_timesteps=1000,\n",
    "    pretrained_embeddings=vocab\n",
    ")\n",
    "\n",
    "model,performance_metrics_DICT = train_diffusion_model(model,train_loader,val_loader,num_epochs=10,patience_num_epochs=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "STAT940_Final_Project_VENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
