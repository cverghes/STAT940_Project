{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: f_473.json\n",
      "Formula: (gaussian(cos(var_0))+tanh((var_2+var_1)))\n",
      "Tokens: ['(', 'gaussian', '(', 'cos', '(', 'var_0', ')', ')', '+', 'tanh', '(', '(', 'var_2', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_189.json\n",
      "Formula: (gaussian(reverse(var_1))*gaussian((var_0*var_2)))\n",
      "Tokens: ['(', 'gaussian', '(', 'reverse', '(', 'var_1', ')', ')', '*', 'gaussian', '(', '(', 'var_0', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_536.json\n",
      "Formula: (neg(cosh(var_0))+pow_2((var_2*var_1)))\n",
      "Tokens: ['(', 'neg', '(', 'cosh', '(', 'var_0', ')', ')', '+', 'pow_2', '(', '(', 'var_2', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_166.json\n",
      "Formula: ((pow_2(var_1)*log(var_0))*neg(var_2))\n",
      "Tokens: ['(', '(', 'pow_2', '(', 'var_1', ')', '*', 'log', '(', 'var_0', ')', ')', '*', 'neg', '(', 'var_2', ')', ')']\n",
      "\n",
      "File: f_49.json\n",
      "Formula: ((C_0*(var_2*var_1))*sinh(sin(var_0)))\n",
      "Tokens: ['(', '(', 'C_0', '*', '(', 'var_2', '*', 'var_1', ')', ')', '*', 'sinh', '(', 'sin', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_424.json\n",
      "Formula: ((sin(var_1)*gaussian(var_2))*gaussian(log(var_0)))\n",
      "Tokens: ['(', '(', 'sin', '(', 'var_1', ')', '*', 'gaussian', '(', 'var_2', ')', ')', '*', 'gaussian', '(', 'log', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_8.json\n",
      "Formula: ((tanh(var_1)*tan(var_0))*cos(var_2))\n",
      "Tokens: ['(', '(', 'tanh', '(', 'var_1', ')', '*', 'tan', '(', 'var_0', ')', ')', '*', 'cos', '(', 'var_2', ')', ')']\n",
      "\n",
      "File: f_131.json\n",
      "Formula: (((var_2+var_0)+gaussian(var_1))*log((var_2+C_0)))\n",
      "Tokens: ['(', '(', '(', 'var_2', '+', 'var_0', ')', '+', 'gaussian', '(', 'var_1', ')', ')', '*', 'log', '(', '(', 'var_2', '+', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_561.json\n",
      "Formula: ((sqrt(var_1)+sqrt(var_2))+(tanh(var_1)+exp(var_0)))\n",
      "Tokens: ['(', '(', 'sqrt', '(', 'var_1', ')', '+', 'sqrt', '(', 'var_2', ')', ')', '+', '(', 'tanh', '(', 'var_1', ')', '+', 'exp', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_648.json\n",
      "Formula: (neg((var_1+var_0))+cos((var_2+var_0)))\n",
      "Tokens: ['(', 'neg', '(', '(', 'var_1', '+', 'var_0', ')', ')', '+', 'cos', '(', '(', 'var_2', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_218.json\n",
      "Formula: (sin((var_1+C_0))+cosh((var_0+var_2)))\n",
      "Tokens: ['(', 'sin', '(', '(', 'var_1', '+', 'C_0', ')', ')', '+', 'cosh', '(', '(', 'var_0', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_432.json\n",
      "Formula: ((reverse(var_1)+tanh(var_2))*sqrt(pow_2(var_0)))\n",
      "Tokens: ['(', '(', 'reverse', '(', 'var_1', ')', '+', 'tanh', '(', 'var_2', ')', ')', '*', 'sqrt', '(', 'pow_2', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_598.json\n",
      "Formula: ((cos(var_0)+tan(var_1))+sqrt(log(var_2)))\n",
      "Tokens: ['(', '(', 'cos', '(', 'var_0', ')', '+', 'tan', '(', 'var_1', ')', ')', '+', 'sqrt', '(', 'log', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_577.json\n",
      "Formula: (((var_0*C_0)*cosh(var_2))+exp((var_2*var_1)))\n",
      "Tokens: ['(', '(', '(', 'var_0', '*', 'C_0', ')', '*', 'cosh', '(', 'var_2', ')', ')', '+', 'exp', '(', '(', 'var_2', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_127.json\n",
      "Formula: ((tan(var_0)*tanh(var_1))+cosh(cos(var_2)))\n",
      "Tokens: ['(', '(', 'tan', '(', 'var_0', ')', '*', 'tanh', '(', 'var_1', ')', ')', '+', 'cosh', '(', 'cos', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_465.json\n",
      "Formula: (neg((var_1+var_2))*tanh(neg(var_0)))\n",
      "Tokens: ['(', 'neg', '(', '(', 'var_1', '+', 'var_2', ')', ')', '*', 'tanh', '(', 'neg', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_170.json\n",
      "Formula: (sqrt((var_2*var_1))+neg(cosh(var_0)))\n",
      "Tokens: ['(', 'sqrt', '(', '(', 'var_2', '*', 'var_1', ')', ')', '+', 'neg', '(', 'cosh', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_520.json\n",
      "Formula: (gaussian((var_1+var_2))+tan(neg(var_0)))\n",
      "Tokens: ['(', 'gaussian', '(', '(', 'var_1', '+', 'var_2', ')', ')', '+', 'tan', '(', 'neg', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_609.json\n",
      "Formula: (tan(reverse(var_0))+neg((var_2*var_1)))\n",
      "Tokens: ['(', 'tan', '(', 'reverse', '(', 'var_0', ')', ')', '+', 'neg', '(', '(', 'var_2', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_259.json\n",
      "Formula: (sin((var_0*var_1))*exp((var_2*var_0)))\n",
      "Tokens: ['(', 'sin', '(', '(', 'var_0', '*', 'var_1', ')', ')', '*', 'exp', '(', '(', 'var_2', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_73.json\n",
      "Formula: ((sinh(var_2)+tan(var_2))*((var_0*C_0)*var_1))\n",
      "Tokens: ['(', '(', 'sinh', '(', 'var_2', ')', '+', 'tan', '(', 'var_2', ')', ')', '*', '(', '(', 'var_0', '*', 'C_0', ')', '*', 'var_1', ')', ')']\n",
      "\n",
      "File: f_737.json\n",
      "Formula: (gaussian((var_2*var_1))*reverse(tan(var_0)))\n",
      "Tokens: ['(', 'gaussian', '(', '(', 'var_2', '*', 'var_1', ')', ')', '*', 'reverse', '(', 'tan', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_367.json\n",
      "Formula: (sqrt((var_1+var_0))*neg(log(var_2)))\n",
      "Tokens: ['(', 'sqrt', '(', '(', 'var_1', '+', 'var_0', ')', ')', '*', 'neg', '(', 'log', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_672.json\n",
      "Formula: ((cos(var_1)+sin(var_2))*log(cos(var_0)))\n",
      "Tokens: ['(', '(', 'cos', '(', 'var_1', ')', '+', 'sin', '(', 'var_2', ')', ')', '*', 'log', '(', 'cos', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_388.json\n",
      "Formula: (exp(tan(var_0))*tan((var_2*var_1)))\n",
      "Tokens: ['(', 'exp', '(', 'tan', '(', 'var_0', ')', ')', '*', 'tan', '(', '(', 'var_2', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_222.json\n",
      "Formula: reverse(((var_2+var_0)*(var_1+C_0)))\n",
      "Tokens: ['reverse', '(', '(', '(', 'var_2', '+', 'var_0', ')', '*', '(', 'var_1', '+', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_449.json\n",
      "Formula: ((sinh(var_2)*cos(var_0))+sqrt(reverse(var_1)))\n",
      "Tokens: ['(', '(', 'sinh', '(', 'var_2', ')', '*', 'cos', '(', 'var_0', ')', ')', '+', 'sqrt', '(', 'reverse', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_24.json\n",
      "Formula: (cos((var_0*var_2))*neg(log(var_1)))\n",
      "Tokens: ['(', 'cos', '(', '(', 'var_0', '*', 'var_2', ')', ')', '*', 'neg', '(', 'log', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_330.json\n",
      "Formula: (sin(reverse(var_0))*tanh((var_1*var_2)))\n",
      "Tokens: ['(', 'sin', '(', 'reverse', '(', 'var_0', ')', ')', '*', 'tanh', '(', '(', 'var_1', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_275.json\n",
      "Formula: ((sqrt(var_2)*sinh(var_1))*pow_2(reverse(var_0)))\n",
      "Tokens: ['(', '(', 'sqrt', '(', 'var_2', ')', '*', 'sinh', '(', 'var_1', ')', ')', '*', 'pow_2', '(', 'reverse', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_625.json\n",
      "Formula: ((reverse(var_1)*cosh(var_0))+sqrt(neg(var_2)))\n",
      "Tokens: ['(', '(', 'reverse', '(', 'var_1', ')', '*', 'cosh', '(', 'var_0', ')', ')', '+', 'sqrt', '(', 'neg', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_32.json\n",
      "Formula: (cosh(tanh(var_1))+cosh((var_0*var_2)))\n",
      "Tokens: ['(', 'cosh', '(', 'tanh', '(', 'var_1', ')', ')', '+', 'cosh', '(', '(', 'var_0', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_326.json\n",
      "Formula: ((log(var_2)+sinh(var_2))+reverse((var_1*var_0)))\n",
      "Tokens: ['(', '(', 'log', '(', 'var_2', ')', '+', 'sinh', '(', 'var_2', ')', ')', '+', 'reverse', '(', '(', 'var_1', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_633.json\n",
      "Formula: (sinh(neg(var_2))+tan((var_0*var_1)))\n",
      "Tokens: ['(', 'sinh', '(', 'neg', '(', 'var_2', ')', ')', '+', 'tan', '(', '(', 'var_0', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_263.json\n",
      "Formula: ((cos(var_2)+gaussian(var_0))*neg((var_1*C_0)))\n",
      "Tokens: ['(', '(', 'cos', '(', 'var_2', ')', '+', 'gaussian', '(', 'var_0', ')', ')', '*', 'neg', '(', '(', 'var_1', '*', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_408.json\n",
      "Formula: ((cos(var_0)*tanh(var_2))*pow_2((var_0+var_1)))\n",
      "Tokens: ['(', '(', 'cos', '(', 'var_0', ')', '*', 'tanh', '(', 'var_2', ')', ')', '*', 'pow_2', '(', '(', 'var_0', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_65.json\n",
      "Formula: (gaussian((var_1*var_0))+exp(sinh(var_2)))\n",
      "Tokens: ['(', 'gaussian', '(', '(', 'var_1', '*', 'var_0', ')', ')', '+', 'exp', '(', 'sinh', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_371.json\n",
      "Formula: ((cosh(var_1)*var_0)+log(sin(var_2)))\n",
      "Tokens: ['(', '(', 'cosh', '(', 'var_1', ')', '*', 'var_0', ')', '+', 'log', '(', 'sin', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_721.json\n",
      "Formula: (reverse((var_2+var_0))*cosh(gaussian(var_1)))\n",
      "Tokens: ['(', 'reverse', '(', '(', 'var_2', '+', 'var_0', ')', ')', '*', 'cosh', '(', 'gaussian', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_234.json\n",
      "Formula: (neg((var_1+var_2))+log(pow_2(var_0)))\n",
      "Tokens: ['(', 'neg', '(', '(', 'var_1', '+', 'var_2', ')', ')', '+', 'log', '(', 'pow_2', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_664.json\n",
      "Formula: cos((tan(var_2)*(var_1+var_0)))\n",
      "Tokens: ['cos', '(', '(', 'tan', '(', 'var_2', ')', '*', '(', 'var_1', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_613.json\n",
      "Formula: (cosh((var_0*var_2))*tanh(reverse(var_1)))\n",
      "Tokens: ['(', 'cosh', '(', '(', 'var_0', '*', 'var_2', ')', ')', '*', 'tanh', '(', 'reverse', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_243.json\n",
      "Formula: (sinh((var_1*var_0))*cos(sqrt(var_2)))\n",
      "Tokens: ['(', 'sinh', '(', '(', 'var_1', '*', 'var_0', ')', ')', '*', 'cos', '(', 'sqrt', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_306.json\n",
      "Formula: ((tan(var_2)+(var_1*var_0))+(sinh(var_1)*(var_1+C_0)))\n",
      "Tokens: ['(', '(', 'tan', '(', 'var_2', ')', '+', '(', 'var_1', '*', 'var_0', ')', ')', '+', '(', 'sinh', '(', 'var_1', ')', '*', '(', 'var_1', '+', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_12.json\n",
      "Formula: (cosh(cosh(var_2))+exp((var_1+var_0)))\n",
      "Tokens: ['(', 'cosh', '(', 'cosh', '(', 'var_2', ')', ')', '+', 'exp', '(', '(', 'var_1', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_185.json\n",
      "Formula: ((sin(var_0)+gaussian(var_2))*cos(pow_2(var_1)))\n",
      "Tokens: ['(', '(', 'sin', '(', 'var_0', ')', '+', 'gaussian', '(', 'var_2', ')', ')', '*', 'cos', '(', 'pow_2', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_490.json\n",
      "Formula: (log(neg(var_0))+log((var_2*var_1)))\n",
      "Tokens: ['(', 'log', '(', 'neg', '(', 'var_0', ')', ')', '+', 'log', '(', '(', 'var_2', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_214.json\n",
      "Formula: ((sqrt(var_1)+(var_1*var_2))+(C_0+var_0))\n",
      "Tokens: ['(', '(', 'sqrt', '(', 'var_1', ')', '+', '(', 'var_1', '*', 'var_2', ')', ')', '+', '(', 'C_0', '+', 'var_0', ')', ')']\n",
      "\n",
      "File: f_644.json\n",
      "Formula: ((reverse(var_1)*exp(var_0))*(sqrt(var_2)+cosh(var_1)))\n",
      "Tokens: ['(', '(', 'reverse', '(', 'var_1', ')', '*', 'exp', '(', 'var_0', ')', ')', '*', '(', 'sqrt', '(', 'var_2', ')', '+', 'cosh', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_351.json\n",
      "Formula: (neg(pow_2(var_2))*sinh((var_0*var_1)))\n",
      "Tokens: ['(', 'neg', '(', 'pow_2', '(', 'var_2', ')', ')', '*', 'sinh', '(', '(', 'var_0', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_701.json\n",
      "Formula: ((cosh(var_0)*cosh(var_1))*cosh(reverse(var_2)))\n",
      "Tokens: ['(', '(', 'cosh', '(', 'var_0', ')', '*', 'cosh', '(', 'var_1', ')', ')', '*', 'cosh', '(', 'reverse', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_428.json\n",
      "Formula: (((var_0*C_0)*cos(var_1))*cos(neg(var_2)))\n",
      "Tokens: ['(', '(', '(', 'var_0', '*', 'C_0', ')', '*', 'cos', '(', 'var_1', ')', ')', '*', 'cos', '(', 'neg', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_4.json\n",
      "Formula: ((sin(var_2)*var_0)*sqrt(reverse(var_1)))\n",
      "Tokens: ['(', '(', 'sin', '(', 'var_2', ')', '*', 'var_0', ')', '*', 'sqrt', '(', 'reverse', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_45.json\n",
      "Formula: (pow_2(tan(var_0))+pow_2((var_1*var_2)))\n",
      "Tokens: ['(', 'pow_2', '(', 'tan', '(', 'var_0', ')', ')', '+', 'pow_2', '(', '(', 'var_1', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_582.json\n",
      "Formula: ((tanh(var_0)*sqrt(var_2))*exp(cosh(var_1)))\n",
      "Tokens: ['(', '(', 'tanh', '(', 'var_0', ')', '*', 'sqrt', '(', 'var_2', ')', ')', '*', 'exp', '(', 'cosh', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_652.json\n",
      "Formula: (reverse((var_0+var_1))*pow_2(cos(var_2)))\n",
      "Tokens: ['(', 'reverse', '(', '(', 'var_0', '+', 'var_1', ')', ')', '*', 'pow_2', '(', 'cos', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_202.json\n",
      "Formula: (exp(cosh(var_1))*exp((var_0*var_2)))\n",
      "Tokens: ['(', 'exp', '(', 'cosh', '(', 'var_1', ')', ')', '*', 'exp', '(', '(', 'var_0', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_717.json\n",
      "Formula: exp(((var_0+var_1)+log(var_2)))\n",
      "Tokens: ['exp', '(', '(', '(', 'var_0', '+', 'var_1', ')', '+', 'log', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_347.json\n",
      "Formula: ((C_0*(var_1*var_0))+neg(gaussian(var_2)))\n",
      "Tokens: ['(', '(', 'C_0', '*', '(', 'var_1', '*', 'var_0', ')', ')', '+', 'neg', '(', 'gaussian', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_53.json\n",
      "Formula: (reverse((var_2*var_1))+pow_2(tanh(var_0)))\n",
      "Tokens: ['(', 'reverse', '(', '(', 'var_2', '*', 'var_1', ')', ')', '+', 'pow_2', '(', 'tanh', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_594.json\n",
      "Formula: (tanh((var_2*var_1))*sinh(var_0))\n",
      "Tokens: ['(', 'tanh', '(', '(', 'var_2', '*', 'var_1', ')', ')', '*', 'sinh', '(', 'var_0', ')', ')']\n",
      "\n",
      "File: f_255.json\n",
      "Formula: neg((sqrt(var_2)*(var_0+var_1)))\n",
      "Tokens: ['neg', '(', '(', 'sqrt', '(', 'var_2', ')', '*', '(', 'var_0', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_605.json\n",
      "Formula: (tan((var_0+C_0))+pow_2((var_1*var_2)))\n",
      "Tokens: ['(', 'tan', '(', '(', 'var_0', '+', 'C_0', ')', ')', '+', 'pow_2', '(', '(', 'var_1', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_310.json\n",
      "Formula: (tan((var_1*var_0))*tanh(reverse(var_2)))\n",
      "Tokens: ['(', 'tan', '(', '(', 'var_1', '*', 'var_0', ')', ')', '*', 'tanh', '(', 'reverse', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_740.json\n",
      "Formula: (reverse((var_2*var_0))*tan(reverse(var_1)))\n",
      "Tokens: ['(', 'reverse', '(', '(', 'var_2', '*', 'var_0', ')', ')', '*', 'tan', '(', 'reverse', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_469.json\n",
      "Formula: ((gaussian(var_0)+log(var_1))+tanh(neg(var_2)))\n",
      "Tokens: ['(', '(', 'gaussian', '(', 'var_0', ')', '+', 'log', '(', 'var_1', ')', ')', '+', 'tanh', '(', 'neg', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_193.json\n",
      "Formula: (neg((var_0*C_0))*neg((var_2*var_1)))\n",
      "Tokens: ['(', 'neg', '(', '(', 'var_0', '*', 'C_0', ')', ')', '*', 'neg', '(', '(', 'var_2', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_486.json\n",
      "Formula: (((var_1+var_0)+gaussian(var_2))*sin((var_1+var_0)))\n",
      "Tokens: ['(', '(', '(', 'var_1', '+', 'var_0', ')', '+', 'gaussian', '(', 'var_2', ')', ')', '*', 'sin', '(', '(', 'var_1', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_691.json\n",
      "Formula: ((pow_2(var_2)+pow_2(var_1))*cosh(var_0))\n",
      "Tokens: ['(', '(', 'pow_2', '(', 'var_2', ')', '+', 'pow_2', '(', 'var_1', ')', ')', '*', 'cosh', '(', 'var_0', ')', ')']\n",
      "\n",
      "File: f_384.json\n",
      "Formula: ((neg(var_1)*pow_2(var_0))*(sin(var_2)*(var_0*C_0)))\n",
      "Tokens: ['(', '(', 'neg', '(', 'var_1', ')', '*', 'pow_2', '(', 'var_0', ')', ')', '*', '(', 'sin', '(', 'var_2', ')', '*', '(', 'var_0', '*', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_90.json\n",
      "Formula: (((var_1*C_0)+var_2)+exp(cos(var_0)))\n",
      "Tokens: ['(', '(', '(', 'var_1', '*', 'C_0', ')', '+', 'var_2', ')', '+', 'exp', '(', 'cos', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_557.json\n",
      "Formula: (gaussian((var_2*var_0))*reverse(neg(var_1)))\n",
      "Tokens: ['(', 'gaussian', '(', '(', 'var_2', '*', 'var_0', ')', ')', '*', 'reverse', '(', 'neg', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_107.json\n",
      "Formula: (log(sinh(var_0))+neg((var_2*var_1)))\n",
      "Tokens: ['(', 'log', '(', 'sinh', '(', 'var_0', ')', ')', '+', 'neg', '(', '(', 'var_2', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_412.json\n",
      "Formula: ((tanh(var_2)*tanh(var_1))*tanh(sqrt(var_0)))\n",
      "Tokens: ['(', '(', 'tanh', '(', 'var_2', ')', '*', 'tanh', '(', 'var_1', ')', ')', '*', 'tanh', '(', 'sqrt', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_296.json\n",
      "Formula: (tanh(cosh(var_1))+sin((var_0*var_2)))\n",
      "Tokens: ['(', 'tanh', '(', 'cosh', '(', 'var_1', ')', ')', '+', 'sin', '(', '(', 'var_0', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_629.json\n",
      "Formula: (((var_1+var_0)+(var_0*var_2))*cos(reverse(var_2)))\n",
      "Tokens: ['(', '(', '(', 'var_1', '+', 'var_0', ')', '+', '(', 'var_0', '*', 'var_2', ')', ')', '*', 'cos', '(', 'reverse', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_279.json\n",
      "Formula: ((C_0*exp(var_0))+log((var_2+var_1)))\n",
      "Tokens: ['(', '(', 'C_0', '*', 'exp', '(', 'var_0', ')', ')', '+', 'log', '(', '(', 'var_2', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_150.json\n",
      "Formula: ((neg(var_2)+tanh(var_0))*tanh(reverse(var_1)))\n",
      "Tokens: ['(', '(', 'neg', '(', 'var_2', ')', '+', 'tanh', '(', 'var_0', ')', ')', '*', 'tanh', '(', 'reverse', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_500.json\n",
      "Formula: (pow_2((var_2*var_1))*tanh(log(var_0)))\n",
      "Tokens: ['(', 'pow_2', '(', '(', 'var_2', '*', 'var_1', ')', ')', '*', 'tanh', '(', 'log', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_28.json\n",
      "Formula: ((sin(var_2)*(var_0*C_0))*sin(neg(var_1)))\n",
      "Tokens: ['(', '(', 'sin', '(', 'var_2', ')', '*', '(', 'var_0', '*', 'C_0', ')', ')', '*', 'sin', '(', 'neg', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_445.json\n",
      "Formula: ((C_0+var_1)*(sinh(var_2)*sqrt(var_0)))\n",
      "Tokens: ['(', '(', 'C_0', '+', 'var_1', ')', '*', '(', 'sinh', '(', 'var_2', ')', '*', 'sqrt', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_280.json\n",
      "Formula: (neg((var_1+var_0))*sinh(pow_2(var_2)))\n",
      "Tokens: ['(', 'neg', '(', '(', 'var_1', '+', 'var_0', ')', ')', '*', 'sinh', '(', 'pow_2', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_516.json\n",
      "Formula: (neg(cos(var_0))*log((var_1+var_2)))\n",
      "Tokens: ['(', 'neg', '(', 'cos', '(', 'var_0', ')', ')', '*', 'log', '(', '(', 'var_1', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_146.json\n",
      "Formula: ((C_0+C_1)+((var_0+var_1)*var_2))\n",
      "Tokens: ['(', '(', 'C_0', '+', 'C_1', ')', '+', '(', '(', 'var_0', '+', 'var_1', ')', '*', 'var_2', ')', ')']\n",
      "\n",
      "File: f_453.json\n",
      "Formula: (((var_0+C_0)+exp(var_1))*tanh(reverse(var_2)))\n",
      "Tokens: ['(', '(', '(', 'var_0', '+', 'C_0', ')', '+', 'exp', '(', 'var_1', ')', ')', '*', 'tanh', '(', 'reverse', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_687.json\n",
      "Formula: (reverse((var_0+C_0))+pow_2((var_2+var_1)))\n",
      "Tokens: ['(', 'reverse', '(', '(', 'var_0', '+', 'C_0', ')', ')', '+', 'pow_2', '(', '(', 'var_2', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_668.json\n",
      "Formula: ((reverse(var_2)+cos(var_0))+sqrt(cosh(var_1)))\n",
      "Tokens: ['(', '(', 'reverse', '(', 'var_2', ')', '+', 'cos', '(', 'var_0', ')', ')', '+', 'sqrt', '(', 'cosh', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_392.json\n",
      "Formula: (reverse(gaussian(var_0))*neg((var_1*var_2)))\n",
      "Tokens: ['(', 'reverse', '(', 'gaussian', '(', 'var_0', ')', ')', '*', 'neg', '(', '(', 'var_1', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_238.json\n",
      "Formula: ((pow_2(var_1)*tan(var_0))+neg(pow_2(var_2)))\n",
      "Tokens: ['(', '(', 'pow_2', '(', 'var_1', ')', '*', 'tan', '(', 'var_0', ')', ')', '+', 'neg', '(', 'pow_2', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_111.json\n",
      "Formula: ((gaussian(var_1)+(var_0*C_0))+sqrt(var_2))\n",
      "Tokens: ['(', '(', 'gaussian', '(', 'var_1', ')', '+', '(', 'var_0', '*', 'C_0', ')', ')', '+', 'sqrt', '(', 'var_2', ')', ')']\n",
      "\n",
      "File: f_86.json\n",
      "Formula: (sinh(exp(var_0))+neg((var_2+var_1)))\n",
      "Tokens: ['(', 'sinh', '(', 'exp', '(', 'var_0', ')', ')', '+', 'neg', '(', '(', 'var_2', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_541.json\n",
      "Formula: (exp((var_2*var_1))+exp((var_2+var_0)))\n",
      "Tokens: ['(', 'exp', '(', '(', 'var_2', '*', 'var_1', ')', ')', '+', 'exp', '(', '(', 'var_2', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_69.json\n",
      "Formula: ((tanh(var_2)+(var_1*C_0))*(neg(var_2)+cos(var_0)))\n",
      "Tokens: ['(', '(', 'tanh', '(', 'var_2', ')', '+', '(', 'var_1', '*', 'C_0', ')', ')', '*', '(', 'neg', '(', 'var_2', ')', '+', 'cos', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_404.json\n",
      "Formula: (sinh(reverse(var_1))+tan((var_2*var_0)))\n",
      "Tokens: ['(', 'sinh', '(', 'reverse', '(', 'var_1', ')', ')', '+', 'tan', '(', '(', 'var_2', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_110.json\n",
      "Formula: (log((var_1+var_0))*sqrt((var_2+C_0)))\n",
      "Tokens: ['(', 'log', '(', '(', 'var_1', '+', 'var_0', ')', ')', '*', 'sqrt', '(', '(', 'var_2', '+', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_540.json\n",
      "Formula: (tan((var_0*var_2))+reverse(gaussian(var_1)))\n",
      "Tokens: ['(', 'tan', '(', '(', 'var_0', '*', 'var_2', ')', ')', '+', 'reverse', '(', 'gaussian', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_87.json\n",
      "Formula: (((var_1+var_2)+tanh(var_2))+(tanh(var_0)*tanh(var_2)))\n",
      "Tokens: ['(', '(', '(', 'var_1', '+', 'var_2', ')', '+', 'tanh', '(', 'var_2', ')', ')', '+', '(', 'tanh', '(', 'var_0', ')', '*', 'tanh', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_68.json\n",
      "Formula: (reverse(tanh(var_1))+log((var_2*var_0)))\n",
      "Tokens: ['(', 'reverse', '(', 'tanh', '(', 'var_1', ')', ')', '+', 'log', '(', '(', 'var_2', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_405.json\n",
      "Formula: ((neg(var_2)*(var_0+C_0))*reverse(exp(var_1)))\n",
      "Tokens: ['(', '(', 'neg', '(', 'var_2', ')', '*', '(', 'var_0', '+', 'C_0', ')', ')', '*', 'reverse', '(', 'exp', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_686.json\n",
      "Formula: (gaussian((var_1+var_2))+log(tanh(var_0)))\n",
      "Tokens: ['(', 'gaussian', '(', '(', 'var_1', '+', 'var_2', ')', ')', '+', 'log', '(', 'tanh', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_669.json\n",
      "Formula: (((var_1+var_1)*cosh(var_0))*reverse((var_2+C_0)))\n",
      "Tokens: ['(', '(', '(', 'var_1', '+', 'var_1', ')', '*', 'cosh', '(', 'var_0', ')', ')', '*', 'reverse', '(', '(', 'var_2', '+', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_393.json\n",
      "Formula: (exp((var_1*var_2))*gaussian(sin(var_0)))\n",
      "Tokens: ['(', 'exp', '(', '(', 'var_1', '*', 'var_2', ')', ')', '*', 'gaussian', '(', 'sin', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_239.json\n",
      "Formula: (neg((var_2+C_0))*tan((var_0+var_1)))\n",
      "Tokens: ['(', 'neg', '(', '(', 'var_2', '+', 'C_0', ')', ')', '*', 'tan', '(', '(', 'var_0', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_517.json\n",
      "Formula: (tan((var_0+var_2))*log(tanh(var_1)))\n",
      "Tokens: ['(', 'tan', '(', '(', 'var_0', '+', 'var_2', ')', ')', '*', 'log', '(', 'tanh', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_147.json\n",
      "Formula: (((var_1*C_0)+cos(var_0))+((var_2+C_1)+C_2))\n",
      "Tokens: ['(', '(', '(', 'var_1', '*', 'C_0', ')', '+', 'cos', '(', 'var_0', ')', ')', '+', '(', '(', 'var_2', '+', 'C_1', ')', '+', 'C_2', ')', ')']\n",
      "\n",
      "File: f_452.json\n",
      "Formula: ((var_2*(var_1+var_0))+(exp(var_2)+sin(var_2)))\n",
      "Tokens: ['(', '(', 'var_2', '*', '(', 'var_1', '+', 'var_0', ')', ')', '+', '(', 'exp', '(', 'var_2', ')', '+', 'sin', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_281.json\n",
      "Formula: ((sqrt(var_2)+tanh(var_0))*exp(pow_2(var_1)))\n",
      "Tokens: ['(', '(', 'sqrt', '(', 'var_2', ')', '+', 'tanh', '(', 'var_0', ')', ')', '*', 'exp', '(', 'pow_2', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_151.json\n",
      "Formula: (tan((var_2*C_0))+neg((var_0*var_1)))\n",
      "Tokens: ['(', 'tan', '(', '(', 'var_2', '*', 'C_0', ')', ')', '+', 'neg', '(', '(', 'var_0', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_501.json\n",
      "Formula: log(((var_1+var_2)+(var_0*C_0)))\n",
      "Tokens: ['log', '(', '(', '(', 'var_1', '+', 'var_2', ')', '+', '(', 'var_0', '*', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_29.json\n",
      "Formula: ((sin(var_2)+cosh(var_0))*gaussian(tanh(var_1)))\n",
      "Tokens: ['(', '(', 'sin', '(', 'var_2', ')', '+', 'cosh', '(', 'var_0', ')', ')', '*', 'gaussian', '(', 'tanh', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_444.json\n",
      "Formula: ((cos(var_0)*cos(var_2))*sinh(neg(var_1)))\n",
      "Tokens: ['(', '(', 'cos', '(', 'var_0', ')', '*', 'cos', '(', 'var_2', ')', ')', '*', 'sinh', '(', 'neg', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_297.json\n",
      "Formula: (log((var_2*C_0))+sin((var_1*var_0)))\n",
      "Tokens: ['(', 'log', '(', '(', 'var_2', '*', 'C_0', ')', ')', '+', 'sin', '(', '(', 'var_1', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_628.json\n",
      "Formula: ((cos(var_2)+cosh(var_2))*((var_0+C_0)+gaussian(var_1)))\n",
      "Tokens: ['(', '(', 'cos', '(', 'var_2', ')', '+', 'cosh', '(', 'var_2', ')', ')', '*', '(', '(', 'var_0', '+', 'C_0', ')', '+', 'gaussian', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_278.json\n",
      "Formula: log(((var_2+var_1)*tanh(var_0)))\n",
      "Tokens: ['log', '(', '(', '(', 'var_2', '+', 'var_1', ')', '*', 'tanh', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_556.json\n",
      "Formula: (sqrt((var_0+var_1))*gaussian(reverse(var_2)))\n",
      "Tokens: ['(', 'sqrt', '(', '(', 'var_0', '+', 'var_1', ')', ')', '*', 'gaussian', '(', 'reverse', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_91.json\n",
      "Formula: ((tanh(var_0)+tan(var_2))*sqrt(tanh(var_1)))\n",
      "Tokens: ['(', '(', 'tanh', '(', 'var_0', ')', '+', 'tan', '(', 'var_2', ')', ')', '*', 'sqrt', '(', 'tanh', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_106.json\n",
      "Formula: (sinh(tanh(var_0))+cos((var_1*var_2)))\n",
      "Tokens: ['(', 'sinh', '(', 'tanh', '(', 'var_0', ')', ')', '+', 'cos', '(', '(', 'var_1', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_413.json\n",
      "Formula: (tan((var_2*var_0))+gaussian((var_1+var_2)))\n",
      "Tokens: ['(', 'tan', '(', '(', 'var_2', '*', 'var_0', ')', ')', '+', 'gaussian', '(', '(', 'var_1', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_690.json\n",
      "Formula: (((var_2+var_2)+(var_1+var_0))*log(reverse(var_1)))\n",
      "Tokens: ['(', '(', '(', 'var_2', '+', 'var_2', ')', '+', '(', 'var_1', '+', 'var_0', ')', ')', '*', 'log', '(', 'reverse', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_385.json\n",
      "Formula: ((neg(var_0)+pow_2(var_0))+tan((var_1+var_2)))\n",
      "Tokens: ['(', '(', 'neg', '(', 'var_0', ')', '+', 'pow_2', '(', 'var_0', ')', ')', '+', 'tan', '(', '(', 'var_1', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_468.json\n",
      "Formula: ((pow_2(var_1)*neg(var_0))+tanh(cos(var_2)))\n",
      "Tokens: ['(', '(', 'pow_2', '(', 'var_1', ')', '*', 'neg', '(', 'var_0', ')', ')', '+', 'tanh', '(', 'cos', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_192.json\n",
      "Formula: (tan((var_2*var_1))+sin(neg(var_0)))\n",
      "Tokens: ['(', 'tan', '(', '(', 'var_2', '*', 'var_1', ')', ')', '+', 'sin', '(', 'neg', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_487.json\n",
      "Formula: (((var_2*C_0)+tan(var_1))*pow_2((var_0*var_0)))\n",
      "Tokens: ['(', '(', '(', 'var_2', '*', 'C_0', ')', '+', 'tan', '(', 'var_1', ')', ')', '*', 'pow_2', '(', '(', 'var_0', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_254.json\n",
      "Formula: (((var_0+C_0)+pow_2(var_2))+sinh(tan(var_1)))\n",
      "Tokens: ['(', '(', '(', 'var_0', '+', 'C_0', ')', '+', 'pow_2', '(', 'var_2', ')', ')', '+', 'sinh', '(', 'tan', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_604.json\n",
      "Formula: ((tan(var_2)*tanh(var_0))*cos(gaussian(var_1)))\n",
      "Tokens: ['(', '(', 'tan', '(', 'var_2', ')', '*', 'tanh', '(', 'var_0', ')', ')', '*', 'cos', '(', 'gaussian', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_311.json\n",
      "Formula: reverse((exp(var_1)+(var_2*var_0)))\n",
      "Tokens: ['reverse', '(', '(', 'exp', '(', 'var_1', ')', '+', '(', 'var_2', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_741.json\n",
      "Formula: ((C_0+(var_0+var_2))*pow_2(log(var_1)))\n",
      "Tokens: ['(', '(', 'C_0', '+', '(', 'var_0', '+', 'var_2', ')', ')', '*', 'pow_2', '(', 'log', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_595.json\n",
      "Formula: (gaussian(tan(var_0))*exp((var_1*var_2)))\n",
      "Tokens: ['(', 'gaussian', '(', 'tan', '(', 'var_0', ')', ')', '*', 'exp', '(', '(', 'var_1', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_52.json\n",
      "Formula: (pow_2(sin(var_1))+reverse((var_2+var_0)))\n",
      "Tokens: ['(', 'pow_2', '(', 'sin', '(', 'var_1', ')', ')', '+', 'reverse', '(', '(', 'var_2', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_653.json\n",
      "Formula: (cosh((var_2*var_1))*cosh((var_0*C_0)))\n",
      "Tokens: ['(', 'cosh', '(', '(', 'var_2', '*', 'var_1', ')', ')', '*', 'cosh', '(', '(', 'var_0', '*', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_203.json\n",
      "Formula: (tan((var_0*var_1))*exp(var_2))\n",
      "Tokens: ['(', 'tan', '(', '(', 'var_0', '*', 'var_1', ')', ')', '*', 'exp', '(', 'var_2', ')', ')']\n",
      "\n",
      "File: f_716.json\n",
      "Formula: (neg(exp(var_2))+sin((var_0+var_1)))\n",
      "Tokens: ['(', 'neg', '(', 'exp', '(', 'var_2', ')', ')', '+', 'sin', '(', '(', 'var_0', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_346.json\n",
      "Formula: (sin((var_1*var_0))+log(gaussian(var_2)))\n",
      "Tokens: ['(', 'sin', '(', '(', 'var_1', '*', 'var_0', ')', ')', '+', 'log', '(', 'gaussian', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_429.json\n",
      "Formula: (neg(gaussian(var_0))+sinh((var_1+var_2)))\n",
      "Tokens: ['(', 'neg', '(', 'gaussian', '(', 'var_0', ')', ')', '+', 'sinh', '(', '(', 'var_1', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_5.json\n",
      "Formula: (pow_2(tan(var_0))+exp((var_2*var_1)))\n",
      "Tokens: ['(', 'pow_2', '(', 'tan', '(', 'var_0', ')', ')', '+', 'exp', '(', '(', 'var_2', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_583.json\n",
      "Formula: (log((var_1+var_0))+log(cos(var_2)))\n",
      "Tokens: ['(', 'log', '(', '(', 'var_1', '+', 'var_0', ')', ')', '+', 'log', '(', 'cos', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_44.json\n",
      "Formula: ((pow_2(var_1)+(var_2*C_0))*cos((var_0*C_1)))\n",
      "Tokens: ['(', '(', 'pow_2', '(', 'var_1', ')', '+', '(', 'var_2', '*', 'C_0', ')', ')', '*', 'cos', '(', '(', 'var_0', '*', 'C_1', ')', ')', ')']\n",
      "\n",
      "File: f_215.json\n",
      "Formula: (sqrt((var_1+var_2))+gaussian(pow_2(var_0)))\n",
      "Tokens: ['(', 'sqrt', '(', '(', 'var_1', '+', 'var_2', ')', ')', '+', 'gaussian', '(', 'pow_2', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_645.json\n",
      "Formula: (log((var_0+C_0))*sinh((var_1+var_2)))\n",
      "Tokens: ['(', 'log', '(', '(', 'var_0', '+', 'C_0', ')', ')', '*', 'sinh', '(', '(', 'var_1', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_350.json\n",
      "Formula: (log((var_2+var_0))+tanh((var_1*var_1)))\n",
      "Tokens: ['(', 'log', '(', '(', 'var_2', '+', 'var_0', ')', ')', '+', 'tanh', '(', '(', 'var_1', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_700.json\n",
      "Formula: (sinh((var_2*var_1))+tanh(log(var_0)))\n",
      "Tokens: ['(', 'sinh', '(', '(', 'var_2', '*', 'var_1', ')', ')', '+', 'tanh', '(', 'log', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_13.json\n",
      "Formula: (sqrt(sinh(var_0))*pow_2((var_2*var_1)))\n",
      "Tokens: ['(', 'sqrt', '(', 'sinh', '(', 'var_0', ')', ')', '*', 'pow_2', '(', '(', 'var_2', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_184.json\n",
      "Formula: ((exp(var_0)*var_2)+reverse(neg(var_1)))\n",
      "Tokens: ['(', '(', 'exp', '(', 'var_0', ')', '*', 'var_2', ')', '+', 'reverse', '(', 'neg', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_491.json\n",
      "Formula: (sin((var_1*var_2))*sinh(gaussian(var_0)))\n",
      "Tokens: ['(', 'sin', '(', '(', 'var_1', '*', 'var_2', ')', ')', '*', 'sinh', '(', 'gaussian', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_612.json\n",
      "Formula: (neg((var_0*var_1))*reverse(var_2))\n",
      "Tokens: ['(', 'neg', '(', '(', 'var_0', '*', 'var_1', ')', ')', '*', 'reverse', '(', 'var_2', ')', ')']\n",
      "\n",
      "File: f_242.json\n",
      "Formula: (pow_2(gaussian(var_0))*sinh((var_2+var_1)))\n",
      "Tokens: ['(', 'pow_2', '(', 'gaussian', '(', 'var_0', ')', ')', '*', 'sinh', '(', '(', 'var_2', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_307.json\n",
      "Formula: ((tan(var_0)*neg(var_1))*sinh(sqrt(var_2)))\n",
      "Tokens: ['(', '(', 'tan', '(', 'var_0', ')', '*', 'neg', '(', 'var_1', ')', ')', '*', 'sinh', '(', 'sqrt', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_370.json\n",
      "Formula: (cos((var_1*var_2))*tanh(pow_2(var_0)))\n",
      "Tokens: ['(', 'cos', '(', '(', 'var_1', '*', 'var_2', ')', ')', '*', 'tanh', '(', 'pow_2', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_720.json\n",
      "Formula: (cosh(log(var_0))+gaussian((var_2*var_1)))\n",
      "Tokens: ['(', 'cosh', '(', 'log', '(', 'var_0', ')', ')', '+', 'gaussian', '(', '(', 'var_2', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_235.json\n",
      "Formula: (((var_2*var_2)+(var_0+C_0))*tan((var_2+var_1)))\n",
      "Tokens: ['(', '(', '(', 'var_2', '*', 'var_2', ')', '+', '(', 'var_0', '+', 'C_0', ')', ')', '*', 'tan', '(', '(', 'var_2', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_665.json\n",
      "Formula: (((var_0+C_0)*neg(var_2))*(exp(var_2)*(var_1+C_1)))\n",
      "Tokens: ['(', '(', '(', 'var_0', '+', 'C_0', ')', '*', 'neg', '(', 'var_2', ')', ')', '*', '(', 'exp', '(', 'var_2', ')', '*', '(', 'var_1', '+', 'C_1', ')', ')', ')']\n",
      "\n",
      "File: f_409.json\n",
      "Formula: (pow_2(sinh(var_2))+neg((var_0*var_1)))\n",
      "Tokens: ['(', 'pow_2', '(', 'sinh', '(', 'var_2', ')', ')', '+', 'neg', '(', '(', 'var_0', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_64.json\n",
      "Formula: (pow_2((var_2*var_0))+log((var_1+C_0)))\n",
      "Tokens: ['(', 'pow_2', '(', '(', 'var_2', '*', 'var_0', ')', ')', '+', 'log', '(', '(', 'var_1', '+', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_327.json\n",
      "Formula: (cosh((var_1*var_2))*cosh(tanh(var_0)))\n",
      "Tokens: ['(', 'cosh', '(', '(', 'var_1', '*', 'var_2', ')', ')', '*', 'cosh', '(', 'tanh', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_632.json\n",
      "Formula: ((var_1*(var_0+var_2))*tanh(cos(var_0)))\n",
      "Tokens: ['(', '(', 'var_1', '*', '(', 'var_0', '+', 'var_2', ')', ')', '*', 'tanh', '(', 'cos', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_262.json\n",
      "Formula: (sinh(pow_2(var_2))+sqrt((var_0+var_1)))\n",
      "Tokens: ['(', 'sinh', '(', 'pow_2', '(', 'var_2', ')', ')', '+', 'sqrt', '(', '(', 'var_0', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_33.json\n",
      "Formula: (neg(sqrt(var_1))*reverse((var_0+var_2)))\n",
      "Tokens: ['(', 'neg', '(', 'sqrt', '(', 'var_1', ')', ')', '*', 'reverse', '(', '(', 'var_0', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_331.json\n",
      "Formula: (cosh(neg(var_0))+cos((var_1+var_2)))\n",
      "Tokens: ['(', 'cosh', '(', 'neg', '(', 'var_0', ')', ')', '+', 'cos', '(', '(', 'var_1', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_274.json\n",
      "Formula: (tanh((var_1+var_0))+tanh(sinh(var_2)))\n",
      "Tokens: ['(', 'tanh', '(', '(', 'var_1', '+', 'var_0', ')', ')', '+', 'tanh', '(', 'sinh', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_624.json\n",
      "Formula: (tan((var_0*var_2))*cos(reverse(var_1)))\n",
      "Tokens: ['(', 'tan', '(', '(', 'var_0', '*', 'var_2', ')', ')', '*', 'cos', '(', 'reverse', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_448.json\n",
      "Formula: (log((var_2+var_1))+cosh(neg(var_0)))\n",
      "Tokens: ['(', 'log', '(', '(', 'var_2', '+', 'var_1', ')', ')', '+', 'cosh', '(', 'neg', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_25.json\n",
      "Formula: (cosh(tan(var_2))+exp((var_1+var_0)))\n",
      "Tokens: ['(', 'cosh', '(', 'tan', '(', 'var_2', ')', ')', '+', 'exp', '(', '(', 'var_1', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_736.json\n",
      "Formula: (tanh((var_0*var_1))+gaussian(reverse(var_2)))\n",
      "Tokens: ['(', 'tanh', '(', '(', 'var_0', '*', 'var_1', ')', ')', '+', 'gaussian', '(', 'reverse', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_366.json\n",
      "Formula: ((cos(var_0)*log(var_2))*log(sqrt(var_1)))\n",
      "Tokens: ['(', '(', 'cos', '(', 'var_0', ')', '*', 'log', '(', 'var_2', ')', ')', '*', 'log', '(', 'sqrt', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_673.json\n",
      "Formula: (exp((var_0+var_2))*tan(sqrt(var_1)))\n",
      "Tokens: ['(', 'exp', '(', '(', 'var_0', '+', 'var_2', ')', ')', '*', 'tan', '(', 'sqrt', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_389.json\n",
      "Formula: (((var_0*C_0)*(var_1*C_1))*cosh(neg(var_2)))\n",
      "Tokens: ['(', '(', '(', 'var_0', '*', 'C_0', ')', '*', '(', 'var_1', '*', 'C_1', ')', ')', '*', 'cosh', '(', 'neg', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_223.json\n",
      "Formula: ((reverse(var_0)*log(var_2))+pow_2(cos(var_1)))\n",
      "Tokens: ['(', '(', 'reverse', '(', 'var_0', ')', '*', 'log', '(', 'var_2', ')', ')', '+', 'pow_2', '(', 'cos', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_72.json\n",
      "Formula: (neg(reverse(var_1))*sqrt((var_2+var_0)))\n",
      "Tokens: ['(', 'neg', '(', 'reverse', '(', 'var_1', ')', ')', '*', 'sqrt', '(', '(', 'var_2', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_608.json\n",
      "Formula: ((neg(var_1)+C_0)*cos((var_0+var_2)))\n",
      "Tokens: ['(', '(', 'neg', '(', 'var_1', ')', '+', 'C_0', ')', '*', 'cos', '(', '(', 'var_0', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_258.json\n",
      "Formula: ((tan(var_0)*(var_2+C_0))+exp(reverse(var_1)))\n",
      "Tokens: ['(', '(', 'tan', '(', 'var_0', ')', '*', '(', 'var_2', '+', 'C_0', ')', ')', '+', 'exp', '(', 'reverse', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_464.json\n",
      "Formula: ((reverse(var_0)*(var_2+C_0))+pow_2(log(var_1)))\n",
      "Tokens: ['(', '(', 'reverse', '(', 'var_0', ')', '*', '(', 'var_2', '+', 'C_0', ')', ')', '+', 'pow_2', '(', 'log', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_171.json\n",
      "Formula: (cosh(reverse(var_1))+cosh((var_0+var_2)))\n",
      "Tokens: ['(', 'cosh', '(', 'reverse', '(', 'var_1', ')', ')', '+', 'cosh', '(', '(', 'var_0', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_521.json\n",
      "Formula: (tanh(var_2)*log((var_0*var_1)))\n",
      "Tokens: ['(', 'tanh', '(', 'var_2', ')', '*', 'log', '(', '(', 'var_0', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_433.json\n",
      "Formula: (((var_1*var_2)+(var_1+var_2))+(C_0*(var_0*var_0)))\n",
      "Tokens: ['(', '(', '(', 'var_1', '*', 'var_2', ')', '+', '(', 'var_1', '+', 'var_2', ')', ')', '+', '(', 'C_0', '*', '(', 'var_0', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_599.json\n",
      "Formula: (log(pow_2(var_1))+neg((var_2+var_0)))\n",
      "Tokens: ['(', 'log', '(', 'pow_2', '(', 'var_1', ')', ')', '+', 'neg', '(', '(', 'var_2', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_576.json\n",
      "Formula: ((neg(var_0)*neg(var_2))*cosh(gaussian(var_1)))\n",
      "Tokens: ['(', '(', 'neg', '(', 'var_0', ')', '*', 'neg', '(', 'var_2', ')', ')', '*', 'cosh', '(', 'gaussian', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_126.json\n",
      "Formula: ((cosh(var_2)*var_2)+((var_0+var_1)*sinh(var_0)))\n",
      "Tokens: ['(', '(', 'cosh', '(', 'var_2', ')', '*', 'var_2', ')', '+', '(', '(', 'var_0', '+', 'var_1', ')', '*', 'sinh', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_649.json\n",
      "Formula: ((log(var_1)*sqrt(var_2))*tanh(var_0))\n",
      "Tokens: ['(', '(', 'log', '(', 'var_1', ')', '*', 'sqrt', '(', 'var_2', ')', ')', '*', 'tanh', '(', 'var_0', ')', ')']\n",
      "\n",
      "File: f_219.json\n",
      "Formula: sqrt((sin(var_0)*(var_1+var_2)))\n",
      "Tokens: ['sqrt', '(', '(', 'sin', '(', 'var_0', ')', '*', '(', 'var_1', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_48.json\n",
      "Formula: (sinh((var_2+var_0))+tan(neg(var_1)))\n",
      "Tokens: ['(', 'sinh', '(', '(', 'var_2', '+', 'var_0', ')', ')', '+', 'tan', '(', 'neg', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_425.json\n",
      "Formula: ((cosh(var_0)+sin(var_1))+tanh(log(var_2)))\n",
      "Tokens: ['(', '(', 'cosh', '(', 'var_0', ')', '+', 'sin', '(', 'var_1', ')', ')', '+', 'tanh', '(', 'log', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_9.json\n",
      "Formula: (tan((var_0*var_1))*gaussian(tan(var_2)))\n",
      "Tokens: ['(', 'tan', '(', '(', 'var_0', '*', 'var_1', ')', ')', '*', 'gaussian', '(', 'tan', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_130.json\n",
      "Formula: ((exp(var_1)*sqrt(var_2))*tanh(tan(var_0)))\n",
      "Tokens: ['(', '(', 'exp', '(', 'var_1', ')', '*', 'sqrt', '(', 'var_2', ')', ')', '*', 'tanh', '(', 'tan', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_560.json\n",
      "Formula: ((var_2+tanh(var_1))*sqrt(log(var_0)))\n",
      "Tokens: ['(', '(', 'var_2', '+', 'tanh', '(', 'var_1', ')', ')', '*', 'sqrt', '(', 'log', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_472.json\n",
      "Formula: ((gaussian(var_1)*C_0)+tanh((var_0+var_2)))\n",
      "Tokens: ['(', '(', 'gaussian', '(', 'var_1', ')', '*', 'C_0', ')', '+', 'tanh', '(', '(', 'var_0', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_188.json\n",
      "Formula: (((var_0+C_0)+sqrt(var_2))*gaussian(pow_2(var_1)))\n",
      "Tokens: ['(', '(', '(', 'var_0', '+', 'C_0', ')', '+', 'sqrt', '(', 'var_2', ')', ')', '*', 'gaussian', '(', 'pow_2', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_537.json\n",
      "Formula: ((tanh(var_0)*(var_2+C_0))*gaussian((var_1*var_2)))\n",
      "Tokens: ['(', '(', 'tanh', '(', 'var_0', ')', '*', '(', 'var_2', '+', 'C_0', ')', ')', '*', 'gaussian', '(', '(', 'var_1', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_167.json\n",
      "Formula: ((sin(var_2)+(var_1+var_2))*sin((var_0+C_0)))\n",
      "Tokens: ['(', '(', 'sin', '(', 'var_2', ')', '+', '(', 'var_1', '+', 'var_2', ')', ')', '*', 'sin', '(', '(', 'var_0', '+', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_615.json\n",
      "Formula: ((tan(var_2)*gaussian(var_0))*reverse(pow_2(var_1)))\n",
      "Tokens: ['(', '(', 'tan', '(', 'var_2', ')', '*', 'gaussian', '(', 'var_0', ')', ')', '*', 'reverse', '(', 'pow_2', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_245.json\n",
      "Formula: (((var_2+var_1)*cosh(var_0))*log((var_1*C_0)))\n",
      "Tokens: ['(', '(', '(', 'var_2', '+', 'var_1', ')', '*', 'cosh', '(', 'var_0', ')', ')', '*', 'log', '(', '(', 'var_1', '*', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_300.json\n",
      "Formula: (log((var_2+var_0))+sqrt(sinh(var_1)))\n",
      "Tokens: ['(', 'log', '(', '(', 'var_2', '+', 'var_0', ')', ')', '+', 'sqrt', '(', 'sinh', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_14.json\n",
      "Formula: (((var_1*C_0)*(var_0*var_1))+log(var_2))\n",
      "Tokens: ['(', '(', '(', 'var_1', '*', 'C_0', ')', '*', '(', 'var_0', '*', 'var_1', ')', ')', '+', 'log', '(', 'var_2', ')', ')']\n",
      "\n",
      "File: f_479.json\n",
      "Formula: (reverse(sinh(var_1))*cosh((var_2+var_0)))\n",
      "Tokens: ['(', 'reverse', '(', 'sinh', '(', 'var_1', ')', ')', '*', 'cosh', '(', '(', 'var_2', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_183.json\n",
      "Formula: ((var_2*(var_1*C_0))+pow_2(cosh(var_0)))\n",
      "Tokens: ['(', '(', 'var_2', '*', '(', 'var_1', '*', 'C_0', ')', ')', '+', 'pow_2', '(', 'cosh', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_496.json\n",
      "Formula: (log(sinh(var_0))*cosh((var_1*var_2)))\n",
      "Tokens: ['(', 'log', '(', 'sinh', '(', 'var_0', ')', ')', '*', 'cosh', '(', '(', 'var_1', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_212.json\n",
      "Formula: (sin((var_0*var_2))*sinh(sinh(var_1)))\n",
      "Tokens: ['(', 'sin', '(', '(', 'var_0', '*', 'var_2', ')', ')', '*', 'sinh', '(', 'sinh', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_642.json\n",
      "Formula: tanh(((var_2*var_0)*sinh(var_1)))\n",
      "Tokens: ['tanh', '(', '(', '(', 'var_2', '*', 'var_0', ')', '*', 'sinh', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_357.json\n",
      "Formula: ((sin(var_0)+reverse(var_2))+(log(var_0)+log(var_1)))\n",
      "Tokens: ['(', '(', 'sin', '(', 'var_0', ')', '+', 'reverse', '(', 'var_2', ')', ')', '+', '(', 'log', '(', 'var_0', ')', '+', 'log', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_707.json\n",
      "Formula: (((var_2*C_0)*pow_2(var_0))*tanh(cosh(var_1)))\n",
      "Tokens: ['(', '(', '(', 'var_2', '*', 'C_0', ')', '*', 'pow_2', '(', 'var_0', ')', ')', '*', 'tanh', '(', 'cosh', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_2.json\n",
      "Formula: (log(sqrt(var_1))*tan((var_2+var_0)))\n",
      "Tokens: ['(', 'log', '(', 'sqrt', '(', 'var_1', ')', ')', '*', 'tan', '(', '(', 'var_2', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_43.json\n",
      "Formula: ((var_1*cos(var_2))+sqrt(sin(var_0)))\n",
      "Tokens: ['(', '(', 'var_1', '*', 'cos', '(', 'var_2', ')', ')', '+', 'sqrt', '(', 'sin', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_584.json\n",
      "Formula: (log((var_2*var_1))*exp(sinh(var_0)))\n",
      "Tokens: ['(', 'log', '(', '(', 'var_2', '*', 'var_1', ')', ')', '*', 'exp', '(', 'sinh', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_654.json\n",
      "Formula: (pow_2((var_2+var_1))*cosh(gaussian(var_0)))\n",
      "Tokens: ['(', 'pow_2', '(', '(', 'var_2', '+', 'var_1', ')', ')', '*', 'cosh', '(', 'gaussian', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_204.json\n",
      "Formula: (tanh(log(var_2))*sqrt((var_0*var_1)))\n",
      "Tokens: ['(', 'tanh', '(', 'log', '(', 'var_2', ')', ')', '*', 'sqrt', '(', '(', 'var_0', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_711.json\n",
      "Formula: (cosh((var_0+C_0))+gaussian((var_1*var_2)))\n",
      "Tokens: ['(', 'cosh', '(', '(', 'var_0', '+', 'C_0', ')', ')', '+', 'gaussian', '(', '(', 'var_1', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_341.json\n",
      "Formula: (exp((var_1+var_2))+reverse(sqrt(var_0)))\n",
      "Tokens: ['(', 'exp', '(', '(', 'var_1', '+', 'var_2', ')', ')', '+', 'reverse', '(', 'sqrt', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_55.json\n",
      "Formula: (neg((var_0*var_1))+tanh(sqrt(var_2)))\n",
      "Tokens: ['(', 'neg', '(', '(', 'var_0', '*', 'var_1', ')', ')', '+', 'tanh', '(', 'sqrt', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_592.json\n",
      "Formula: (reverse((var_0*var_1))*log((var_2*var_2)))\n",
      "Tokens: ['(', 'reverse', '(', '(', 'var_0', '*', 'var_1', ')', ')', '*', 'log', '(', '(', 'var_2', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_438.json\n",
      "Formula: ((reverse(var_0)*(var_2*C_0))*reverse((var_1*var_0)))\n",
      "Tokens: ['(', '(', 'reverse', '(', 'var_0', ')', '*', '(', 'var_2', '*', 'C_0', ')', ')', '*', 'reverse', '(', '(', 'var_1', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_253.json\n",
      "Formula: ((sinh(var_0)+cosh(var_1))+reverse(cosh(var_2)))\n",
      "Tokens: ['(', '(', 'sinh', '(', 'var_0', ')', '+', 'cosh', '(', 'var_1', ')', ')', '+', 'reverse', '(', 'cosh', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_603.json\n",
      "Formula: ((log(var_0)+sinh(var_1))+exp(tanh(var_2)))\n",
      "Tokens: ['(', '(', 'log', '(', 'var_0', ')', '+', 'sinh', '(', 'var_1', ')', ')', '+', 'exp', '(', 'tanh', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_316.json\n",
      "Formula: (cos((var_0+var_2))*sqrt((var_1*var_0)))\n",
      "Tokens: ['(', 'cos', '(', '(', 'var_0', '+', 'var_2', ')', ')', '*', 'sqrt', '(', '(', 'var_1', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_746.json\n",
      "Formula: (((var_0+var_1)+cosh(var_2))*neg(cosh(var_2)))\n",
      "Tokens: ['(', '(', '(', 'var_0', '+', 'var_1', ')', '+', 'cosh', '(', 'var_2', ')', ')', '*', 'neg', '(', 'cosh', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_195.json\n",
      "Formula: (pow_2((var_0+var_1))*reverse(sqrt(var_2)))\n",
      "Tokens: ['(', 'pow_2', '(', '(', 'var_0', '+', 'var_1', ')', ')', '*', 'reverse', '(', 'sqrt', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_480.json\n",
      "Formula: ((sin(var_1)*exp(var_0))+cos(reverse(var_2)))\n",
      "Tokens: ['(', '(', 'sin', '(', 'var_1', ')', '*', 'exp', '(', 'var_0', ')', ')', '+', 'cos', '(', 'reverse', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_697.json\n",
      "Formula: (((var_0*C_0)*cos(var_2))*tan((var_1*C_1)))\n",
      "Tokens: ['(', '(', '(', 'var_0', '*', 'C_0', ')', '*', 'cos', '(', 'var_2', ')', ')', '*', 'tan', '(', '(', 'var_1', '*', 'C_1', ')', ')', ')']\n",
      "\n",
      "File: f_228.json\n",
      "Formula: (log((var_0+var_2))+log((var_1+C_0)))\n",
      "Tokens: ['(', 'log', '(', '(', 'var_0', '+', 'var_2', ')', ')', '+', 'log', '(', '(', 'var_1', '+', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_678.json\n",
      "Formula: (((var_2+C_0)*(var_2*var_1))*sinh(tan(var_0)))\n",
      "Tokens: ['(', '(', '(', 'var_2', '+', 'C_0', ')', '*', '(', 'var_2', '*', 'var_1', ')', ')', '*', 'sinh', '(', 'tan', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_382.json\n",
      "Formula: ((tanh(var_0)*(var_0*var_2))+exp(reverse(var_1)))\n",
      "Tokens: ['(', '(', 'tanh', '(', 'var_0', ')', '*', '(', 'var_0', '*', 'var_2', ')', ')', '+', 'exp', '(', 'reverse', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_96.json\n",
      "Formula: ((tanh(var_2)+neg(var_1))+pow_2(reverse(var_0)))\n",
      "Tokens: ['(', '(', 'tanh', '(', 'var_2', ')', '+', 'neg', '(', 'var_1', ')', ')', '+', 'pow_2', '(', 'reverse', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_551.json\n",
      "Formula: gaussian((pow_2(var_2)+(var_1*var_0)))\n",
      "Tokens: ['gaussian', '(', '(', 'pow_2', '(', 'var_2', ')', '+', '(', 'var_1', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_101.json\n",
      "Formula: (sqrt((var_2*var_0))+neg(cosh(var_1)))\n",
      "Tokens: ['(', 'sqrt', '(', '(', 'var_2', '*', 'var_0', ')', ')', '+', 'neg', '(', 'cosh', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_414.json\n",
      "Formula: (tanh(neg(var_1))*cos((var_2*var_0)))\n",
      "Tokens: ['(', 'tanh', '(', 'neg', '(', 'var_1', ')', ')', '*', 'cos', '(', '(', 'var_2', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_79.json\n",
      "Formula: (gaussian(cos(var_0))*sinh((var_1+var_2)))\n",
      "Tokens: ['(', 'gaussian', '(', 'cos', '(', 'var_0', ')', ')', '*', 'sinh', '(', '(', 'var_1', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_290.json\n",
      "Formula: (pow_2((var_2+var_1))*exp(cosh(var_0)))\n",
      "Tokens: ['(', 'pow_2', '(', '(', 'var_2', '+', 'var_1', ')', ')', '*', 'exp', '(', 'cosh', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_156.json\n",
      "Formula: (cosh((var_1+var_2))+sin((var_0+C_0)))\n",
      "Tokens: ['(', 'cosh', '(', '(', 'var_1', '+', 'var_2', ')', ')', '+', 'sin', '(', '(', 'var_0', '+', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_506.json\n",
      "Formula: (neg((var_2+var_0))*exp(reverse(var_1)))\n",
      "Tokens: ['(', 'neg', '(', '(', 'var_2', '+', 'var_0', ')', ')', '*', 'exp', '(', 'reverse', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_443.json\n",
      "Formula: ((tanh(var_0)+cos(var_1))*neg(cosh(var_2)))\n",
      "Tokens: ['(', '(', 'tanh', '(', 'var_0', ')', '+', 'cos', '(', 'var_1', ')', ')', '*', 'neg', '(', 'cosh', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_286.json\n",
      "Formula: (sin((var_0*var_2))+exp(tanh(var_1)))\n",
      "Tokens: ['(', 'sin', '(', '(', 'var_0', '*', 'var_2', ')', ')', '+', 'exp', '(', 'tanh', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_269.json\n",
      "Formula: (gaussian((var_2*var_1))+cosh(sqrt(var_0)))\n",
      "Tokens: ['(', 'gaussian', '(', '(', 'var_2', '*', 'var_1', ')', ')', '+', 'cosh', '(', 'sqrt', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_639.json\n",
      "Formula: (((var_0*var_2)*reverse(var_1))+cos(sqrt(var_1)))\n",
      "Tokens: ['(', '(', '(', 'var_0', '*', 'var_2', ')', '*', 'reverse', '(', 'var_1', ')', ')', '+', 'cos', '(', 'sqrt', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_510.json\n",
      "Formula: (((var_0*var_0)+(var_0+var_1))*cosh(sinh(var_2)))\n",
      "Tokens: ['(', '(', '(', 'var_0', '*', 'var_0', ')', '+', '(', 'var_0', '+', 'var_1', ')', ')', '*', 'cosh', '(', 'sinh', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_140.json\n",
      "Formula: (((var_2+var_1)+log(var_0))+cosh(C_0))\n",
      "Tokens: ['(', '(', '(', 'var_2', '+', 'var_1', ')', '+', 'log', '(', 'var_0', ')', ')', '+', 'cosh', '(', 'C_0', ')', ')']\n",
      "\n",
      "File: f_455.json\n",
      "Formula: (sqrt((var_2+var_1))*sinh(cos(var_0)))\n",
      "Tokens: ['(', 'sqrt', '(', '(', 'var_2', '+', 'var_1', ')', ')', '*', 'sinh', '(', 'cos', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_38.json\n",
      "Formula: ((cosh(var_2)*sinh(var_0))+sinh(var_1))\n",
      "Tokens: ['(', '(', 'cosh', '(', 'var_2', ')', '*', 'sinh', '(', 'var_0', ')', ')', '+', 'sinh', '(', 'var_1', ')', ')']\n",
      "\n",
      "File: f_681.json\n",
      "Formula: pow_2(((var_0+var_2)*pow_2(var_1)))\n",
      "Tokens: ['pow_2', '(', '(', '(', 'var_0', '+', 'var_2', ')', '*', 'pow_2', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_394.json\n",
      "Formula: (sinh(sqrt(var_2))*sin((var_0*var_1)))\n",
      "Tokens: ['(', 'sinh', '(', 'sqrt', '(', 'var_2', ')', ')', '*', 'sin', '(', '(', 'var_0', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_117.json\n",
      "Formula: (sin((var_0+var_2))*pow_2(neg(var_1)))\n",
      "Tokens: ['(', 'sin', '(', '(', 'var_0', '+', 'var_2', ')', ')', '*', 'pow_2', '(', 'neg', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_80.json\n",
      "Formula: ((sqrt(var_1)+(var_2+var_2))+pow_2((var_0+var_2)))\n",
      "Tokens: ['(', '(', 'sqrt', '(', 'var_1', ')', '+', '(', 'var_2', '+', 'var_2', ')', ')', '+', 'pow_2', '(', '(', 'var_0', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_547.json\n",
      "Formula: (sinh((var_1*var_0))+sin(gaussian(var_2)))\n",
      "Tokens: ['(', 'sinh', '(', '(', 'var_1', '*', 'var_0', ')', ')', '+', 'sin', '(', 'gaussian', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_402.json\n",
      "Formula: (neg((var_1+C_0))+cos((var_0*var_2)))\n",
      "Tokens: ['(', 'neg', '(', '(', 'var_1', '+', 'C_0', ')', ')', '+', 'cos', '(', '(', 'var_0', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_475.json\n",
      "Formula: (cosh((var_1+var_2))+pow_2(exp(var_0)))\n",
      "Tokens: ['(', 'cosh', '(', '(', 'var_1', '+', 'var_2', ')', ')', '+', 'pow_2', '(', 'exp', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_18.json\n",
      "Formula: (((var_0*C_0)+(var_2+var_1))+sqrt((var_1+var_2)))\n",
      "Tokens: ['(', '(', '(', 'var_0', '*', 'C_0', ')', '+', '(', 'var_2', '+', 'var_1', ')', ')', '+', 'sqrt', '(', '(', 'var_1', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_530.json\n",
      "Formula: ((cosh(var_0)*var_1)*cos((var_2+C_0)))\n",
      "Tokens: ['(', '(', 'cosh', '(', 'var_0', ')', '*', 'var_1', ')', '*', 'cos', '(', '(', 'var_2', '+', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_160.json\n",
      "Formula: ((neg(var_0)+tanh(var_2))*sqrt(sin(var_1)))\n",
      "Tokens: ['(', '(', 'neg', '(', 'var_0', ')', '+', 'tanh', '(', 'var_2', ')', ')', '*', 'sqrt', '(', 'sin', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_249.json\n",
      "Formula: ((sinh(var_2)+(var_0*C_0))+tanh((var_1*var_1)))\n",
      "Tokens: ['(', '(', 'sinh', '(', 'var_2', ')', '+', '(', 'var_0', '*', 'C_0', ')', ')', '+', 'tanh', '(', '(', 'var_1', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_619.json\n",
      "Formula: ((neg(var_1)*var_0)+sqrt(gaussian(var_2)))\n",
      "Tokens: ['(', '(', 'neg', '(', 'var_1', ')', '*', 'var_0', ')', '+', 'sqrt', '(', 'gaussian', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_588.json\n",
      "Formula: (sin((var_1+var_2))*cosh(reverse(var_0)))\n",
      "Tokens: ['(', 'sin', '(', '(', 'var_1', '+', 'var_2', ')', ')', '*', 'cosh', '(', 'reverse', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_422.json\n",
      "Formula: ((cos(var_0)+log(var_1))+log(tan(var_2)))\n",
      "Tokens: ['(', '(', 'cos', '(', 'var_0', ')', '+', 'log', '(', 'var_1', ')', ')', '+', 'log', '(', 'tan', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_137.json\n",
      "Formula: ((sin(var_1)+sqrt(var_0))*reverse(exp(var_2)))\n",
      "Tokens: ['(', '(', 'sin', '(', 'var_1', ')', '+', 'sqrt', '(', 'var_0', ')', ')', '*', 'reverse', '(', 'exp', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_567.json\n",
      "Formula: (sin((var_2*C_0))+pow_2((var_0+var_1)))\n",
      "Tokens: ['(', 'sin', '(', '(', 'var_2', '*', 'C_0', ')', ')', '+', 'pow_2', '(', '(', 'var_0', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_434.json\n",
      "Formula: (reverse((var_0*var_1))+log((var_2+C_0)))\n",
      "Tokens: ['(', 'reverse', '(', '(', 'var_0', '*', 'var_1', ')', ')', '+', 'log', '(', '(', 'var_2', '+', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_59.json\n",
      "Formula: (((var_1+var_2)*tan(var_1))*cos((var_0*C_0)))\n",
      "Tokens: ['(', '(', '(', 'var_1', '+', 'var_2', ')', '*', 'tan', '(', 'var_1', ')', ')', '*', 'cos', '(', '(', 'var_0', '*', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_571.json\n",
      "Formula: ((cosh(var_0)+cosh(var_1))+neg((var_1*var_2)))\n",
      "Tokens: ['(', '(', 'cosh', '(', 'var_0', ')', '+', 'cosh', '(', 'var_1', ')', ')', '+', 'neg', '(', '(', 'var_1', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_121.json\n",
      "Formula: (reverse(log(var_0))+cosh((var_2*var_1)))\n",
      "Tokens: ['(', 'reverse', '(', 'log', '(', 'var_0', ')', ')', '+', 'cosh', '(', '(', 'var_2', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_208.json\n",
      "Formula: (tanh(cosh(var_0))*reverse((var_2+var_1)))\n",
      "Tokens: ['(', 'tanh', '(', 'cosh', '(', 'var_0', ')', ')', '*', 'reverse', '(', '(', 'var_2', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_658.json\n",
      "Formula: (sqrt(neg(var_0))+tanh((var_1*var_2)))\n",
      "Tokens: ['(', 'sqrt', '(', 'neg', '(', 'var_0', ')', ')', '+', 'tanh', '(', '(', 'var_1', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_463.json\n",
      "Formula: (tanh((var_0*var_2))+sinh(reverse(var_1)))\n",
      "Tokens: ['(', 'tanh', '(', '(', 'var_0', '*', 'var_2', ')', ')', '+', 'sinh', '(', 'reverse', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_199.json\n",
      "Formula: (gaussian((var_2+var_1))*pow_2(cosh(var_0)))\n",
      "Tokens: ['(', 'gaussian', '(', '(', 'var_2', '+', 'var_1', ')', ')', '*', 'pow_2', '(', 'cosh', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_176.json\n",
      "Formula: (neg((var_2*C_0))+sin((var_1*var_0)))\n",
      "Tokens: ['(', 'neg', '(', '(', 'var_2', '*', 'C_0', ')', ')', '+', 'sin', '(', '(', 'var_1', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_526.json\n",
      "Formula: (exp(tanh(var_0))+cos((var_2+var_1)))\n",
      "Tokens: ['(', 'exp', '(', 'tanh', '(', 'var_0', ')', ')', '+', 'cos', '(', '(', 'var_2', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_75.json\n",
      "Formula: (sin((var_1*var_0))+log((var_2+var_0)))\n",
      "Tokens: ['(', 'sin', '(', '(', 'var_1', '*', 'var_0', ')', ')', '+', 'log', '(', '(', 'var_2', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_418.json\n",
      "Formula: (log(reverse(var_0))+tan((var_2+var_1)))\n",
      "Tokens: ['(', 'log', '(', 'reverse', '(', 'var_0', ')', ')', '+', 'tan', '(', '(', 'var_2', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_731.json\n",
      "Formula: (tanh(var_0)*gaussian((var_1+var_2)))\n",
      "Tokens: ['(', 'tanh', '(', 'var_0', ')', '*', 'gaussian', '(', '(', 'var_1', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_361.json\n",
      "Formula: ((cos(var_1)*var_0)+sqrt((var_2+C_0)))\n",
      "Tokens: ['(', '(', 'cos', '(', 'var_1', ')', '*', 'var_0', ')', '+', 'sqrt', '(', '(', 'var_2', '+', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_674.json\n",
      "Formula: (pow_2(log(var_1))*exp((var_2*var_0)))\n",
      "Tokens: ['(', 'pow_2', '(', 'log', '(', 'var_1', ')', ')', '*', 'exp', '(', '(', 'var_2', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_224.json\n",
      "Formula: (reverse(tanh(var_2))*sinh((var_0+var_1)))\n",
      "Tokens: ['(', 'reverse', '(', 'tanh', '(', 'var_2', ')', ')', '*', 'sinh', '(', '(', 'var_0', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_22.json\n",
      "Formula: ((tanh(var_2)+(var_2+var_0))+tan((var_1+var_0)))\n",
      "Tokens: ['(', '(', 'tanh', '(', 'var_2', ')', '+', '(', 'var_2', '+', 'var_0', ')', ')', '+', 'tan', '(', '(', 'var_1', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_336.json\n",
      "Formula: (neg((var_2+var_0))*gaussian(sin(var_1)))\n",
      "Tokens: ['(', 'neg', '(', '(', 'var_2', '+', 'var_0', ')', ')', '*', 'gaussian', '(', 'sin', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_273.json\n",
      "Formula: ((sin(var_0)+cosh(var_2))+neg(log(var_1)))\n",
      "Tokens: ['(', '(', 'sin', '(', 'var_0', ')', '+', 'cosh', '(', 'var_2', ')', ')', '+', 'neg', '(', 'log', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_623.json\n",
      "Formula: (pow_2(cos(var_2))+cos((var_0*var_1)))\n",
      "Tokens: ['(', 'pow_2', '(', 'cos', '(', 'var_2', ')', ')', '+', 'cos', '(', '(', 'var_0', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_34.json\n",
      "Formula: (((var_1*C_0)*sqrt(var_2))+gaussian((var_0+var_1)))\n",
      "Tokens: ['(', '(', '(', 'var_1', '*', 'C_0', ')', '*', 'sqrt', '(', 'var_2', ')', ')', '+', 'gaussian', '(', '(', 'var_0', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_459.json\n",
      "Formula: ((cosh(var_0)*var_2)+tanh((var_1+C_0)))\n",
      "Tokens: ['(', '(', 'cosh', '(', 'var_0', ')', '*', 'var_2', ')', '+', 'tanh', '(', '(', 'var_1', '+', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_320.json\n",
      "Formula: (sinh((var_1+var_2))*sinh(pow_2(var_0)))\n",
      "Tokens: ['(', 'sinh', '(', '(', 'var_1', '+', 'var_2', ')', ')', '*', 'sinh', '(', 'pow_2', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_635.json\n",
      "Formula: (sin((var_1+var_0))+log((var_2*var_2)))\n",
      "Tokens: ['(', 'sin', '(', '(', 'var_1', '+', 'var_0', ')', ')', '+', 'log', '(', '(', 'var_2', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_265.json\n",
      "Formula: (tan((var_2*var_1))*cos(neg(var_0)))\n",
      "Tokens: ['(', 'tan', '(', '(', 'var_2', '*', 'var_1', ')', ')', '*', 'cos', '(', 'neg', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_63.json\n",
      "Formula: (exp((var_2+var_0))*pow_2(log(var_1)))\n",
      "Tokens: ['(', 'exp', '(', '(', 'var_2', '+', 'var_0', ')', ')', '*', 'pow_2', '(', 'log', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_377.json\n",
      "Formula: ((cos(var_0)*var_0)*(tan(var_1)*log(var_2)))\n",
      "Tokens: ['(', '(', 'cos', '(', 'var_0', ')', '*', 'var_0', ')', '*', '(', 'tan', '(', 'var_1', ')', '*', 'log', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_727.json\n",
      "Formula: ((pow_2(var_1)*log(var_0))*exp((var_2+C_0)))\n",
      "Tokens: ['(', '(', 'pow_2', '(', 'var_1', ')', '*', 'log', '(', 'var_0', ')', ')', '*', 'exp', '(', '(', 'var_2', '+', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_232.json\n",
      "Formula: cos((sqrt(var_0)*(var_1*var_2)))\n",
      "Tokens: ['cos', '(', '(', 'sqrt', '(', 'var_0', ')', '*', '(', 'var_1', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_662.json\n",
      "Formula: (cosh((var_0+var_2))*pow_2(neg(var_1)))\n",
      "Tokens: ['(', 'cosh', '(', '(', 'var_0', '+', 'var_2', ')', ')', '*', 'pow_2', '(', 'neg', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_398.json\n",
      "Formula: ((neg(var_1)+sqrt(var_0))*tan(var_2))\n",
      "Tokens: ['(', '(', 'neg', '(', 'var_1', ')', '+', 'sqrt', '(', 'var_0', ')', ')', '*', 'tan', '(', 'var_2', ')', ')']\n",
      "\n",
      "File: f_376.json\n",
      "Formula: (cos((var_0+var_2))+cos(reverse(var_1)))\n",
      "Tokens: ['(', 'cos', '(', '(', 'var_0', '+', 'var_2', ')', ')', '+', 'cos', '(', 'reverse', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_726.json\n",
      "Formula: ((sinh(var_2)*C_0)*neg((var_1*var_0)))\n",
      "Tokens: ['(', '(', 'sinh', '(', 'var_2', ')', '*', 'C_0', ')', '*', 'neg', '(', '(', 'var_1', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_233.json\n",
      "Formula: ((var_0+sinh(var_2))+tan((var_1*var_0)))\n",
      "Tokens: ['(', '(', 'var_0', '+', 'sinh', '(', 'var_2', ')', ')', '+', 'tan', '(', '(', 'var_1', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_663.json\n",
      "Formula: (reverse((var_0+var_1))+sinh(cos(var_2)))\n",
      "Tokens: ['(', 'reverse', '(', '(', 'var_0', '+', 'var_1', ')', ')', '+', 'sinh', '(', 'cos', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_399.json\n",
      "Formula: ((var_0+sqrt(var_1))*reverse(pow_2(var_2)))\n",
      "Tokens: ['(', '(', 'var_0', '+', 'sqrt', '(', 'var_1', ')', ')', '*', 'reverse', '(', 'pow_2', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_62.json\n",
      "Formula: (neg(sinh(var_0))+pow_2((var_2+var_1)))\n",
      "Tokens: ['(', 'neg', '(', 'sinh', '(', 'var_0', ')', ')', '+', 'pow_2', '(', '(', 'var_2', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_321.json\n",
      "Formula: pow_2(((var_2*C_0)+(var_1+var_0)))\n",
      "Tokens: ['pow_2', '(', '(', '(', 'var_2', '*', 'C_0', ')', '+', '(', 'var_1', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_634.json\n",
      "Formula: ((log(var_2)+sinh(var_1))+(sinh(var_2)*var_0))\n",
      "Tokens: ['(', '(', 'log', '(', 'var_2', ')', '+', 'sinh', '(', 'var_1', ')', ')', '+', '(', 'sinh', '(', 'var_2', ')', '*', 'var_0', ')', ')']\n",
      "\n",
      "File: f_264.json\n",
      "Formula: ((sin(var_2)+sinh(var_1))*(sinh(var_2)*tanh(var_0)))\n",
      "Tokens: ['(', '(', 'sin', '(', 'var_2', ')', '+', 'sinh', '(', 'var_1', ')', ')', '*', '(', 'sinh', '(', 'var_2', ')', '*', 'tanh', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_35.json\n",
      "Formula: ((log(var_0)*pow_2(var_2))+cosh(reverse(var_1)))\n",
      "Tokens: ['(', '(', 'log', '(', 'var_0', ')', '*', 'pow_2', '(', 'var_2', ')', ')', '+', 'cosh', '(', 'reverse', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_458.json\n",
      "Formula: ((cosh(var_1)+sin(var_2))+gaussian(tan(var_0)))\n",
      "Tokens: ['(', '(', 'cosh', '(', 'var_1', ')', '+', 'sin', '(', 'var_2', ')', ')', '+', 'gaussian', '(', 'tan', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_337.json\n",
      "Formula: (tan((var_0+var_2))*tanh(neg(var_1)))\n",
      "Tokens: ['(', 'tan', '(', '(', 'var_0', '+', 'var_2', ')', ')', '*', 'tanh', '(', 'neg', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_272.json\n",
      "Formula: (cos(var_2)*exp((var_0+var_1)))\n",
      "Tokens: ['(', 'cos', '(', 'var_2', ')', '*', 'exp', '(', '(', 'var_0', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_622.json\n",
      "Formula: (cosh(neg(var_2))+tan((var_1*var_0)))\n",
      "Tokens: ['(', 'cosh', '(', 'neg', '(', 'var_2', ')', ')', '+', 'tan', '(', '(', 'var_1', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_23.json\n",
      "Formula: ((pow_2(var_1)*sinh(var_0))*cos(pow_2(var_2)))\n",
      "Tokens: ['(', '(', 'pow_2', '(', 'var_1', ')', '*', 'sinh', '(', 'var_0', ')', ')', '*', 'cos', '(', 'pow_2', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_730.json\n",
      "Formula: (tanh((var_2*var_0))+sin((var_1*C_0)))\n",
      "Tokens: ['(', 'tanh', '(', '(', 'var_2', '*', 'var_0', ')', ')', '+', 'sin', '(', '(', 'var_1', '*', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_360.json\n",
      "Formula: (neg(cos(var_1))+tan((var_2+var_0)))\n",
      "Tokens: ['(', 'neg', '(', 'cos', '(', 'var_1', ')', ')', '+', 'tan', '(', '(', 'var_2', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_675.json\n",
      "Formula: ((sqrt(var_2)*pow_2(var_0))*log(cos(var_1)))\n",
      "Tokens: ['(', '(', 'sqrt', '(', 'var_2', ')', '*', 'pow_2', '(', 'var_0', ')', ')', '*', 'log', '(', 'cos', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_225.json\n",
      "Formula: (((var_2*var_1)+cosh(var_0))+sinh(C_0))\n",
      "Tokens: ['(', '(', '(', 'var_2', '*', 'var_1', ')', '+', 'cosh', '(', 'var_0', ')', ')', '+', 'sinh', '(', 'C_0', ')', ')']\n",
      "\n",
      "File: f_74.json\n",
      "Formula: ((sin(var_1)*neg(var_2))+cosh((var_0*C_0)))\n",
      "Tokens: ['(', '(', 'sin', '(', 'var_1', ')', '*', 'neg', '(', 'var_2', ')', ')', '+', 'cosh', '(', '(', 'var_0', '*', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_419.json\n",
      "Formula: ((cos(var_0)+var_2)*cosh(sinh(var_1)))\n",
      "Tokens: ['(', '(', 'cos', '(', 'var_0', ')', '+', 'var_2', ')', '*', 'cosh', '(', 'sinh', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_462.json\n",
      "Formula: (neg((var_2*var_2))+tanh((var_0*var_1)))\n",
      "Tokens: ['(', 'neg', '(', '(', 'var_2', '*', 'var_2', ')', ')', '+', 'tanh', '(', '(', 'var_0', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_198.json\n",
      "Formula: ((cosh(var_0)+pow_2(var_1))*exp(neg(var_2)))\n",
      "Tokens: ['(', '(', 'cosh', '(', 'var_0', ')', '+', 'pow_2', '(', 'var_1', ')', ')', '*', 'exp', '(', 'neg', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_177.json\n",
      "Formula: (neg(gaussian(var_1))+neg((var_0+var_2)))\n",
      "Tokens: ['(', 'neg', '(', 'gaussian', '(', 'var_1', ')', ')', '+', 'neg', '(', '(', 'var_0', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_527.json\n",
      "Formula: ((tan(var_0)+cosh(var_2))+exp(cosh(var_1)))\n",
      "Tokens: ['(', '(', 'tan', '(', 'var_0', ')', '+', 'cosh', '(', 'var_2', ')', ')', '+', 'exp', '(', 'cosh', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_209.json\n",
      "Formula: (sin((var_2+var_0))*reverse(log(var_1)))\n",
      "Tokens: ['(', 'sin', '(', '(', 'var_2', '+', 'var_0', ')', ')', '*', 'reverse', '(', 'log', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_659.json\n",
      "Formula: ((sin(var_2)+tan(var_0))+pow_2(log(var_1)))\n",
      "Tokens: ['(', '(', 'sin', '(', 'var_2', ')', '+', 'tan', '(', 'var_0', ')', ')', '+', 'pow_2', '(', 'log', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_435.json\n",
      "Formula: (cosh(exp(var_0))+sinh((var_1+var_2)))\n",
      "Tokens: ['(', 'cosh', '(', 'exp', '(', 'var_0', ')', ')', '+', 'sinh', '(', '(', 'var_1', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_58.json\n",
      "Formula: (reverse((var_1*C_0))*cos((var_2*var_0)))\n",
      "Tokens: ['(', 'reverse', '(', '(', 'var_1', '*', 'C_0', ')', ')', '*', 'cos', '(', '(', 'var_2', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_570.json\n",
      "Formula: sqrt((tan(var_0)*(var_1*var_2)))\n",
      "Tokens: ['sqrt', '(', '(', 'tan', '(', 'var_0', ')', '*', '(', 'var_1', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_120.json\n",
      "Formula: (neg(cosh(var_0))+cosh((var_2*var_1)))\n",
      "Tokens: ['(', 'neg', '(', 'cosh', '(', 'var_0', ')', ')', '+', 'cosh', '(', '(', 'var_2', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_589.json\n",
      "Formula: (((var_0+C_0)*tan(var_2))+((var_1+var_0)*tanh(var_0)))\n",
      "Tokens: ['(', '(', '(', 'var_0', '+', 'C_0', ')', '*', 'tan', '(', 'var_2', ')', ')', '+', '(', '(', 'var_1', '+', 'var_0', ')', '*', 'tanh', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_423.json\n",
      "Formula: ((sinh(var_1)+cos(var_2))*sinh(gaussian(var_0)))\n",
      "Tokens: ['(', '(', 'sinh', '(', 'var_1', ')', '+', 'cos', '(', 'var_2', ')', ')', '*', 'sinh', '(', 'gaussian', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_136.json\n",
      "Formula: (((var_1*var_2)*reverse(var_2))+sqrt((var_0*C_0)))\n",
      "Tokens: ['(', '(', '(', 'var_1', '*', 'var_2', ')', '*', 'reverse', '(', 'var_2', ')', ')', '+', 'sqrt', '(', '(', 'var_0', '*', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_566.json\n",
      "Formula: ((reverse(var_0)*sin(var_2))+(tanh(var_2)+(var_1*C_0)))\n",
      "Tokens: ['(', '(', 'reverse', '(', 'var_0', ')', '*', 'sin', '(', 'var_2', ')', ')', '+', '(', 'tanh', '(', 'var_2', ')', '+', '(', 'var_1', '*', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_248.json\n",
      "Formula: (((var_1+var_2)+sinh(var_2))+cosh(neg(var_0)))\n",
      "Tokens: ['(', '(', '(', 'var_1', '+', 'var_2', ')', '+', 'sinh', '(', 'var_2', ')', ')', '+', 'cosh', '(', 'neg', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_618.json\n",
      "Formula: ((sinh(var_2)+exp(var_0))*reverse((var_1*C_0)))\n",
      "Tokens: ['(', '(', 'sinh', '(', 'var_2', ')', '+', 'exp', '(', 'var_0', ')', ')', '*', 'reverse', '(', '(', 'var_1', '*', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_474.json\n",
      "Formula: (sin(pow_2(var_1))*sinh((var_2+var_0)))\n",
      "Tokens: ['(', 'sin', '(', 'pow_2', '(', 'var_1', ')', ')', '*', 'sinh', '(', '(', 'var_2', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_19.json\n",
      "Formula: (((var_0*var_1)+(var_1+C_0))*exp(reverse(var_2)))\n",
      "Tokens: ['(', '(', '(', 'var_0', '*', 'var_1', ')', '+', '(', 'var_1', '+', 'C_0', ')', ')', '*', 'exp', '(', 'reverse', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_531.json\n",
      "Formula: (((var_0+C_0)+tan(var_2))+cosh((var_1+C_1)))\n",
      "Tokens: ['(', '(', '(', 'var_0', '+', 'C_0', ')', '+', 'tan', '(', 'var_2', ')', ')', '+', 'cosh', '(', '(', 'var_1', '+', 'C_1', ')', ')', ')']\n",
      "\n",
      "File: f_161.json\n",
      "Formula: (((var_0+C_0)*(var_1+C_1))*pow_2(neg(var_2)))\n",
      "Tokens: ['(', '(', '(', 'var_0', '+', 'C_0', ')', '*', '(', 'var_1', '+', 'C_1', ')', ')', '*', 'pow_2', '(', 'neg', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_116.json\n",
      "Formula: ((cos(var_0)+tanh(var_2))*sqrt(sin(var_1)))\n",
      "Tokens: ['(', '(', 'cos', '(', 'var_0', ')', '+', 'tanh', '(', 'var_2', ')', ')', '*', 'sqrt', '(', 'sin', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_546.json\n",
      "Formula: (gaussian(reverse(var_2))*sinh((var_1+var_0)))\n",
      "Tokens: ['(', 'gaussian', '(', 'reverse', '(', 'var_2', ')', ')', '*', 'sinh', '(', '(', 'var_1', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_81.json\n",
      "Formula: (neg((var_0+var_1))+sinh((var_2+C_0)))\n",
      "Tokens: ['(', 'neg', '(', '(', 'var_0', '+', 'var_1', ')', ')', '+', 'sinh', '(', '(', 'var_2', '+', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_403.json\n",
      "Formula: ((cos(var_2)*reverse(var_0))*exp(pow_2(var_1)))\n",
      "Tokens: ['(', '(', 'cos', '(', 'var_2', ')', '*', 'reverse', '(', 'var_0', ')', ')', '*', 'exp', '(', 'pow_2', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_680.json\n",
      "Formula: (sinh(cos(var_0))+neg((var_2*var_1)))\n",
      "Tokens: ['(', 'sinh', '(', 'cos', '(', 'var_0', ')', ')', '+', 'neg', '(', '(', 'var_2', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_395.json\n",
      "Formula: ((sin(var_2)+tan(var_0))+(var_1*cos(var_2)))\n",
      "Tokens: ['(', '(', 'sin', '(', 'var_2', ')', '+', 'tan', '(', 'var_0', ')', ')', '+', '(', 'var_1', '*', 'cos', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_511.json\n",
      "Formula: (log((var_0*var_1))+cosh(var_2))\n",
      "Tokens: ['(', 'log', '(', '(', 'var_0', '*', 'var_1', ')', ')', '+', 'cosh', '(', 'var_2', ')', ')']\n",
      "\n",
      "File: f_141.json\n",
      "Formula: (reverse((var_0*var_1))+gaussian(var_2))\n",
      "Tokens: ['(', 'reverse', '(', '(', 'var_0', '*', 'var_1', ')', ')', '+', 'gaussian', '(', 'var_2', ')', ')']\n",
      "\n",
      "File: f_454.json\n",
      "Formula: ((pow_2(var_0)+(var_1*C_0))*reverse(log(var_2)))\n",
      "Tokens: ['(', '(', 'pow_2', '(', 'var_0', ')', '+', '(', 'var_1', '*', 'C_0', ')', ')', '*', 'reverse', '(', 'log', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_39.json\n",
      "Formula: (cosh((var_0*var_2))*sinh(gaussian(var_1)))\n",
      "Tokens: ['(', 'cosh', '(', '(', 'var_0', '*', 'var_2', ')', ')', '*', 'sinh', '(', 'gaussian', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_287.json\n",
      "Formula: (reverse((var_1+var_0))*neg(tan(var_2)))\n",
      "Tokens: ['(', 'reverse', '(', '(', 'var_1', '+', 'var_0', ')', ')', '*', 'neg', '(', 'tan', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_268.json\n",
      "Formula: (((var_1*C_0)*sin(var_0))+reverse(exp(var_2)))\n",
      "Tokens: ['(', '(', '(', 'var_1', '*', 'C_0', ')', '*', 'sin', '(', 'var_0', ')', ')', '+', 'reverse', '(', 'exp', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_638.json\n",
      "Formula: ((exp(var_2)+pow_2(var_1))*pow_2(tanh(var_0)))\n",
      "Tokens: ['(', '(', 'exp', '(', 'var_2', ')', '+', 'pow_2', '(', 'var_1', ')', ')', '*', 'pow_2', '(', 'tanh', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_157.json\n",
      "Formula: ((tan(var_1)*sin(var_1))+(tan(var_0)+cos(var_2)))\n",
      "Tokens: ['(', '(', 'tan', '(', 'var_1', ')', '*', 'sin', '(', 'var_1', ')', ')', '+', '(', 'tan', '(', 'var_0', ')', '+', 'cos', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_507.json\n",
      "Formula: (tan(var_2)*sinh((var_0+var_1)))\n",
      "Tokens: ['(', 'tan', '(', 'var_2', ')', '*', 'sinh', '(', '(', 'var_0', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_442.json\n",
      "Formula: tan(((var_1+var_2)*cos(var_0)))\n",
      "Tokens: ['tan', '(', '(', '(', 'var_1', '+', 'var_2', ')', '*', 'cos', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_291.json\n",
      "Formula: (((var_0+var_2)*log(var_2))+gaussian((var_0*var_1)))\n",
      "Tokens: ['(', '(', '(', 'var_0', '+', 'var_2', ')', '*', 'log', '(', 'var_2', ')', ')', '+', 'gaussian', '(', '(', 'var_0', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_550.json\n",
      "Formula: (cos((var_2+var_1))+pow_2(sqrt(var_0)))\n",
      "Tokens: ['(', 'cos', '(', '(', 'var_2', '+', 'var_1', ')', ')', '+', 'pow_2', '(', 'sqrt', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_97.json\n",
      "Formula: (pow_2((var_0+var_1))*log(tan(var_2)))\n",
      "Tokens: ['(', 'pow_2', '(', '(', 'var_0', '+', 'var_1', ')', ')', '*', 'log', '(', 'tan', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_100.json\n",
      "Formula: ((gaussian(var_1)+(var_0+C_0))+tan((var_1*var_2)))\n",
      "Tokens: ['(', '(', 'gaussian', '(', 'var_1', ')', '+', '(', 'var_0', '+', 'C_0', ')', ')', '+', 'tan', '(', '(', 'var_1', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_415.json\n",
      "Formula: ((cos(var_2)*gaussian(var_0))*(neg(var_1)*cosh(var_1)))\n",
      "Tokens: ['(', '(', 'cos', '(', 'var_2', ')', '*', 'gaussian', '(', 'var_0', ')', ')', '*', '(', 'neg', '(', 'var_1', ')', '*', 'cosh', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_78.json\n",
      "Formula: (((var_0*C_0)*tanh(var_1))*cosh(sqrt(var_2)))\n",
      "Tokens: ['(', '(', '(', 'var_0', '*', 'C_0', ')', '*', 'tanh', '(', 'var_1', ')', ')', '*', 'cosh', '(', 'sqrt', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_696.json\n",
      "Formula: (cos(var_1)*tanh((var_2+var_0)))\n",
      "Tokens: ['(', 'cos', '(', 'var_1', ')', '*', 'tanh', '(', '(', 'var_2', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_229.json\n",
      "Formula: (sinh((var_2*var_0))*log(sqrt(var_1)))\n",
      "Tokens: ['(', 'sinh', '(', '(', 'var_2', '*', 'var_0', ')', ')', '*', 'log', '(', 'sqrt', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_679.json\n",
      "Formula: (((var_1*var_0)*tanh(var_2))+tanh(C_0))\n",
      "Tokens: ['(', '(', '(', 'var_1', '*', 'var_0', ')', '*', 'tanh', '(', 'var_2', ')', ')', '+', 'tanh', '(', 'C_0', ')', ')']\n",
      "\n",
      "File: f_383.json\n",
      "Formula: (log(gaussian(var_2))+cosh((var_0*var_1)))\n",
      "Tokens: ['(', 'log', '(', 'gaussian', '(', 'var_2', ')', ')', '+', 'cosh', '(', '(', 'var_0', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_194.json\n",
      "Formula: (((var_0+C_0)+var_1)*(log(var_1)*tanh(var_2)))\n",
      "Tokens: ['(', '(', '(', 'var_0', '+', 'C_0', ')', '+', 'var_1', ')', '*', '(', 'log', '(', 'var_1', ')', '*', 'tanh', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_481.json\n",
      "Formula: (reverse((var_2*var_1))+sqrt(exp(var_0)))\n",
      "Tokens: ['(', 'reverse', '(', '(', 'var_2', '*', 'var_1', ')', ')', '+', 'sqrt', '(', 'exp', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_252.json\n",
      "Formula: ((tanh(var_0)*pow_2(var_2))+pow_2(log(var_1)))\n",
      "Tokens: ['(', '(', 'tanh', '(', 'var_0', ')', '*', 'pow_2', '(', 'var_2', ')', ')', '+', 'pow_2', '(', 'log', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_602.json\n",
      "Formula: ((gaussian(var_1)+cosh(var_2))*sinh(gaussian(var_0)))\n",
      "Tokens: ['(', '(', 'gaussian', '(', 'var_1', ')', '+', 'cosh', '(', 'var_2', ')', ')', '*', 'sinh', '(', 'gaussian', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_317.json\n",
      "Formula: (tanh(sqrt(var_1))*cos((var_0*var_2)))\n",
      "Tokens: ['(', 'tanh', '(', 'sqrt', '(', 'var_1', ')', ')', '*', 'cos', '(', '(', 'var_0', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_593.json\n",
      "Formula: (((var_2+C_0)*sinh(var_1))*sin((var_0*C_1)))\n",
      "Tokens: ['(', '(', '(', 'var_2', '+', 'C_0', ')', '*', 'sinh', '(', 'var_1', ')', ')', '*', 'sin', '(', '(', 'var_0', '*', 'C_1', ')', ')', ')']\n",
      "\n",
      "File: f_54.json\n",
      "Formula: (((var_2+var_1)*var_0)+log((var_2*C_0)))\n",
      "Tokens: ['(', '(', '(', 'var_2', '+', 'var_1', ')', '*', 'var_0', ')', '+', 'log', '(', '(', 'var_2', '*', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_439.json\n",
      "Formula: (gaussian((var_0*var_1))+tanh(sqrt(var_2)))\n",
      "Tokens: ['(', 'gaussian', '(', '(', 'var_0', '*', 'var_1', ')', ')', '+', 'tanh', '(', 'sqrt', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_655.json\n",
      "Formula: (neg(gaussian(var_0))+sinh((var_1+var_2)))\n",
      "Tokens: ['(', 'neg', '(', 'gaussian', '(', 'var_0', ')', ')', '+', 'sinh', '(', '(', 'var_1', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_205.json\n",
      "Formula: ((tan(var_1)+log(var_2))+log(cosh(var_0)))\n",
      "Tokens: ['(', '(', 'tan', '(', 'var_1', ')', '+', 'log', '(', 'var_2', ')', ')', '+', 'log', '(', 'cosh', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_710.json\n",
      "Formula: (((var_2+var_1)*C_0)*tan((var_0*var_1)))\n",
      "Tokens: ['(', '(', '(', 'var_2', '+', 'var_1', ')', '*', 'C_0', ')', '*', 'tan', '(', '(', 'var_0', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_340.json\n",
      "Formula: ((neg(var_1)+neg(var_0))+gaussian(sin(var_2)))\n",
      "Tokens: ['(', '(', 'neg', '(', 'var_1', ')', '+', 'neg', '(', 'var_0', ')', ')', '+', 'gaussian', '(', 'sin', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_3.json\n",
      "Formula: (reverse((var_0*var_1))+reverse(sinh(var_2)))\n",
      "Tokens: ['(', 'reverse', '(', '(', 'var_0', '*', 'var_1', ')', ')', '+', 'reverse', '(', 'sinh', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_585.json\n",
      "Formula: ((sqrt(var_1)*C_0)+(var_0+sinh(var_2)))\n",
      "Tokens: ['(', '(', 'sqrt', '(', 'var_1', ')', '*', 'C_0', ')', '+', '(', 'var_0', '+', 'sinh', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_42.json\n",
      "Formula: ((cosh(var_0)+(var_1+var_2))+pow_2(log(var_0)))\n",
      "Tokens: ['(', '(', 'cosh', '(', 'var_0', ')', '+', '(', 'var_1', '+', 'var_2', ')', ')', '+', 'pow_2', '(', 'log', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_213.json\n",
      "Formula: ((reverse(var_1)*log(var_2))+sin((var_1+var_0)))\n",
      "Tokens: ['(', '(', 'reverse', '(', 'var_1', ')', '*', 'log', '(', 'var_2', ')', ')', '+', 'sin', '(', '(', 'var_1', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_643.json\n",
      "Formula: (sin((var_0*var_2))+sinh(cos(var_1)))\n",
      "Tokens: ['(', 'sin', '(', '(', 'var_0', '*', 'var_2', ')', ')', '+', 'sinh', '(', 'cos', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_356.json\n",
      "Formula: ((exp(var_2)*cos(var_0))+sinh(neg(var_1)))\n",
      "Tokens: ['(', '(', 'exp', '(', 'var_2', ')', '*', 'cos', '(', 'var_0', ')', ')', '+', 'sinh', '(', 'neg', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_706.json\n",
      "Formula: (((var_1+C_0)*sqrt(var_0))*cosh(sin(var_2)))\n",
      "Tokens: ['(', '(', '(', 'var_1', '+', 'C_0', ')', '*', 'sqrt', '(', 'var_0', ')', ')', '*', 'cosh', '(', 'sin', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_15.json\n",
      "Formula: (log((var_2*var_0))+pow_2(sinh(var_1)))\n",
      "Tokens: ['(', 'log', '(', '(', 'var_2', '*', 'var_0', ')', ')', '+', 'pow_2', '(', 'sinh', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_478.json\n",
      "Formula: (cos((var_0*var_1))+sinh((var_2*var_0)))\n",
      "Tokens: ['(', 'cos', '(', '(', 'var_0', '*', 'var_1', ')', ')', '+', 'sinh', '(', '(', 'var_2', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_182.json\n",
      "Formula: (((var_0+C_0)+sqrt(var_1))+cos((var_2*C_1)))\n",
      "Tokens: ['(', '(', '(', 'var_0', '+', 'C_0', ')', '+', 'sqrt', '(', 'var_1', ')', ')', '+', 'cos', '(', '(', 'var_2', '*', 'C_1', ')', ')', ')']\n",
      "\n",
      "File: f_497.json\n",
      "Formula: reverse((tanh(var_0)+(var_1+var_2)))\n",
      "Tokens: ['reverse', '(', '(', 'tanh', '(', 'var_0', ')', '+', '(', 'var_1', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_614.json\n",
      "Formula: (sqrt(neg(var_1))*exp((var_0*var_2)))\n",
      "Tokens: ['(', 'sqrt', '(', 'neg', '(', 'var_1', ')', ')', '*', 'exp', '(', '(', 'var_0', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_244.json\n",
      "Formula: tan(((var_2*var_0)*sinh(var_1)))\n",
      "Tokens: ['tan', '(', '(', '(', 'var_2', '*', 'var_0', ')', '*', 'sinh', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_301.json\n",
      "Formula: ((sin(var_0)*C_0)*((var_1+C_1)+tanh(var_2)))\n",
      "Tokens: ['(', '(', 'sin', '(', 'var_0', ')', '*', 'C_0', ')', '*', '(', '(', 'var_1', '+', 'C_1', ')', '+', 'tanh', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_400.json\n",
      "Formula: ((cosh(var_0)+gaussian(var_1))+exp(gaussian(var_2)))\n",
      "Tokens: ['(', '(', 'cosh', '(', 'var_0', ')', '+', 'gaussian', '(', 'var_1', ')', ')', '+', 'exp', '(', 'gaussian', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_115.json\n",
      "Formula: (((var_2*C_0)+tan(var_0))*sinh((var_0*var_1)))\n",
      "Tokens: ['(', '(', '(', 'var_2', '*', 'C_0', ')', '+', 'tan', '(', 'var_0', ')', ')', '*', 'sinh', '(', '(', 'var_0', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_545.json\n",
      "Formula: ((pow_2(var_1)+reverse(var_2))*cosh((var_0+C_0)))\n",
      "Tokens: ['(', '(', 'pow_2', '(', 'var_1', ')', '+', 'reverse', '(', 'var_2', ')', ')', '*', 'cosh', '(', '(', 'var_0', '+', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_82.json\n",
      "Formula: ((gaussian(var_0)*neg(var_2))*sinh(cosh(var_1)))\n",
      "Tokens: ['(', '(', 'gaussian', '(', 'var_0', ')', '*', 'neg', '(', 'var_2', ')', ')', '*', 'sinh', '(', 'cosh', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_396.json\n",
      "Formula: (((var_0+var_2)+(var_1*var_0))+sinh(reverse(var_2)))\n",
      "Tokens: ['(', '(', '(', 'var_0', '+', 'var_2', ')', '+', '(', 'var_1', '*', 'var_0', ')', ')', '+', 'sinh', '(', 'reverse', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_729.json\n",
      "Formula: gaussian((tanh(var_2)*(var_1*var_0)))\n",
      "Tokens: ['gaussian', '(', '(', 'tanh', '(', 'var_2', ')', '*', '(', 'var_1', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_379.json\n",
      "Formula: (reverse(sqrt(var_0))*cos((var_2*var_1)))\n",
      "Tokens: ['(', 'reverse', '(', 'sqrt', '(', 'var_0', ')', ')', '*', 'cos', '(', '(', 'var_2', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_683.json\n",
      "Formula: (sinh(sqrt(var_2))+cosh((var_1+var_0)))\n",
      "Tokens: ['(', 'sinh', '(', 'sqrt', '(', 'var_2', ')', ')', '+', 'cosh', '(', '(', 'var_1', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_457.json\n",
      "Formula: tan(((var_0*var_2)*tan(var_1)))\n",
      "Tokens: ['tan', '(', '(', '(', 'var_0', '*', 'var_2', ')', '*', 'tan', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_512.json\n",
      "Formula: (sinh(reverse(var_1))+reverse((var_2+var_0)))\n",
      "Tokens: ['(', 'sinh', '(', 'reverse', '(', 'var_1', ')', ')', '+', 'reverse', '(', '(', 'var_2', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_142.json\n",
      "Formula: ((pow_2(var_1)*gaussian(var_2))+cosh(tanh(var_0)))\n",
      "Tokens: ['(', '(', 'pow_2', '(', 'var_1', ')', '*', 'gaussian', '(', 'var_2', ')', ')', '+', 'cosh', '(', 'tanh', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_284.json\n",
      "Formula: (exp((var_0+var_1))+sinh((var_2*C_0)))\n",
      "Tokens: ['(', 'exp', '(', '(', 'var_0', '+', 'var_1', ')', ')', '+', 'sinh', '(', '(', 'var_2', '*', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_441.json\n",
      "Formula: (tan(neg(var_0))*cosh((var_2+var_1)))\n",
      "Tokens: ['(', 'tan', '(', 'neg', '(', 'var_0', ')', ')', '*', 'cosh', '(', '(', 'var_2', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_154.json\n",
      "Formula: (neg((var_1+var_2))*tanh(tan(var_0)))\n",
      "Tokens: ['(', 'neg', '(', '(', 'var_1', '+', 'var_2', ')', ')', '*', 'tanh', '(', 'tan', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_504.json\n",
      "Formula: (sqrt((var_2*var_0))+sqrt(cosh(var_1)))\n",
      "Tokens: ['(', 'sqrt', '(', '(', 'var_2', '*', 'var_0', ')', ')', '+', 'sqrt', '(', 'cosh', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_292.json\n",
      "Formula: (cosh((var_2*var_0))*neg((var_1+var_2)))\n",
      "Tokens: ['(', 'cosh', '(', '(', 'var_2', '*', 'var_0', ')', ')', '*', 'neg', '(', '(', 'var_1', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_338.json\n",
      "Formula: ((reverse(var_0)*(var_2*C_0))+((var_1+C_1)*tanh(var_2)))\n",
      "Tokens: ['(', '(', 'reverse', '(', 'var_0', ')', '*', '(', 'var_2', '*', 'C_0', ')', ')', '+', '(', '(', 'var_1', '+', 'C_1', ')', '*', 'tanh', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_416.json\n",
      "Formula: sinh((sinh(var_1)*(var_0+var_2)))\n",
      "Tokens: ['sinh', '(', '(', 'sinh', '(', 'var_1', ')', '*', '(', 'var_0', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_553.json\n",
      "Formula: (((var_2*var_1)*tan(var_0))*sinh(sin(var_1)))\n",
      "Tokens: ['(', '(', '(', 'var_2', '*', 'var_1', ')', '*', 'tan', '(', 'var_0', ')', ')', '*', 'sinh', '(', 'sin', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_94.json\n",
      "Formula: (sin((var_0*var_1))*gaussian(var_2))\n",
      "Tokens: ['(', 'sin', '(', '(', 'var_0', '*', 'var_1', ')', ')', '*', 'gaussian', '(', 'var_2', ')', ')']\n",
      "\n",
      "File: f_103.json\n",
      "Formula: log(((var_0+C_0)*(var_1+var_2)))\n",
      "Tokens: ['log', '(', '(', '(', 'var_0', '+', 'C_0', ')', '*', '(', 'var_1', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_380.json\n",
      "Formula: ((sqrt(var_0)+cosh(var_2))+sinh(sinh(var_1)))\n",
      "Tokens: ['(', '(', 'sqrt', '(', 'var_0', ')', '+', 'cosh', '(', 'var_2', ')', ')', '+', 'sinh', '(', 'sinh', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_695.json\n",
      "Formula: ((exp(var_0)*exp(var_1))+cosh(log(var_2)))\n",
      "Tokens: ['(', '(', 'exp', '(', 'var_0', ')', '*', 'exp', '(', 'var_1', ')', ')', '+', 'cosh', '(', 'log', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_528.json\n",
      "Formula: (exp((var_1+C_0))*tanh((var_0+var_2)))\n",
      "Tokens: ['(', 'exp', '(', '(', 'var_1', '+', 'C_0', ')', ')', '*', 'tanh', '(', '(', 'var_0', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_178.json\n",
      "Formula: (reverse((var_0+var_1))+pow_2(gaussian(var_2)))\n",
      "Tokens: ['(', 'reverse', '(', '(', 'var_0', '+', 'var_1', ')', ')', '+', 'pow_2', '(', 'gaussian', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_482.json\n",
      "Formula: (cosh(sqrt(var_2))+sqrt((var_1*var_0)))\n",
      "Tokens: ['(', 'cosh', '(', 'sqrt', '(', 'var_2', ')', ')', '+', 'sqrt', '(', '(', 'var_1', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_197.json\n",
      "Formula: (tanh(sin(var_0))*tanh((var_1+var_2)))\n",
      "Tokens: ['(', 'tanh', '(', 'sin', '(', 'var_0', ')', ')', '*', 'tanh', '(', '(', 'var_1', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_314.json\n",
      "Formula: (exp((var_1*var_0))+sin(pow_2(var_2)))\n",
      "Tokens: ['(', 'exp', '(', '(', 'var_1', '*', 'var_0', ')', ')', '+', 'sin', '(', 'pow_2', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_744.json\n",
      "Formula: ((cosh(var_1)+tanh(var_2))*sin(gaussian(var_0)))\n",
      "Tokens: ['(', '(', 'cosh', '(', 'var_1', ')', '+', 'tanh', '(', 'var_2', ')', ')', '*', 'sin', '(', 'gaussian', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_251.json\n",
      "Formula: ((var_2*reverse(var_0))+pow_2((var_1*C_0)))\n",
      "Tokens: ['(', '(', 'var_2', '*', 'reverse', '(', 'var_0', ')', ')', '+', 'pow_2', '(', '(', 'var_1', '*', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_601.json\n",
      "Formula: ((tanh(var_2)+neg(var_0))*cosh(cos(var_1)))\n",
      "Tokens: ['(', '(', 'tanh', '(', 'var_2', ')', '+', 'neg', '(', 'var_0', ')', ')', '*', 'cosh', '(', 'cos', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_590.json\n",
      "Formula: (gaussian((var_2+var_1))*sqrt(neg(var_0)))\n",
      "Tokens: ['(', 'gaussian', '(', '(', 'var_2', '+', 'var_1', ')', ')', '*', 'sqrt', '(', 'neg', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_57.json\n",
      "Formula: ((tanh(var_0)*cos(var_1))*sinh(log(var_2)))\n",
      "Tokens: ['(', '(', 'tanh', '(', 'var_0', ')', '*', 'cos', '(', 'var_1', ')', ')', '*', 'sinh', '(', 'log', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_713.json\n",
      "Formula: (tanh((var_2*var_1))*reverse(var_0))\n",
      "Tokens: ['(', 'tanh', '(', '(', 'var_2', '*', 'var_1', ')', ')', '*', 'reverse', '(', 'var_0', ')', ')']\n",
      "\n",
      "File: f_343.json\n",
      "Formula: (((var_0+C_0)*(var_1+var_2))+tanh((var_1+var_0)))\n",
      "Tokens: ['(', '(', '(', 'var_0', '+', 'C_0', ')', '*', '(', 'var_1', '+', 'var_2', ')', ')', '+', 'tanh', '(', '(', 'var_1', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_656.json\n",
      "Formula: exp(((var_0+var_1)*sqrt(var_2)))\n",
      "Tokens: ['exp', '(', '(', '(', 'var_0', '+', 'var_1', ')', '*', 'sqrt', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_206.json\n",
      "Formula: (tanh((var_2+C_0))+sqrt((var_0+var_1)))\n",
      "Tokens: ['(', 'tanh', '(', '(', 'var_2', '+', 'C_0', ')', ')', '+', 'sqrt', '(', '(', 'var_0', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_569.json\n",
      "Formula: (cos((var_1*C_0))+cosh((var_2+var_0)))\n",
      "Tokens: ['(', 'cos', '(', '(', 'var_1', '*', 'C_0', ')', ')', '+', 'cosh', '(', '(', 'var_2', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_139.json\n",
      "Formula: (reverse((var_2*var_1))*pow_2(gaussian(var_0)))\n",
      "Tokens: ['(', 'reverse', '(', '(', 'var_2', '*', 'var_1', ')', ')', '*', 'pow_2', '(', 'gaussian', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_0.json\n",
      "Formula: ((cos(var_1)+(var_2*C_0))*((var_0*var_0)*cos(var_2)))\n",
      "Tokens: ['(', '(', 'cos', '(', 'var_1', ')', '+', '(', 'var_2', '*', 'C_0', ')', ')', '*', '(', '(', 'var_0', '*', 'var_0', ')', '*', 'cos', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_586.json\n",
      "Formula: (((var_1+var_0)*(var_0*C_0))+cos((var_2+C_1)))\n",
      "Tokens: ['(', '(', '(', 'var_1', '+', 'var_0', ')', '*', '(', 'var_0', '*', 'C_0', ')', ')', '+', 'cos', '(', '(', 'var_2', '+', 'C_1', ')', ')', ')']\n",
      "\n",
      "File: f_41.json\n",
      "Formula: (pow_2((var_1+var_0))*exp(tan(var_2)))\n",
      "Tokens: ['(', 'pow_2', '(', '(', 'var_1', '+', 'var_0', ')', ')', '*', 'exp', '(', 'tan', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_355.json\n",
      "Formula: (exp((var_0+var_1))+reverse((var_2+C_0)))\n",
      "Tokens: ['(', 'exp', '(', '(', 'var_0', '+', 'var_1', ')', ')', '+', 'reverse', '(', '(', 'var_2', '+', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_705.json\n",
      "Formula: (tan((var_2+var_0))+log(tan(var_1)))\n",
      "Tokens: ['(', 'tan', '(', '(', 'var_2', '+', 'var_0', ')', ')', '+', 'log', '(', 'tan', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_210.json\n",
      "Formula: (sqrt(log(var_2))+sqrt((var_0+var_1)))\n",
      "Tokens: ['(', 'sqrt', '(', 'log', '(', 'var_2', ')', ')', '+', 'sqrt', '(', '(', 'var_0', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_640.json\n",
      "Formula: (reverse((var_0+var_1))*gaussian(sinh(var_2)))\n",
      "Tokens: ['(', 'reverse', '(', '(', 'var_0', '+', 'var_1', ')', ')', '*', 'gaussian', '(', 'sinh', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_494.json\n",
      "Formula: ((cos(var_2)+exp(var_0))+sqrt(tanh(var_1)))\n",
      "Tokens: ['(', '(', 'cos', '(', 'var_2', ')', '+', 'exp', '(', 'var_0', ')', ')', '+', 'sqrt', '(', 'tanh', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_16.json\n",
      "Formula: (neg((var_0*C_0))+sin((var_2*var_1)))\n",
      "Tokens: ['(', 'neg', '(', '(', 'var_0', '*', 'C_0', ')', ')', '+', 'sin', '(', '(', 'var_2', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_181.json\n",
      "Formula: (gaussian(cosh(var_2))+reverse((var_1*var_0)))\n",
      "Tokens: ['(', 'gaussian', '(', 'cosh', '(', 'var_2', ')', ')', '+', 'reverse', '(', '(', 'var_1', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_302.json\n",
      "Formula: (pow_2((var_0*var_1))*cos(neg(var_2)))\n",
      "Tokens: ['(', 'pow_2', '(', '(', 'var_0', '*', 'var_1', ')', ')', '*', 'cos', '(', 'neg', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_617.json\n",
      "Formula: ((gaussian(var_0)+(var_1*C_0))+tanh(pow_2(var_2)))\n",
      "Tokens: ['(', '(', 'gaussian', '(', 'var_0', ')', '+', '(', 'var_1', '*', 'C_0', ')', ')', '+', 'tanh', '(', 'pow_2', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_247.json\n",
      "Formula: ((tan(var_0)+pow_2(var_1))*exp(neg(var_2)))\n",
      "Tokens: ['(', '(', 'tan', '(', 'var_0', ')', '+', 'pow_2', '(', 'var_1', ')', ')', '*', 'exp', '(', 'neg', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_230.json\n",
      "Formula: (sinh((var_1+var_0))*cosh(log(var_2)))\n",
      "Tokens: ['(', 'sinh', '(', '(', 'var_1', '+', 'var_0', ')', ')', '*', 'cosh', '(', 'log', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_660.json\n",
      "Formula: ((pow_2(var_1)+cosh(var_0))+cosh(tan(var_2)))\n",
      "Tokens: ['(', '(', 'pow_2', '(', 'var_1', ')', '+', 'cosh', '(', 'var_0', ')', ')', '+', 'cosh', '(', 'tan', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_375.json\n",
      "Formula: ((tanh(var_0)+reverse(var_1))+neg(gaussian(var_2)))\n",
      "Tokens: ['(', '(', 'tanh', '(', 'var_0', ')', '+', 'reverse', '(', 'var_1', ')', ')', '+', 'neg', '(', 'gaussian', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_725.json\n",
      "Formula: ((sin(var_0)+tanh(var_1))+gaussian(gaussian(var_2)))\n",
      "Tokens: ['(', '(', 'sin', '(', 'var_0', ')', '+', 'tanh', '(', 'var_1', ')', ')', '+', 'gaussian', '(', 'gaussian', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_61.json\n",
      "Formula: ((tanh(var_0)*(var_2+C_0))+gaussian(pow_2(var_1)))\n",
      "Tokens: ['(', '(', 'tanh', '(', 'var_0', ')', '*', '(', 'var_2', '+', 'C_0', ')', ')', '+', 'gaussian', '(', 'pow_2', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_549.json\n",
      "Formula: (log(cos(var_0))+sqrt((var_1+var_2)))\n",
      "Tokens: ['(', 'log', '(', 'cos', '(', 'var_0', ')', ')', '+', 'sqrt', '(', '(', 'var_1', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_119.json\n",
      "Formula: (neg((var_1*var_0))*sin(sqrt(var_2)))\n",
      "Tokens: ['(', 'neg', '(', '(', 'var_1', '*', 'var_0', ')', ')', '*', 'sin', '(', 'sqrt', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_637.json\n",
      "Formula: (((var_0*var_1)*tan(var_2))+sinh(cos(var_0)))\n",
      "Tokens: ['(', '(', '(', 'var_0', '*', 'var_1', ')', '*', 'tan', '(', 'var_2', ')', ')', '+', 'sinh', '(', 'cos', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_267.json\n",
      "Formula: (gaussian(sinh(var_1))+cosh((var_0*var_2)))\n",
      "Tokens: ['(', 'gaussian', '(', 'sinh', '(', 'var_1', ')', ')', '+', 'cosh', '(', '(', 'var_0', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_288.json\n",
      "Formula: (reverse(tan(var_2))*tan((var_0+var_1)))\n",
      "Tokens: ['(', 'reverse', '(', 'tan', '(', 'var_2', ')', ')', '*', 'tan', '(', '(', 'var_0', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_322.json\n",
      "Formula: ((sinh(var_2)+sin(var_1))+cos(pow_2(var_0)))\n",
      "Tokens: ['(', '(', 'sinh', '(', 'var_2', ')', '+', 'sin', '(', 'var_1', ')', ')', '+', 'cos', '(', 'pow_2', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_36.json\n",
      "Formula: ((var_0+cosh(var_2))*log(var_1))\n",
      "Tokens: ['(', '(', 'var_0', '+', 'cosh', '(', 'var_2', ')', ')', '*', 'log', '(', 'var_1', ')', ')']\n",
      "\n",
      "File: f_271.json\n",
      "Formula: (tan(pow_2(var_1))*neg((var_2+var_0)))\n",
      "Tokens: ['(', 'tan', '(', 'pow_2', '(', 'var_1', ')', ')', '*', 'neg', '(', '(', 'var_2', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_621.json\n",
      "Formula: (tan((var_2+var_1))*exp(var_0))\n",
      "Tokens: ['(', 'tan', '(', '(', 'var_2', '+', 'var_1', ')', ')', '*', 'exp', '(', 'var_0', ')', ')']\n",
      "\n",
      "File: f_334.json\n",
      "Formula: (((var_2+var_0)*(var_2+C_0))+(sqrt(var_1)+cos(var_1)))\n",
      "Tokens: ['(', '(', '(', 'var_2', '+', 'var_0', ')', '*', '(', 'var_2', '+', 'C_0', ')', ')', '+', '(', 'sqrt', '(', 'var_1', ')', '+', 'cos', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_20.json\n",
      "Formula: (sinh((var_2+var_1))+sqrt(tan(var_0)))\n",
      "Tokens: ['(', 'sinh', '(', '(', 'var_2', '+', 'var_1', ')', ')', '+', 'sqrt', '(', 'tan', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_508.json\n",
      "Formula: ((cos(var_0)*gaussian(var_2))*neg(gaussian(var_1)))\n",
      "Tokens: ['(', '(', 'cos', '(', 'var_0', ')', '*', 'gaussian', '(', 'var_2', ')', ')', '*', 'neg', '(', 'gaussian', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_158.json\n",
      "Formula: ((var_0*sinh(var_2))+(sqrt(var_1)*reverse(var_1)))\n",
      "Tokens: ['(', '(', 'var_0', '*', 'sinh', '(', 'var_2', ')', ')', '+', '(', 'sqrt', '(', 'var_1', ')', '*', 'reverse', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_676.json\n",
      "Formula: (reverse((var_0+var_2))*cosh(cosh(var_1)))\n",
      "Tokens: ['(', 'reverse', '(', '(', 'var_0', '+', 'var_2', ')', ')', '*', 'cosh', '(', 'cosh', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_226.json\n",
      "Formula: (tan(neg(var_0))+tanh((var_2+var_1)))\n",
      "Tokens: ['(', 'tan', '(', 'neg', '(', 'var_0', ')', ')', '+', 'tanh', '(', '(', 'var_2', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_733.json\n",
      "Formula: ((tan(var_0)+pow_2(var_2))+gaussian(cosh(var_1)))\n",
      "Tokens: ['(', '(', 'tan', '(', 'var_0', ')', '+', 'pow_2', '(', 'var_2', ')', ')', '+', 'gaussian', '(', 'cosh', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_363.json\n",
      "Formula: (((var_0+C_0)+sqrt(var_1))*sinh((var_2+C_1)))\n",
      "Tokens: ['(', '(', '(', 'var_0', '+', 'C_0', ')', '+', 'sqrt', '(', 'var_1', ')', ')', '*', 'sinh', '(', '(', 'var_2', '+', 'C_1', ')', ')', ')']\n",
      "\n",
      "File: f_699.json\n",
      "Formula: (reverse(cosh(var_1))*log((var_0+var_2)))\n",
      "Tokens: ['(', 'reverse', '(', 'cosh', '(', 'var_1', ')', ')', '*', 'log', '(', '(', 'var_0', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_77.json\n",
      "Formula: (log((var_1+var_2))*sin(pow_2(var_0)))\n",
      "Tokens: ['(', 'log', '(', '(', 'var_1', '+', 'var_2', ')', ')', '*', 'sin', '(', 'pow_2', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_98.json\n",
      "Formula: ((tan(var_2)+cosh(var_0))+cosh(cos(var_1)))\n",
      "Tokens: ['(', '(', 'tan', '(', 'var_2', ')', '+', 'cosh', '(', 'var_0', ')', ')', '+', 'cosh', '(', 'cos', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_318.json\n",
      "Formula: ((log(var_0)*sin(var_1))*reverse(gaussian(var_2)))\n",
      "Tokens: ['(', '(', 'log', '(', 'var_0', ')', '*', 'sin', '(', 'var_1', ')', ')', '*', 'reverse', '(', 'gaussian', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_174.json\n",
      "Formula: (sinh(sqrt(var_2))*tanh((var_1+var_0)))\n",
      "Tokens: ['(', 'sinh', '(', 'sqrt', '(', 'var_2', ')', ')', '*', 'tanh', '(', '(', 'var_1', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_524.json\n",
      "Formula: (pow_2(cos(var_0))+log((var_2*var_1)))\n",
      "Tokens: ['(', 'pow_2', '(', 'cos', '(', 'var_0', ')', ')', '+', 'log', '(', '(', 'var_2', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_461.json\n",
      "Formula: ((gaussian(var_1)+neg(var_2))*(C_0*(var_0+C_1)))\n",
      "Tokens: ['(', '(', 'gaussian', '(', 'var_1', ')', '+', 'neg', '(', 'var_2', ')', ')', '*', '(', 'C_0', '*', '(', 'var_0', '+', 'C_1', ')', ')', ')']\n",
      "\n",
      "File: f_573.json\n",
      "Formula: ((sin(var_2)*log(var_1))*reverse(exp(var_0)))\n",
      "Tokens: ['(', '(', 'sin', '(', 'var_2', ')', '*', 'log', '(', 'var_1', ')', ')', '*', 'reverse', '(', 'exp', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_123.json\n",
      "Formula: (exp((var_0+var_2))+pow_2(sqrt(var_1)))\n",
      "Tokens: ['(', 'exp', '(', '(', 'var_0', '+', 'var_2', ')', ')', '+', 'pow_2', '(', 'sqrt', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_436.json\n",
      "Formula: ((tan(var_2)+gaussian(var_0))*tan(var_1))\n",
      "Tokens: ['(', '(', 'tan', '(', 'var_2', ')', '+', 'gaussian', '(', 'var_0', ')', ')', '*', 'tan', '(', 'var_1', ')', ')']\n",
      "\n",
      "File: f_709.json\n",
      "Formula: (((var_2*C_0)+gaussian(var_1))+cosh((var_0+var_1)))\n",
      "Tokens: ['(', '(', '(', 'var_2', '*', 'C_0', ')', '+', 'gaussian', '(', 'var_1', ')', ')', '+', 'cosh', '(', '(', 'var_0', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_359.json\n",
      "Formula: (((var_0*C_0)*reverse(var_1))*exp(var_2))\n",
      "Tokens: ['(', '(', '(', 'var_0', '*', 'C_0', ')', '*', 'reverse', '(', 'var_1', ')', ')', '*', 'exp', '(', 'var_2', ')', ')']\n",
      "\n",
      "File: f_135.json\n",
      "Formula: ((sin(var_0)+tan(var_2))+(sin(var_1)+neg(var_1)))\n",
      "Tokens: ['(', '(', 'sin', '(', 'var_0', ')', '+', 'tan', '(', 'var_2', ')', ')', '+', '(', 'sin', '(', 'var_1', ')', '+', 'neg', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_565.json\n",
      "Formula: ((log(var_2)*exp(var_1))*log(cos(var_0)))\n",
      "Tokens: ['(', '(', 'log', '(', 'var_2', ')', '*', 'exp', '(', 'var_1', ')', ')', '*', 'log', '(', 'cos', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_420.json\n",
      "Formula: (reverse(exp(var_2))+exp((var_0+var_1)))\n",
      "Tokens: ['(', 'reverse', '(', 'exp', '(', 'var_2', ')', ')', '+', 'exp', '(', '(', 'var_0', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_532.json\n",
      "Formula: ((tanh(var_0)+exp(var_1))+pow_2(gaussian(var_2)))\n",
      "Tokens: ['(', '(', 'tanh', '(', 'var_0', ')', '+', 'exp', '(', 'var_1', ')', ')', '+', 'pow_2', '(', 'gaussian', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_162.json\n",
      "Formula: sinh((var_1+(var_2+var_0)))\n",
      "Tokens: ['sinh', '(', '(', 'var_1', '+', '(', 'var_2', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_498.json\n",
      "Formula: (log((var_2*var_0))*sqrt((var_1*C_0)))\n",
      "Tokens: ['(', 'log', '(', '(', 'var_2', '*', 'var_0', ')', ')', '*', 'sqrt', '(', '(', 'var_1', '*', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_477.json\n",
      "Formula: (pow_2((var_2+var_1))+neg(log(var_0)))\n",
      "Tokens: ['(', 'pow_2', '(', '(', 'var_2', '+', 'var_1', ')', ')', '+', 'neg', '(', 'log', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_533.json\n",
      "Formula: ((sinh(var_2)*log(var_1))*cos(sqrt(var_0)))\n",
      "Tokens: ['(', '(', 'sinh', '(', 'var_2', ')', '*', 'log', '(', 'var_1', ')', ')', '*', 'cos', '(', 'sqrt', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_163.json\n",
      "Formula: ((sin(var_2)*cosh(var_1))*neg(var_0))\n",
      "Tokens: ['(', '(', 'sin', '(', 'var_2', ')', '*', 'cosh', '(', 'var_1', ')', ')', '*', 'neg', '(', 'var_0', ')', ')']\n",
      "\n",
      "File: f_499.json\n",
      "Formula: (sqrt(reverse(var_1))*sin((var_0+var_2)))\n",
      "Tokens: ['(', 'sqrt', '(', 'reverse', '(', 'var_1', ')', ')', '*', 'sin', '(', '(', 'var_0', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_476.json\n",
      "Formula: ((var_2*(var_0*var_1))+cos((var_0*var_0)))\n",
      "Tokens: ['(', '(', 'var_2', '*', '(', 'var_0', '*', 'var_1', ')', ')', '+', 'cos', '(', '(', 'var_0', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_134.json\n",
      "Formula: (sqrt(sqrt(var_2))*sinh((var_1+var_0)))\n",
      "Tokens: ['(', 'sqrt', '(', 'sqrt', '(', 'var_2', ')', ')', '*', 'sinh', '(', '(', 'var_1', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_564.json\n",
      "Formula: ((tanh(var_0)+exp(var_1))*reverse(exp(var_2)))\n",
      "Tokens: ['(', '(', 'tanh', '(', 'var_0', ')', '+', 'exp', '(', 'var_1', ')', ')', '*', 'reverse', '(', 'exp', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_421.json\n",
      "Formula: (cosh(tanh(var_0))*log((var_1*var_2)))\n",
      "Tokens: ['(', 'cosh', '(', 'tanh', '(', 'var_0', ')', ')', '*', 'log', '(', '(', 'var_1', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_708.json\n",
      "Formula: (cos((var_1+var_2))*neg(tanh(var_0)))\n",
      "Tokens: ['(', 'cos', '(', '(', 'var_1', '+', 'var_2', ')', ')', '*', 'neg', '(', 'tanh', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_358.json\n",
      "Formula: ((var_2*gaussian(var_0))+gaussian(cosh(var_1)))\n",
      "Tokens: ['(', '(', 'var_2', '*', 'gaussian', '(', 'var_0', ')', ')', '+', 'gaussian', '(', 'cosh', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_572.json\n",
      "Formula: (gaussian(neg(var_2))*cosh((var_1*var_0)))\n",
      "Tokens: ['(', 'gaussian', '(', 'neg', '(', 'var_2', ')', ')', '*', 'cosh', '(', '(', 'var_1', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_122.json\n",
      "Formula: (tan((var_1*var_0))+sin((var_2+C_0)))\n",
      "Tokens: ['(', 'tan', '(', '(', 'var_1', '*', 'var_0', ')', ')', '+', 'sin', '(', '(', 'var_2', '+', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_437.json\n",
      "Formula: (((var_1+C_0)*exp(var_2))+sqrt(exp(var_0)))\n",
      "Tokens: ['(', '(', '(', 'var_1', '+', 'C_0', ')', '*', 'exp', '(', 'var_2', ')', ')', '+', 'sqrt', '(', 'exp', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_175.json\n",
      "Formula: (sinh(sqrt(var_2))*sinh((var_1+var_0)))\n",
      "Tokens: ['(', 'sinh', '(', 'sqrt', '(', 'var_2', ')', ')', '*', 'sinh', '(', '(', 'var_1', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_525.json\n",
      "Formula: (sin((var_0*C_0))*neg((var_1+var_2)))\n",
      "Tokens: ['(', 'sin', '(', '(', 'var_0', '*', 'C_0', ')', ')', '*', 'neg', '(', '(', 'var_1', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_460.json\n",
      "Formula: cosh(((var_1+var_0)+(var_2+C_0)))\n",
      "Tokens: ['cosh', '(', '(', '(', 'var_1', '+', 'var_0', ')', '+', '(', 'var_2', '+', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_319.json\n",
      "Formula: ((reverse(var_1)+tanh(var_2))+sin(reverse(var_0)))\n",
      "Tokens: ['(', '(', 'reverse', '(', 'var_1', ')', '+', 'tanh', '(', 'var_2', ')', ')', '+', 'sin', '(', 'reverse', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_76.json\n",
      "Formula: (sinh(pow_2(var_2))*exp((var_0+var_1)))\n",
      "Tokens: ['(', 'sinh', '(', 'pow_2', '(', 'var_2', ')', ')', '*', 'exp', '(', '(', 'var_0', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_99.json\n",
      "Formula: (gaussian((var_0*C_0))*neg((var_2+var_1)))\n",
      "Tokens: ['(', 'gaussian', '(', '(', 'var_0', '*', 'C_0', ')', ')', '*', 'neg', '(', '(', 'var_2', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_677.json\n",
      "Formula: ((sqrt(var_2)*pow_2(var_1))+cos(pow_2(var_0)))\n",
      "Tokens: ['(', '(', 'sqrt', '(', 'var_2', ')', '*', 'pow_2', '(', 'var_1', ')', ')', '+', 'cos', '(', 'pow_2', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_227.json\n",
      "Formula: (((var_0*C_0)+neg(var_1))*(sqrt(var_2)+C_1))\n",
      "Tokens: ['(', '(', '(', 'var_0', '*', 'C_0', ')', '+', 'neg', '(', 'var_1', ')', ')', '*', '(', 'sqrt', '(', 'var_2', ')', '+', 'C_1', ')', ')']\n",
      "\n",
      "File: f_732.json\n",
      "Formula: ((neg(var_2)*neg(var_0))*gaussian(tanh(var_1)))\n",
      "Tokens: ['(', '(', 'neg', '(', 'var_2', ')', '*', 'neg', '(', 'var_0', ')', ')', '*', 'gaussian', '(', 'tanh', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_362.json\n",
      "Formula: (exp(neg(var_2))+gaussian((var_1*var_0)))\n",
      "Tokens: ['(', 'exp', '(', 'neg', '(', 'var_2', ')', ')', '+', 'gaussian', '(', '(', 'var_1', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_698.json\n",
      "Formula: (cos(sqrt(var_1))*pow_2((var_2*var_0)))\n",
      "Tokens: ['(', 'cos', '(', 'sqrt', '(', 'var_1', ')', ')', '*', 'pow_2', '(', '(', 'var_2', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_21.json\n",
      "Formula: (gaussian((var_0+var_2))+sinh(log(var_1)))\n",
      "Tokens: ['(', 'gaussian', '(', '(', 'var_0', '+', 'var_2', ')', ')', '+', 'sinh', '(', 'log', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_509.json\n",
      "Formula: (gaussian((var_0*var_1))*reverse(gaussian(var_2)))\n",
      "Tokens: ['(', 'gaussian', '(', '(', 'var_0', '*', 'var_1', ')', ')', '*', 'reverse', '(', 'gaussian', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_159.json\n",
      "Formula: ((exp(var_1)+(var_1*C_0))*(gaussian(var_2)+sinh(var_0)))\n",
      "Tokens: ['(', '(', 'exp', '(', 'var_1', ')', '+', '(', 'var_1', '*', 'C_0', ')', ')', '*', '(', 'gaussian', '(', 'var_2', ')', '+', 'sinh', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_270.json\n",
      "Formula: ((pow_2(var_1)*gaussian(var_0))*gaussian(exp(var_2)))\n",
      "Tokens: ['(', '(', 'pow_2', '(', 'var_1', ')', '*', 'gaussian', '(', 'var_0', ')', ')', '*', 'gaussian', '(', 'exp', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_620.json\n",
      "Formula: (gaussian((var_1+var_0))*neg(sin(var_2)))\n",
      "Tokens: ['(', 'gaussian', '(', '(', 'var_1', '+', 'var_0', ')', ')', '*', 'neg', '(', 'sin', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_335.json\n",
      "Formula: (sinh((var_1*var_2))+sinh(sinh(var_0)))\n",
      "Tokens: ['(', 'sinh', '(', '(', 'var_1', '*', 'var_2', ')', ')', '+', 'sinh', '(', 'sinh', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_37.json\n",
      "Formula: (tan((var_2*var_0))*gaussian(reverse(var_1)))\n",
      "Tokens: ['(', 'tan', '(', '(', 'var_2', '*', 'var_0', ')', ')', '*', 'gaussian', '(', 'reverse', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_636.json\n",
      "Formula: (((var_1+var_0)*log(var_2))*exp((var_2*C_0)))\n",
      "Tokens: ['(', '(', '(', 'var_1', '+', 'var_0', ')', '*', 'log', '(', 'var_2', ')', ')', '*', 'exp', '(', '(', 'var_2', '*', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_266.json\n",
      "Formula: (gaussian((var_0+var_2))+cosh(sqrt(var_1)))\n",
      "Tokens: ['(', 'gaussian', '(', '(', 'var_0', '+', 'var_2', ')', ')', '+', 'cosh', '(', 'sqrt', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_289.json\n",
      "Formula: ((cos(var_0)*tan(var_0))*((var_2+var_1)+var_0))\n",
      "Tokens: ['(', '(', 'cos', '(', 'var_0', ')', '*', 'tan', '(', 'var_0', ')', ')', '*', '(', '(', 'var_2', '+', 'var_1', ')', '+', 'var_0', ')', ')']\n",
      "\n",
      "File: f_323.json\n",
      "Formula: (tan((var_2*C_0))*neg((var_1*var_0)))\n",
      "Tokens: ['(', 'tan', '(', '(', 'var_2', '*', 'C_0', ')', ')', '*', 'neg', '(', '(', 'var_1', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_60.json\n",
      "Formula: (sin((var_1+var_0))+tanh(sinh(var_2)))\n",
      "Tokens: ['(', 'sin', '(', '(', 'var_1', '+', 'var_0', ')', ')', '+', 'tanh', '(', 'sinh', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_548.json\n",
      "Formula: ((sqrt(var_0)*reverse(var_1))*pow_2((var_2+var_0)))\n",
      "Tokens: ['(', '(', 'sqrt', '(', 'var_0', ')', '*', 'reverse', '(', 'var_1', ')', ')', '*', 'pow_2', '(', '(', 'var_2', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_118.json\n",
      "Formula: ((log(var_0)*var_2)*cosh((var_2*var_1)))\n",
      "Tokens: ['(', '(', 'log', '(', 'var_0', ')', '*', 'var_2', ')', '*', 'cosh', '(', '(', 'var_2', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_231.json\n",
      "Formula: (reverse((var_2*var_0))*sin(gaussian(var_1)))\n",
      "Tokens: ['(', 'reverse', '(', '(', 'var_2', '*', 'var_0', ')', ')', '*', 'sin', '(', 'gaussian', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_661.json\n",
      "Formula: (gaussian((var_2+var_0))+sqrt(sinh(var_1)))\n",
      "Tokens: ['(', 'gaussian', '(', '(', 'var_2', '+', 'var_0', ')', ')', '+', 'sqrt', '(', 'sinh', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_374.json\n",
      "Formula: (reverse((var_0*C_0))*tanh((var_2+var_1)))\n",
      "Tokens: ['(', 'reverse', '(', '(', 'var_0', '*', 'C_0', ')', ')', '*', 'tanh', '(', '(', 'var_2', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_724.json\n",
      "Formula: ((var_0*tan(var_1))+neg(sinh(var_2)))\n",
      "Tokens: ['(', '(', 'var_0', '*', 'tan', '(', 'var_1', ')', ')', '+', 'neg', '(', 'sinh', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_303.json\n",
      "Formula: (sin((var_2+var_1))*pow_2(exp(var_0)))\n",
      "Tokens: ['(', 'sin', '(', '(', 'var_2', '+', 'var_1', ')', ')', '*', 'pow_2', '(', 'exp', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_616.json\n",
      "Formula: (((var_2+var_2)*(var_0*var_2))+tanh(pow_2(var_1)))\n",
      "Tokens: ['(', '(', '(', 'var_2', '+', 'var_2', ')', '*', '(', 'var_0', '*', 'var_2', ')', ')', '+', 'tanh', '(', 'pow_2', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_246.json\n",
      "Formula: (tan(reverse(var_1))+sqrt((var_2+var_0)))\n",
      "Tokens: ['(', 'tan', '(', 'reverse', '(', 'var_1', ')', ')', '+', 'sqrt', '(', '(', 'var_2', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_495.json\n",
      "Formula: ((sqrt(var_2)+pow_2(var_0))*pow_2(sin(var_1)))\n",
      "Tokens: ['(', '(', 'sqrt', '(', 'var_2', ')', '+', 'pow_2', '(', 'var_0', ')', ')', '*', 'pow_2', '(', 'sin', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_17.json\n",
      "Formula: (neg(tan(var_2))*exp((var_1*var_0)))\n",
      "Tokens: ['(', 'neg', '(', 'tan', '(', 'var_2', ')', ')', '*', 'exp', '(', '(', 'var_1', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_180.json\n",
      "Formula: ((reverse(var_0)+sin(var_1))*sqrt((var_1*var_2)))\n",
      "Tokens: ['(', '(', 'reverse', '(', 'var_0', ')', '+', 'sin', '(', 'var_1', ')', ')', '*', 'sqrt', '(', '(', 'var_1', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_354.json\n",
      "Formula: ((pow_2(var_0)+exp(var_2))*cosh((var_1*C_0)))\n",
      "Tokens: ['(', '(', 'pow_2', '(', 'var_0', ')', '+', 'exp', '(', 'var_2', ')', ')', '*', 'cosh', '(', '(', 'var_1', '*', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_704.json\n",
      "Formula: gaussian(((var_1*var_2)+sinh(var_0)))\n",
      "Tokens: ['gaussian', '(', '(', '(', 'var_1', '*', 'var_2', ')', '+', 'sinh', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_211.json\n",
      "Formula: (exp((var_2+var_1))+sinh(reverse(var_0)))\n",
      "Tokens: ['(', 'exp', '(', '(', 'var_2', '+', 'var_1', ')', ')', '+', 'sinh', '(', 'reverse', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_641.json\n",
      "Formula: (tanh((var_1*var_2))+sqrt(pow_2(var_0)))\n",
      "Tokens: ['(', 'tanh', '(', '(', 'var_1', '*', 'var_2', ')', ')', '+', 'sqrt', '(', 'pow_2', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_568.json\n",
      "Formula: (cos((var_2*var_0))*cosh((var_1*C_0)))\n",
      "Tokens: ['(', 'cos', '(', '(', 'var_2', '*', 'var_0', ')', ')', '*', 'cosh', '(', '(', 'var_1', '*', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_138.json\n",
      "Formula: (reverse((var_1*var_0))+tan((var_2+C_0)))\n",
      "Tokens: ['(', 'reverse', '(', '(', 'var_1', '*', 'var_0', ')', ')', '+', 'tan', '(', '(', 'var_2', '+', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_1.json\n",
      "Formula: (((var_1+C_0)+tan(var_0))+tanh(exp(var_2)))\n",
      "Tokens: ['(', '(', '(', 'var_1', '+', 'C_0', ')', '+', 'tan', '(', 'var_0', ')', ')', '+', 'tanh', '(', 'exp', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_40.json\n",
      "Formula: ((reverse(var_2)*exp(var_1))+exp(tan(var_0)))\n",
      "Tokens: ['(', '(', 'reverse', '(', 'var_2', ')', '*', 'exp', '(', 'var_1', ')', ')', '+', 'exp', '(', 'tan', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_587.json\n",
      "Formula: (pow_2((var_0+C_0))*tanh((var_2+var_1)))\n",
      "Tokens: ['(', 'pow_2', '(', '(', 'var_0', '+', 'C_0', ')', ')', '*', 'tanh', '(', '(', 'var_2', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_712.json\n",
      "Formula: ((neg(var_0)*reverse(var_2))+reverse((var_1*C_0)))\n",
      "Tokens: ['(', '(', 'neg', '(', 'var_0', ')', '*', 'reverse', '(', 'var_2', ')', ')', '+', 'reverse', '(', '(', 'var_1', '*', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_342.json\n",
      "Formula: (pow_2((var_1*var_0))+exp(var_2))\n",
      "Tokens: ['(', 'pow_2', '(', '(', 'var_1', '*', 'var_0', ')', ')', '+', 'exp', '(', 'var_2', ')', ')']\n",
      "\n",
      "File: f_657.json\n",
      "Formula: (sinh(var_0)*gaussian((var_2*var_1)))\n",
      "Tokens: ['(', 'sinh', '(', 'var_0', ')', '*', 'gaussian', '(', '(', 'var_2', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_207.json\n",
      "Formula: (cosh((var_1+var_2))+gaussian((var_0+var_2)))\n",
      "Tokens: ['(', 'cosh', '(', '(', 'var_1', '+', 'var_2', ')', ')', '+', 'gaussian', '(', '(', 'var_0', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_56.json\n",
      "Formula: (log(tanh(var_1))*gaussian((var_2+var_0)))\n",
      "Tokens: ['(', 'log', '(', 'tanh', '(', 'var_1', ')', ')', '*', 'gaussian', '(', '(', 'var_2', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_591.json\n",
      "Formula: ((exp(var_1)*cosh(var_2))+reverse(pow_2(var_0)))\n",
      "Tokens: ['(', '(', 'exp', '(', 'var_1', ')', '*', 'cosh', '(', 'var_2', ')', ')', '+', 'reverse', '(', 'pow_2', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_315.json\n",
      "Formula: ((var_2+var_0)+tan(neg(var_1)))\n",
      "Tokens: ['(', '(', 'var_2', '+', 'var_0', ')', '+', 'tan', '(', 'neg', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_745.json\n",
      "Formula: ((cos(var_0)*(var_2*C_0))+tanh(sinh(var_1)))\n",
      "Tokens: ['(', '(', 'cos', '(', 'var_0', ')', '*', '(', 'var_2', '*', 'C_0', ')', ')', '+', 'tanh', '(', 'sinh', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_250.json\n",
      "Formula: ((exp(var_0)*exp(var_2))+reverse(cos(var_1)))\n",
      "Tokens: ['(', '(', 'exp', '(', 'var_0', ')', '*', 'exp', '(', 'var_2', ')', ')', '+', 'reverse', '(', 'cos', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_600.json\n",
      "Formula: ((neg(var_0)+cosh(var_1))*sinh(sqrt(var_2)))\n",
      "Tokens: ['(', '(', 'neg', '(', 'var_0', ')', '+', 'cosh', '(', 'var_1', ')', ')', '*', 'sinh', '(', 'sqrt', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_529.json\n",
      "Formula: ((tanh(var_0)+var_2)*log(cosh(var_1)))\n",
      "Tokens: ['(', '(', 'tanh', '(', 'var_0', ')', '+', 'var_2', ')', '*', 'log', '(', 'cosh', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_179.json\n",
      "Formula: ((sin(var_1)+cosh(var_0))+sinh(log(var_2)))\n",
      "Tokens: ['(', '(', 'sin', '(', 'var_1', ')', '+', 'cosh', '(', 'var_0', ')', ')', '+', 'sinh', '(', 'log', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_483.json\n",
      "Formula: ((cosh(var_2)+cos(var_2))*(gaussian(var_1)+cos(var_0)))\n",
      "Tokens: ['(', '(', 'cosh', '(', 'var_2', ')', '+', 'cos', '(', 'var_2', ')', ')', '*', '(', 'gaussian', '(', 'var_1', ')', '+', 'cos', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_196.json\n",
      "Formula: (sin(pow_2(var_0))*sqrt((var_1*var_2)))\n",
      "Tokens: ['(', 'sin', '(', 'pow_2', '(', 'var_0', ')', ')', '*', 'sqrt', '(', '(', 'var_1', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_381.json\n",
      "Formula: (sin((var_2*var_1))*log(neg(var_0)))\n",
      "Tokens: ['(', 'sin', '(', '(', 'var_2', '*', 'var_1', ')', ')', '*', 'log', '(', 'neg', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_694.json\n",
      "Formula: (cosh((var_0+var_1))*exp((var_2*var_2)))\n",
      "Tokens: ['(', 'cosh', '(', '(', 'var_0', '+', 'var_1', ')', ')', '*', 'exp', '(', '(', 'var_2', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_417.json\n",
      "Formula: (neg((var_1+var_2))*gaussian(pow_2(var_0)))\n",
      "Tokens: ['(', 'neg', '(', '(', 'var_1', '+', 'var_2', ')', ')', '*', 'gaussian', '(', 'pow_2', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_95.json\n",
      "Formula: (reverse(tan(var_2))*pow_2((var_0+var_1)))\n",
      "Tokens: ['(', 'reverse', '(', 'tan', '(', 'var_2', ')', ')', '*', 'pow_2', '(', '(', 'var_0', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_552.json\n",
      "Formula: (tan((var_1+var_0))*neg((var_2*C_0)))\n",
      "Tokens: ['(', 'tan', '(', '(', 'var_1', '+', 'var_0', ')', ')', '*', 'neg', '(', '(', 'var_2', '*', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_102.json\n",
      "Formula: (((var_2+var_0)*sqrt(var_1))*tanh((var_1+var_2)))\n",
      "Tokens: ['(', '(', '(', 'var_2', '+', 'var_0', ')', '*', 'sqrt', '(', 'var_1', ')', ')', '*', 'tanh', '(', '(', 'var_1', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_293.json\n",
      "Formula: (exp(var_0)+neg((var_2+var_1)))\n",
      "Tokens: ['(', 'exp', '(', 'var_0', ')', '+', 'neg', '(', '(', 'var_2', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_339.json\n",
      "Formula: (cosh(neg(var_0))*sinh((var_2*var_1)))\n",
      "Tokens: ['(', 'cosh', '(', 'neg', '(', 'var_0', ')', ')', '*', 'sinh', '(', '(', 'var_2', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_440.json\n",
      "Formula: ((neg(var_1)+reverse(var_2))+tan((var_0+var_2)))\n",
      "Tokens: ['(', '(', 'neg', '(', 'var_1', ')', '+', 'reverse', '(', 'var_2', ')', ')', '+', 'tan', '(', '(', 'var_0', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_155.json\n",
      "Formula: (exp(sin(var_2))+cosh((var_0+var_1)))\n",
      "Tokens: ['(', 'exp', '(', 'sin', '(', 'var_2', ')', ')', '+', 'cosh', '(', '(', 'var_0', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_505.json\n",
      "Formula: (log((var_1+var_0))+tan(var_2))\n",
      "Tokens: ['(', 'log', '(', '(', 'var_1', '+', 'var_0', ')', ')', '+', 'tan', '(', 'var_2', ')', ')']\n",
      "\n",
      "File: f_285.json\n",
      "Formula: (pow_2(tanh(var_1))+pow_2((var_0+var_2)))\n",
      "Tokens: ['(', 'pow_2', '(', 'tanh', '(', 'var_1', ')', ')', '+', 'pow_2', '(', '(', 'var_0', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_456.json\n",
      "Formula: (sqrt(sinh(var_1))*cos((var_2+var_0)))\n",
      "Tokens: ['(', 'sqrt', '(', 'sinh', '(', 'var_1', ')', ')', '*', 'cos', '(', '(', 'var_2', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_513.json\n",
      "Formula: (sin((var_1+C_0))*tan((var_2+var_0)))\n",
      "Tokens: ['(', 'sin', '(', '(', 'var_1', '+', 'C_0', ')', ')', '*', 'tan', '(', '(', 'var_2', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_143.json\n",
      "Formula: ((reverse(var_0)+tanh(var_1))*tan(gaussian(var_2)))\n",
      "Tokens: ['(', '(', 'reverse', '(', 'var_0', ')', '+', 'tanh', '(', 'var_1', ')', ')', '*', 'tan', '(', 'gaussian', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_397.json\n",
      "Formula: (gaussian((var_2*var_1))+reverse(sin(var_0)))\n",
      "Tokens: ['(', 'gaussian', '(', '(', 'var_2', '*', 'var_1', ')', ')', '+', 'reverse', '(', 'sin', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_728.json\n",
      "Formula: ((reverse(var_2)*cos(var_1))+(C_0*var_0))\n",
      "Tokens: ['(', '(', 'reverse', '(', 'var_2', ')', '*', 'cos', '(', 'var_1', ')', ')', '+', '(', 'C_0', '*', 'var_0', ')', ')']\n",
      "\n",
      "File: f_378.json\n",
      "Formula: (neg(reverse(var_0))+sin((var_1+var_2)))\n",
      "Tokens: ['(', 'neg', '(', 'reverse', '(', 'var_0', ')', ')', '+', 'sin', '(', '(', 'var_1', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_682.json\n",
      "Formula: ((sin(var_0)*exp(var_1))*cosh(tan(var_2)))\n",
      "Tokens: ['(', '(', 'sin', '(', 'var_0', ')', '*', 'exp', '(', 'var_1', ')', ')', '*', 'cosh', '(', 'tan', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_401.json\n",
      "Formula: ((exp(var_1)*sin(var_2))*reverse(pow_2(var_0)))\n",
      "Tokens: ['(', '(', 'exp', '(', 'var_1', ')', '*', 'sin', '(', 'var_2', ')', ')', '*', 'reverse', '(', 'pow_2', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_114.json\n",
      "Formula: ((tan(var_2)*sin(var_1))+cos(var_0))\n",
      "Tokens: ['(', '(', 'tan', '(', 'var_2', ')', '*', 'sin', '(', 'var_1', ')', ')', '+', 'cos', '(', 'var_0', ')', ')']\n",
      "\n",
      "File: f_83.json\n",
      "Formula: (cosh((var_1+var_2))+pow_2(exp(var_0)))\n",
      "Tokens: ['(', 'cosh', '(', '(', 'var_1', '+', 'var_2', ')', ')', '+', 'pow_2', '(', 'exp', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_544.json\n",
      "Formula: (neg(sin(var_2))*pow_2((var_1*var_0)))\n",
      "Tokens: ['(', 'neg', '(', 'sin', '(', 'var_2', ')', ')', '*', 'pow_2', '(', '(', 'var_1', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_236.json\n",
      "Formula: ((C_0+(var_1+C_1))*gaussian((var_2+var_0)))\n",
      "Tokens: ['(', '(', 'C_0', '+', '(', 'var_1', '+', 'C_1', ')', ')', '*', 'gaussian', '(', '(', 'var_2', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_666.json\n",
      "Formula: (gaussian(sqrt(var_0))*sqrt((var_2+var_1)))\n",
      "Tokens: ['(', 'gaussian', '(', 'sqrt', '(', 'var_0', ')', ')', '*', 'sqrt', '(', '(', 'var_2', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_373.json\n",
      "Formula: (cosh((var_2+var_0))+sqrt((var_1*C_0)))\n",
      "Tokens: ['(', 'cosh', '(', '(', 'var_2', '+', 'var_0', ')', ')', '+', 'sqrt', '(', '(', 'var_1', '*', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_689.json\n",
      "Formula: (reverse(pow_2(var_2))*cosh((var_0*var_1)))\n",
      "Tokens: ['(', 'reverse', '(', 'pow_2', '(', 'var_2', ')', ')', '*', 'cosh', '(', '(', 'var_0', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_723.json\n",
      "Formula: (reverse(cosh(var_2))*cosh((var_0*var_1)))\n",
      "Tokens: ['(', 'reverse', '(', 'cosh', '(', 'var_2', ')', ')', '*', 'cosh', '(', '(', 'var_0', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_67.json\n",
      "Formula: pow_2(((var_1+C_0)+(var_2*var_0)))\n",
      "Tokens: ['pow_2', '(', '(', '(', 'var_1', '+', 'C_0', ')', '+', '(', 'var_2', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_88.json\n",
      "Formula: (((var_2+C_0)+(var_2+C_1))+cosh((var_0*var_1)))\n",
      "Tokens: ['(', '(', '(', 'var_2', '+', 'C_0', ')', '+', '(', 'var_2', '+', 'C_1', ')', ')', '+', 'cosh', '(', '(', 'var_0', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_631.json\n",
      "Formula: (sqrt(cosh(var_0))+tanh((var_1+var_2)))\n",
      "Tokens: ['(', 'sqrt', '(', 'cosh', '(', 'var_0', ')', ')', '+', 'tanh', '(', '(', 'var_1', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_261.json\n",
      "Formula: (tan((var_1*C_0))+cos((var_0*var_2)))\n",
      "Tokens: ['(', 'tan', '(', '(', 'var_1', '*', 'C_0', ')', ')', '+', 'cos', '(', '(', 'var_0', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_324.json\n",
      "Formula: ((sin(var_2)+cosh(var_1))+(log(var_1)+cos(var_0)))\n",
      "Tokens: ['(', '(', 'sin', '(', 'var_2', ')', '+', 'cosh', '(', 'var_1', ')', ')', '+', '(', 'log', '(', 'var_1', ')', '+', 'cos', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_30.json\n",
      "Formula: ((var_1+sinh(var_0))*gaussian(pow_2(var_2)))\n",
      "Tokens: ['(', '(', 'var_1', '+', 'sinh', '(', 'var_0', ')', ')', '*', 'gaussian', '(', 'pow_2', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_148.json\n",
      "Formula: (pow_2(sin(var_0))+gaussian((var_2*var_1)))\n",
      "Tokens: ['(', 'pow_2', '(', 'sin', '(', 'var_0', ')', ')', '+', 'gaussian', '(', '(', 'var_2', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_518.json\n",
      "Formula: ((gaussian(var_0)+log(var_2))+log(tan(var_1)))\n",
      "Tokens: ['(', '(', 'gaussian', '(', 'var_0', ')', '+', 'log', '(', 'var_2', ')', ')', '+', 'log', '(', 'tan', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_277.json\n",
      "Formula: ((sinh(var_2)*sin(var_1))*(exp(var_1)*(var_0+C_0)))\n",
      "Tokens: ['(', '(', 'sinh', '(', 'var_2', ')', '*', 'sin', '(', 'var_1', ')', ')', '*', '(', 'exp', '(', 'var_1', ')', '*', '(', 'var_0', '+', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_627.json\n",
      "Formula: (gaussian((var_1+var_0))*cosh(neg(var_2)))\n",
      "Tokens: ['(', 'gaussian', '(', '(', 'var_1', '+', 'var_0', ')', ')', '*', 'cosh', '(', 'neg', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_332.json\n",
      "Formula: ((log(var_1)+neg(var_2))*(exp(var_0)*(var_1+C_0)))\n",
      "Tokens: ['(', '(', 'log', '(', 'var_1', ')', '+', 'neg', '(', 'var_2', ')', ')', '*', '(', 'exp', '(', 'var_0', ')', '*', '(', 'var_1', '+', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_298.json\n",
      "Formula: ((cos(var_1)*exp(var_2))*pow_2(sin(var_0)))\n",
      "Tokens: ['(', '(', 'cos', '(', 'var_1', ')', '*', 'exp', '(', 'var_2', ')', ')', '*', 'pow_2', '(', 'sin', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_26.json\n",
      "Formula: (tanh((var_0*var_2))*cosh((var_1+var_1)))\n",
      "Tokens: ['(', 'tanh', '(', '(', 'var_0', '*', 'var_2', ')', ')', '*', 'cosh', '(', '(', 'var_1', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_670.json\n",
      "Formula: (((var_2+var_1)*gaussian(var_0))+(sin(var_1)+tan(var_0)))\n",
      "Tokens: ['(', '(', '(', 'var_2', '+', 'var_1', ')', '*', 'gaussian', '(', 'var_0', ')', ')', '+', '(', 'sin', '(', 'var_1', ')', '+', 'tan', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_220.json\n",
      "Formula: ((neg(var_0)*sin(var_2))*sqrt(exp(var_1)))\n",
      "Tokens: ['(', '(', 'neg', '(', 'var_0', ')', '*', 'sin', '(', 'var_2', ')', ')', '*', 'sqrt', '(', 'exp', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_735.json\n",
      "Formula: (sinh((var_1*var_0))*pow_2(neg(var_2)))\n",
      "Tokens: ['(', 'sinh', '(', '(', 'var_1', '*', 'var_0', ')', ')', '*', 'pow_2', '(', 'neg', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_365.json\n",
      "Formula: (log((var_1+var_2))+sin((var_0+C_0)))\n",
      "Tokens: ['(', 'log', '(', '(', 'var_1', '+', 'var_2', ')', ')', '+', 'sin', '(', '(', 'var_0', '+', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_71.json\n",
      "Formula: ((var_1*gaussian(var_0))*exp((var_2*var_0)))\n",
      "Tokens: ['(', '(', 'var_1', '*', 'gaussian', '(', 'var_0', ')', ')', '*', 'exp', '(', '(', 'var_2', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_109.json\n",
      "Formula: (((var_0*C_0)+sinh(var_1))*reverse(gaussian(var_2)))\n",
      "Tokens: ['(', '(', '(', 'var_0', '*', 'C_0', ')', '+', 'sinh', '(', 'var_1', ')', ')', '*', 'reverse', '(', 'gaussian', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_559.json\n",
      "Formula: ((tan(var_0)+reverse(var_2))+sqrt(gaussian(var_1)))\n",
      "Tokens: ['(', '(', 'tan', '(', 'var_0', ')', '+', 'reverse', '(', 'var_2', ')', ')', '+', 'sqrt', '(', 'gaussian', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_172.json\n",
      "Formula: ((tanh(var_2)*cos(var_2))+((var_1+C_0)+(var_0+C_1)))\n",
      "Tokens: ['(', '(', 'tanh', '(', 'var_2', ')', '*', 'cos', '(', 'var_2', ')', ')', '+', '(', '(', 'var_1', '+', 'C_0', ')', '+', '(', 'var_0', '+', 'C_1', ')', ')', ')']\n",
      "\n",
      "File: f_488.json\n",
      "Formula: (reverse((var_0+C_0))*exp((var_1*var_2)))\n",
      "Tokens: ['(', 'reverse', '(', '(', 'var_0', '+', 'C_0', ')', ')', '*', 'exp', '(', '(', 'var_1', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_522.json\n",
      "Formula: ((C_0+(var_2*C_1))*tanh((var_1*var_0)))\n",
      "Tokens: ['(', '(', 'C_0', '+', '(', 'var_2', '*', 'C_1', ')', ')', '*', 'tanh', '(', '(', 'var_1', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_467.json\n",
      "Formula: (reverse((var_1*var_0))*exp(cosh(var_2)))\n",
      "Tokens: ['(', 'reverse', '(', '(', 'var_1', '*', 'var_0', ')', ')', '*', 'exp', '(', 'cosh', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_349.json\n",
      "Formula: (((var_2*var_1)*(var_2*var_0))*log(cos(var_1)))\n",
      "Tokens: ['(', '(', '(', 'var_2', '*', 'var_1', ')', '*', '(', 'var_2', '*', 'var_0', ')', ')', '*', 'log', '(', 'cos', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_719.json\n",
      "Formula: ((log(var_2)*(var_0*C_0))+pow_2(tanh(var_1)))\n",
      "Tokens: ['(', '(', 'log', '(', 'var_2', ')', '*', '(', 'var_0', '*', 'C_0', ')', ')', '+', 'pow_2', '(', 'tanh', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_575.json\n",
      "Formula: (cosh((var_1*var_2))+tan((var_0*var_2)))\n",
      "Tokens: ['(', 'cosh', '(', '(', 'var_1', '*', 'var_2', ')', ')', '+', 'tan', '(', '(', 'var_0', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_125.json\n",
      "Formula: (log((var_0+var_1))*pow_2((var_2+C_0)))\n",
      "Tokens: ['(', 'log', '(', '(', 'var_0', '+', 'var_1', ')', ')', '*', 'pow_2', '(', '(', 'var_2', '+', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_430.json\n",
      "Formula: (log(var_0)+cos((var_2*var_1)))\n",
      "Tokens: ['(', 'log', '(', 'var_0', ')', '+', 'cos', '(', '(', 'var_2', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_133.json\n",
      "Formula: ((exp(var_2)*tanh(var_1))*pow_2(cosh(var_0)))\n",
      "Tokens: ['(', '(', 'exp', '(', 'var_2', ')', '*', 'tanh', '(', 'var_1', ')', ')', '*', 'pow_2', '(', 'cosh', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_563.json\n",
      "Formula: ((sqrt(var_0)*sin(var_2))*neg(cosh(var_1)))\n",
      "Tokens: ['(', '(', 'sqrt', '(', 'var_0', ')', '*', 'sin', '(', 'var_2', ')', ')', '*', 'neg', '(', 'cosh', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_426.json\n",
      "Formula: (((var_2+var_0)*tan(var_1))+neg(C_0))\n",
      "Tokens: ['(', '(', '(', 'var_2', '+', 'var_0', ')', '*', 'tan', '(', 'var_1', ')', ')', '+', 'neg', '(', 'C_0', ')', ')']\n",
      "\n",
      "File: f_308.json\n",
      "Formula: (pow_2(reverse(var_1))+cos((var_2*var_0)))\n",
      "Tokens: ['(', 'pow_2', '(', 'reverse', '(', 'var_1', ')', ')', '+', 'cos', '(', '(', 'var_2', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_534.json\n",
      "Formula: (neg(exp(var_2))+cos((var_1+var_0)))\n",
      "Tokens: ['(', 'neg', '(', 'exp', '(', 'var_2', ')', ')', '+', 'cos', '(', '(', 'var_1', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_164.json\n",
      "Formula: ((cos(var_1)*(var_0+var_1))+exp((var_2*C_0)))\n",
      "Tokens: ['(', '(', 'cos', '(', 'var_1', ')', '*', '(', 'var_0', '+', 'var_1', ')', ')', '+', 'exp', '(', '(', 'var_2', '*', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_471.json\n",
      "Formula: (((var_2+C_0)*reverse(var_0))*sqrt(var_1))\n",
      "Tokens: ['(', '(', '(', 'var_2', '+', 'C_0', ')', '*', 'reverse', '(', 'var_0', ')', ')', '*', 'sqrt', '(', 'var_1', ')', ')']\n",
      "\n",
      "File: f_406.json\n",
      "Formula: (((var_0+var_0)*(var_1+var_0))*gaussian(cosh(var_2)))\n",
      "Tokens: ['(', '(', '(', 'var_0', '+', 'var_0', ')', '*', '(', 'var_1', '+', 'var_0', ')', ')', '*', 'gaussian', '(', 'cosh', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_113.json\n",
      "Formula: neg((tan(var_2)*(var_0*var_1)))\n",
      "Tokens: ['neg', '(', '(', 'tan', '(', 'var_2', ')', '*', '(', 'var_0', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_543.json\n",
      "Formula: ((tan(var_2)*cosh(var_0))+tanh(gaussian(var_1)))\n",
      "Tokens: ['(', '(', 'tan', '(', 'var_2', ')', '*', 'cosh', '(', 'var_0', ')', ')', '+', 'tanh', '(', 'gaussian', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_84.json\n",
      "Formula: ((sin(var_0)*(var_1+C_0))+cos(pow_2(var_2)))\n",
      "Tokens: ['(', '(', 'sin', '(', 'var_0', ')', '*', '(', 'var_1', '+', 'C_0', ')', ')', '+', 'cos', '(', 'pow_2', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_390.json\n",
      "Formula: (log((var_0*var_2))+cos(gaussian(var_1)))\n",
      "Tokens: ['(', 'log', '(', '(', 'var_0', '*', 'var_2', ')', ')', '+', 'cos', '(', 'gaussian', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_685.json\n",
      "Formula: (exp((var_0*var_2))*cosh(log(var_1)))\n",
      "Tokens: ['(', 'exp', '(', '(', 'var_0', '*', 'var_2', ')', ')', '*', 'cosh', '(', 'log', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_451.json\n",
      "Formula: (cos(var_1)+sin((var_0*var_2)))\n",
      "Tokens: ['(', 'cos', '(', 'var_1', ')', '+', 'sin', '(', '(', 'var_0', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_514.json\n",
      "Formula: (tanh((var_2*var_2))+cosh((var_1*var_0)))\n",
      "Tokens: ['(', 'tanh', '(', '(', 'var_2', '*', 'var_2', ')', ')', '+', 'cosh', '(', '(', 'var_1', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_144.json\n",
      "Formula: ((exp(var_1)+reverse(var_0))*sin(var_2))\n",
      "Tokens: ['(', '(', 'exp', '(', 'var_1', ')', '+', 'reverse', '(', 'var_0', ')', ')', '*', 'sin', '(', 'var_2', ')', ')']\n",
      "\n",
      "File: f_328.json\n",
      "Formula: ((gaussian(var_0)*(var_1*var_2))+((var_1*var_1)*pow_2(var_1)))\n",
      "Tokens: ['(', '(', 'gaussian', '(', 'var_0', ')', '*', '(', 'var_1', '*', 'var_2', ')', ')', '+', '(', '(', 'var_1', '*', 'var_1', ')', '*', 'pow_2', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_282.json\n",
      "Formula: (sin((var_0+var_2))*gaussian(log(var_1)))\n",
      "Tokens: ['(', 'sin', '(', '(', 'var_0', '+', 'var_2', ')', ')', '*', 'gaussian', '(', 'log', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_447.json\n",
      "Formula: (sinh(cos(var_1))+reverse((var_0*var_2)))\n",
      "Tokens: ['(', 'sinh', '(', 'cos', '(', 'var_1', ')', ')', '+', 'reverse', '(', '(', 'var_0', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_152.json\n",
      "Formula: (neg((var_2*var_0))*cosh(gaussian(var_1)))\n",
      "Tokens: ['(', 'neg', '(', '(', 'var_2', '*', 'var_0', ')', ')', '*', 'cosh', '(', 'gaussian', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_502.json\n",
      "Formula: gaussian((var_1+(var_2+var_0)))\n",
      "Tokens: ['gaussian', '(', '(', 'var_1', '+', '(', 'var_2', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_294.json\n",
      "Formula: ((log(var_0)+pow_2(var_2))+reverse(log(var_1)))\n",
      "Tokens: ['(', '(', 'log', '(', 'var_0', ')', '+', 'pow_2', '(', 'var_2', ')', ')', '+', 'reverse', '(', 'log', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_410.json\n",
      "Formula: ((tanh(var_1)*sqrt(var_0))+gaussian(sinh(var_2)))\n",
      "Tokens: ['(', '(', 'tanh', '(', 'var_1', ')', '*', 'sqrt', '(', 'var_0', ')', ')', '+', 'gaussian', '(', 'sinh', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_555.json\n",
      "Formula: (sqrt((var_0*var_1))*log(reverse(var_2)))\n",
      "Tokens: ['(', 'sqrt', '(', '(', 'var_0', '*', 'var_1', ')', ')', '*', 'log', '(', 'reverse', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_92.json\n",
      "Formula: (((var_0+var_2)+(var_2+var_2))*(tan(var_0)*tan(var_1)))\n",
      "Tokens: ['(', '(', '(', 'var_0', '+', 'var_2', ')', '+', '(', 'var_2', '+', 'var_2', ')', ')', '*', '(', 'tan', '(', 'var_0', ')', '*', 'tan', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_105.json\n",
      "Formula: (tanh(log(var_0))+tanh((var_2+var_1)))\n",
      "Tokens: ['(', 'tanh', '(', 'log', '(', 'var_0', ')', ')', '+', 'tanh', '(', '(', 'var_2', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_386.json\n",
      "Formula: ((tanh(var_1)*sqrt(var_0))+(gaussian(var_2)*(var_1*var_2)))\n",
      "Tokens: ['(', '(', 'tanh', '(', 'var_1', ')', '*', 'sqrt', '(', 'var_0', ')', ')', '+', '(', 'gaussian', '(', 'var_2', ')', '*', '(', 'var_1', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_369.json\n",
      "Formula: ((tan(var_0)*tanh(var_2))*(tanh(var_1)+sqrt(var_0)))\n",
      "Tokens: ['(', '(', 'tan', '(', 'var_0', ')', '*', 'tanh', '(', 'var_2', ')', ')', '*', '(', 'tanh', '(', 'var_1', ')', '+', 'sqrt', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_693.json\n",
      "Formula: ((neg(var_0)*var_2)*log(cosh(var_1)))\n",
      "Tokens: ['(', '(', 'neg', '(', 'var_0', ')', '*', 'var_2', ')', '*', 'log', '(', 'cosh', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_739.json\n",
      "Formula: (cosh(sin(var_1))+cos((var_2+var_0)))\n",
      "Tokens: ['(', 'cosh', '(', 'sin', '(', 'var_1', ')', ')', '+', 'cos', '(', '(', 'var_2', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_484.json\n",
      "Formula: ((pow_2(var_2)+pow_2(var_0))*gaussian(neg(var_1)))\n",
      "Tokens: ['(', '(', 'pow_2', '(', 'var_2', ')', '+', 'pow_2', '(', 'var_0', ')', ')', '*', 'gaussian', '(', 'neg', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_191.json\n",
      "Formula: ((cosh(var_1)+sinh(var_1))+cos((var_2+var_0)))\n",
      "Tokens: ['(', '(', 'cosh', '(', 'var_1', ')', '+', 'sinh', '(', 'var_1', ')', ')', '+', 'cos', '(', '(', 'var_2', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_312.json\n",
      "Formula: (cos((var_0*var_2))*cos(sqrt(var_1)))\n",
      "Tokens: ['(', 'cos', '(', '(', 'var_0', '*', 'var_2', ')', ')', '*', 'cos', '(', 'sqrt', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_742.json\n",
      "Formula: (cosh(gaussian(var_0))+tan((var_1+var_2)))\n",
      "Tokens: ['(', 'cosh', '(', 'gaussian', '(', 'var_0', ')', ')', '+', 'tan', '(', '(', 'var_1', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_257.json\n",
      "Formula: ((tanh(var_0)*sqrt(var_2))+sinh(gaussian(var_1)))\n",
      "Tokens: ['(', '(', 'tanh', '(', 'var_0', ')', '*', 'sqrt', '(', 'var_2', ')', ')', '+', 'sinh', '(', 'gaussian', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_607.json\n",
      "Formula: (sqrt((var_1+var_2))+cosh(sin(var_0)))\n",
      "Tokens: ['(', 'sqrt', '(', '(', 'var_1', '+', 'var_2', ')', ')', '+', 'cosh', '(', 'sin', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_129.json\n",
      "Formula: ((sqrt(var_1)+cos(var_2))*(log(var_0)+reverse(var_2)))\n",
      "Tokens: ['(', '(', 'sqrt', '(', 'var_1', ')', '+', 'cos', '(', 'var_2', ')', ')', '*', '(', 'log', '(', 'var_0', ')', '+', 'reverse', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_579.json\n",
      "Formula: (((var_1+C_0)+var_0)+log(cos(var_2)))\n",
      "Tokens: ['(', '(', '(', 'var_1', '+', 'C_0', ')', '+', 'var_0', ')', '+', 'log', '(', 'cos', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_596.json\n",
      "Formula: (sqrt((var_1+var_2))*cosh(neg(var_0)))\n",
      "Tokens: ['(', 'sqrt', '(', '(', 'var_1', '+', 'var_2', ')', ')', '*', 'cosh', '(', 'neg', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_51.json\n",
      "Formula: (sin((var_2*C_0))*sin((var_0+var_1)))\n",
      "Tokens: ['(', 'sin', '(', '(', 'var_2', '*', 'C_0', ')', ')', '*', 'sin', '(', '(', 'var_0', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_715.json\n",
      "Formula: (gaussian((var_1*var_2))+exp(neg(var_0)))\n",
      "Tokens: ['(', 'gaussian', '(', '(', 'var_1', '*', 'var_2', ')', ')', '+', 'exp', '(', 'neg', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_345.json\n",
      "Formula: (sin((var_2*var_0))*cosh(cosh(var_1)))\n",
      "Tokens: ['(', 'sin', '(', '(', 'var_2', '*', 'var_0', ')', ')', '*', 'cosh', '(', 'cosh', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_650.json\n",
      "Formula: (exp(tan(var_0))+exp((var_1+var_2)))\n",
      "Tokens: ['(', 'exp', '(', 'tan', '(', 'var_0', ')', ')', '+', 'exp', '(', '(', 'var_1', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_200.json\n",
      "Formula: (((var_2+C_0)+sin(var_1))*gaussian(gaussian(var_0)))\n",
      "Tokens: ['(', '(', '(', 'var_2', '+', 'C_0', ')', '+', 'sin', '(', 'var_1', ')', ')', '*', 'gaussian', '(', 'gaussian', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_6.json\n",
      "Formula: (sqrt((var_0*var_1))+sinh(pow_2(var_2)))\n",
      "Tokens: ['(', 'sqrt', '(', '(', 'var_0', '*', 'var_1', ')', ')', '+', 'sinh', '(', 'pow_2', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_580.json\n",
      "Formula: (sqrt(neg(var_0))+cos((var_1+var_2)))\n",
      "Tokens: ['(', 'sqrt', '(', 'neg', '(', 'var_0', ')', ')', '+', 'cos', '(', '(', 'var_1', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_47.json\n",
      "Formula: ((gaussian(var_2)+reverse(var_1))*log((var_1*var_0)))\n",
      "Tokens: ['(', '(', 'gaussian', '(', 'var_2', ')', '+', 'reverse', '(', 'var_1', ')', ')', '*', 'log', '(', '(', 'var_1', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_353.json\n",
      "Formula: (reverse(neg(var_1))*sqrt((var_2*var_0)))\n",
      "Tokens: ['(', 'reverse', '(', 'neg', '(', 'var_1', ')', ')', '*', 'sqrt', '(', '(', 'var_2', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_703.json\n",
      "Formula: (tanh((var_2+var_1))+reverse((var_2*var_0)))\n",
      "Tokens: ['(', 'tanh', '(', '(', 'var_2', '+', 'var_1', ')', ')', '+', 'reverse', '(', '(', 'var_2', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_216.json\n",
      "Formula: ((var_1+sin(var_1))*(tan(var_2)+var_0))\n",
      "Tokens: ['(', '(', 'var_1', '+', 'sin', '(', 'var_1', ')', ')', '*', '(', 'tan', '(', 'var_2', ')', '+', 'var_0', ')', ')']\n",
      "\n",
      "File: f_646.json\n",
      "Formula: ((sinh(var_0)*gaussian(var_1))+neg(sinh(var_2)))\n",
      "Tokens: ['(', '(', 'sinh', '(', 'var_0', ')', '*', 'gaussian', '(', 'var_1', ')', ')', '+', 'neg', '(', 'sinh', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_168.json\n",
      "Formula: (((var_2*C_0)*(var_0*var_1))+neg(reverse(var_2)))\n",
      "Tokens: ['(', '(', '(', 'var_2', '*', 'C_0', ')', '*', '(', 'var_0', '*', 'var_1', ')', ')', '+', 'neg', '(', 'reverse', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_492.json\n",
      "Formula: (sinh((var_0*var_2))+reverse(gaussian(var_1)))\n",
      "Tokens: ['(', 'sinh', '(', '(', 'var_0', '*', 'var_2', ')', ')', '+', 'reverse', '(', 'gaussian', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_538.json\n",
      "Formula: (((var_2+var_0)+sqrt(var_0))+log(neg(var_1)))\n",
      "Tokens: ['(', '(', '(', 'var_2', '+', 'var_0', ')', '+', 'sqrt', '(', 'var_0', ')', ')', '+', 'log', '(', 'neg', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_10.json\n",
      "Formula: (pow_2(cosh(var_2))+reverse((var_1*var_0)))\n",
      "Tokens: ['(', 'pow_2', '(', 'cosh', '(', 'var_2', ')', ')', '+', 'reverse', '(', '(', 'var_1', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_187.json\n",
      "Formula: ((gaussian(var_1)+(var_2*C_0))*log(pow_2(var_0)))\n",
      "Tokens: ['(', '(', 'gaussian', '(', 'var_1', ')', '+', '(', 'var_2', '*', 'C_0', ')', ')', '*', 'log', '(', 'pow_2', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_304.json\n",
      "Formula: (neg((var_2*var_1))+sqrt(gaussian(var_0)))\n",
      "Tokens: ['(', 'neg', '(', '(', 'var_2', '*', 'var_1', ')', ')', '+', 'sqrt', '(', 'gaussian', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_611.json\n",
      "Formula: ((tanh(var_2)+cos(var_0))*sinh(cosh(var_1)))\n",
      "Tokens: ['(', '(', 'tanh', '(', 'var_2', ')', '+', 'cos', '(', 'var_0', ')', ')', '*', 'sinh', '(', 'cosh', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_241.json\n",
      "Formula: ((sqrt(var_1)+(var_2+var_0))+reverse(C_0))\n",
      "Tokens: ['(', '(', 'sqrt', '(', 'var_1', ')', '+', '(', 'var_2', '+', 'var_0', ')', ')', '+', 'reverse', '(', 'C_0', ')', ')']\n",
      "\n",
      "File: f_305.json\n",
      "Formula: (sqrt((var_1*var_2))*tanh((var_0+var_0)))\n",
      "Tokens: ['(', 'sqrt', '(', '(', 'var_1', '*', 'var_2', ')', ')', '*', 'tanh', '(', '(', 'var_0', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_610.json\n",
      "Formula: (((var_0+C_0)*var_2)+((var_2+C_1)+(var_2+var_1)))\n",
      "Tokens: ['(', '(', '(', 'var_0', '+', 'C_0', ')', '*', 'var_2', ')', '+', '(', '(', 'var_2', '+', 'C_1', ')', '+', '(', 'var_2', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_240.json\n",
      "Formula: ((sqrt(var_0)*cosh(var_1))+gaussian(exp(var_2)))\n",
      "Tokens: ['(', '(', 'sqrt', '(', 'var_0', ')', '*', 'cosh', '(', 'var_1', ')', ')', '+', 'gaussian', '(', 'exp', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_169.json\n",
      "Formula: ((sqrt(var_0)+(var_2+C_0))+pow_2(sqrt(var_1)))\n",
      "Tokens: ['(', '(', 'sqrt', '(', 'var_0', ')', '+', '(', 'var_2', '+', 'C_0', ')', ')', '+', 'pow_2', '(', 'sqrt', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_493.json\n",
      "Formula: (((var_0+C_0)+tanh(var_1))*sinh(sqrt(var_2)))\n",
      "Tokens: ['(', '(', '(', 'var_0', '+', 'C_0', ')', '+', 'tanh', '(', 'var_1', ')', ')', '*', 'sinh', '(', 'sqrt', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_539.json\n",
      "Formula: (reverse(sin(var_0))*cos((var_2+var_1)))\n",
      "Tokens: ['(', 'reverse', '(', 'sin', '(', 'var_0', ')', ')', '*', 'cos', '(', '(', 'var_2', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_11.json\n",
      "Formula: (tan(reverse(var_2))+exp((var_0+var_1)))\n",
      "Tokens: ['(', 'tan', '(', 'reverse', '(', 'var_2', ')', ')', '+', 'exp', '(', '(', 'var_0', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_186.json\n",
      "Formula: sqrt(((var_0+var_2)+reverse(var_1)))\n",
      "Tokens: ['sqrt', '(', '(', '(', 'var_0', '+', 'var_2', ')', '+', 'reverse', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_352.json\n",
      "Formula: (tan((var_2+var_0))+pow_2((var_1+var_0)))\n",
      "Tokens: ['(', 'tan', '(', '(', 'var_2', '+', 'var_0', ')', ')', '+', 'pow_2', '(', '(', 'var_1', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_702.json\n",
      "Formula: ((gaussian(var_2)+neg(var_0))+reverse(sqrt(var_1)))\n",
      "Tokens: ['(', '(', 'gaussian', '(', 'var_2', ')', '+', 'neg', '(', 'var_0', ')', ')', '+', 'reverse', '(', 'sqrt', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_217.json\n",
      "Formula: (cos(neg(var_2))*sqrt((var_1+var_0)))\n",
      "Tokens: ['(', 'cos', '(', 'neg', '(', 'var_2', ')', ')', '*', 'sqrt', '(', '(', 'var_1', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_647.json\n",
      "Formula: (tan((var_1*var_2))+cos(gaussian(var_0)))\n",
      "Tokens: ['(', 'tan', '(', '(', 'var_1', '*', 'var_2', ')', ')', '+', 'cos', '(', 'gaussian', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_7.json\n",
      "Formula: (log((var_2*var_0))*cos((var_1*C_0)))\n",
      "Tokens: ['(', 'log', '(', '(', 'var_2', '*', 'var_0', ')', ')', '*', 'cos', '(', '(', 'var_1', '*', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_46.json\n",
      "Formula: (sin((var_1*var_0))*pow_2(sqrt(var_2)))\n",
      "Tokens: ['(', 'sin', '(', '(', 'var_1', '*', 'var_0', ')', ')', '*', 'pow_2', '(', 'sqrt', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_581.json\n",
      "Formula: (tan((var_2+var_1))+tanh((var_0+var_2)))\n",
      "Tokens: ['(', 'tan', '(', '(', 'var_2', '+', 'var_1', ')', ')', '+', 'tanh', '(', '(', 'var_0', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_714.json\n",
      "Formula: (tan((var_1*C_0))*neg((var_2+var_0)))\n",
      "Tokens: ['(', 'tan', '(', '(', 'var_1', '*', 'C_0', ')', ')', '*', 'neg', '(', '(', 'var_2', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_344.json\n",
      "Formula: (neg((var_2+var_1))+cosh(sin(var_0)))\n",
      "Tokens: ['(', 'neg', '(', '(', 'var_2', '+', 'var_1', ')', ')', '+', 'cosh', '(', 'sin', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_651.json\n",
      "Formula: (cosh(gaussian(var_0))*sqrt((var_1*var_2)))\n",
      "Tokens: ['(', 'cosh', '(', 'gaussian', '(', 'var_0', ')', ')', '*', 'sqrt', '(', '(', 'var_1', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_201.json\n",
      "Formula: ((pow_2(var_2)*cosh(var_1))+log((var_0*C_0)))\n",
      "Tokens: ['(', '(', 'pow_2', '(', 'var_2', ')', '*', 'cosh', '(', 'var_1', ')', ')', '+', 'log', '(', '(', 'var_0', '*', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_128.json\n",
      "Formula: (cosh((var_1*var_2))*log((var_0+var_2)))\n",
      "Tokens: ['(', 'cosh', '(', '(', 'var_1', '*', 'var_2', ')', ')', '*', 'log', '(', '(', 'var_0', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_578.json\n",
      "Formula: (tanh(exp(var_0))*sinh((var_1*var_2)))\n",
      "Tokens: ['(', 'tanh', '(', 'exp', '(', 'var_0', ')', ')', '*', 'sinh', '(', '(', 'var_1', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_50.json\n",
      "Formula: ((gaussian(var_2)*cosh(var_1))+sinh((var_1*var_0)))\n",
      "Tokens: ['(', '(', 'gaussian', '(', 'var_2', ')', '*', 'cosh', '(', 'var_1', ')', ')', '+', 'sinh', '(', '(', 'var_1', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_597.json\n",
      "Formula: (tan((var_2+var_0))*neg(var_1))\n",
      "Tokens: ['(', 'tan', '(', '(', 'var_2', '+', 'var_0', ')', ')', '*', 'neg', '(', 'var_1', ')', ')']\n",
      "\n",
      "File: f_313.json\n",
      "Formula: (tan((var_0+var_2))+cos((var_1+C_0)))\n",
      "Tokens: ['(', 'tan', '(', '(', 'var_0', '+', 'var_2', ')', ')', '+', 'cos', '(', '(', 'var_1', '+', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_743.json\n",
      "Formula: (tanh((var_0+var_2))*pow_2(tan(var_1)))\n",
      "Tokens: ['(', 'tanh', '(', '(', 'var_0', '+', 'var_2', ')', ')', '*', 'pow_2', '(', 'tan', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_256.json\n",
      "Formula: ((sqrt(var_2)+sqrt(var_1))+tanh(pow_2(var_0)))\n",
      "Tokens: ['(', '(', 'sqrt', '(', 'var_2', ')', '+', 'sqrt', '(', 'var_1', ')', ')', '+', 'tanh', '(', 'pow_2', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_606.json\n",
      "Formula: ((cos(var_2)+tanh(var_1))*neg(sqrt(var_0)))\n",
      "Tokens: ['(', '(', 'cos', '(', 'var_2', ')', '+', 'tanh', '(', 'var_1', ')', ')', '*', 'neg', '(', 'sqrt', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_485.json\n",
      "Formula: ((var_0+reverse(var_1))+(C_0*sqrt(var_2)))\n",
      "Tokens: ['(', '(', 'var_0', '+', 'reverse', '(', 'var_1', ')', ')', '+', '(', 'C_0', '*', 'sqrt', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_190.json\n",
      "Formula: ((tanh(var_1)+pow_2(var_0))+tan(var_2))\n",
      "Tokens: ['(', '(', 'tanh', '(', 'var_1', ')', '+', 'pow_2', '(', 'var_0', ')', ')', '+', 'tan', '(', 'var_2', ')', ')']\n",
      "\n",
      "File: f_387.json\n",
      "Formula: ((log(var_0)*pow_2(var_1))+sinh(tanh(var_2)))\n",
      "Tokens: ['(', '(', 'log', '(', 'var_0', ')', '*', 'pow_2', '(', 'var_1', ')', ')', '+', 'sinh', '(', 'tanh', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_368.json\n",
      "Formula: (neg((var_0*var_2))*sinh(tan(var_1)))\n",
      "Tokens: ['(', 'neg', '(', '(', 'var_0', '*', 'var_2', ')', ')', '*', 'sinh', '(', 'tan', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_692.json\n",
      "Formula: reverse(((var_2+var_1)+sin(var_0)))\n",
      "Tokens: ['reverse', '(', '(', '(', 'var_2', '+', 'var_1', ')', '+', 'sin', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_738.json\n",
      "Formula: (cos((var_2*var_0))+reverse(exp(var_1)))\n",
      "Tokens: ['(', 'cos', '(', '(', 'var_2', '*', 'var_0', ')', ')', '+', 'reverse', '(', 'exp', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_411.json\n",
      "Formula: (tanh((var_0*var_1))+cosh(gaussian(var_2)))\n",
      "Tokens: ['(', 'tanh', '(', '(', 'var_0', '*', 'var_1', ')', ')', '+', 'cosh', '(', 'gaussian', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_93.json\n",
      "Formula: cos((log(var_1)+(var_2+var_0)))\n",
      "Tokens: ['cos', '(', '(', 'log', '(', 'var_1', ')', '+', '(', 'var_2', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_554.json\n",
      "Formula: (log((var_0*var_1))*gaussian(tan(var_2)))\n",
      "Tokens: ['(', 'log', '(', '(', 'var_0', '*', 'var_1', ')', ')', '*', 'gaussian', '(', 'tan', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_104.json\n",
      "Formula: ((sin(var_1)+tanh(var_0))*sinh(sqrt(var_2)))\n",
      "Tokens: ['(', '(', 'sin', '(', 'var_1', ')', '+', 'tanh', '(', 'var_0', ')', ')', '*', 'sinh', '(', 'sqrt', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_295.json\n",
      "Formula: ((neg(var_2)*(var_1+var_0))+gaussian(sinh(var_1)))\n",
      "Tokens: ['(', '(', 'neg', '(', 'var_2', ')', '*', '(', 'var_1', '+', 'var_0', ')', ')', '+', 'gaussian', '(', 'sinh', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_446.json\n",
      "Formula: ((tanh(var_1)+log(var_2))*sqrt(sqrt(var_0)))\n",
      "Tokens: ['(', '(', 'tanh', '(', 'var_1', ')', '+', 'log', '(', 'var_2', ')', ')', '*', 'sqrt', '(', 'sqrt', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_153.json\n",
      "Formula: ((pow_2(var_1)*(var_0*var_0))+exp((var_2+var_2)))\n",
      "Tokens: ['(', '(', 'pow_2', '(', 'var_1', ')', '*', '(', 'var_0', '*', 'var_0', ')', ')', '+', 'exp', '(', '(', 'var_2', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_503.json\n",
      "Formula: (sqrt((var_2*var_1))+neg((var_0+C_0)))\n",
      "Tokens: ['(', 'sqrt', '(', '(', 'var_2', '*', 'var_1', ')', ')', '+', 'neg', '(', '(', 'var_0', '+', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_329.json\n",
      "Formula: (((var_2*C_0)+gaussian(var_1))+(neg(var_2)+tan(var_0)))\n",
      "Tokens: ['(', '(', '(', 'var_2', '*', 'C_0', ')', '+', 'gaussian', '(', 'var_1', ')', ')', '+', '(', 'neg', '(', 'var_2', ')', '+', 'tan', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_283.json\n",
      "Formula: ((var_0*(var_1*var_2))+exp((var_0*var_2)))\n",
      "Tokens: ['(', '(', 'var_0', '*', '(', 'var_1', '*', 'var_2', ')', ')', '+', 'exp', '(', '(', 'var_0', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_450.json\n",
      "Formula: (sqrt((var_2+var_0))*log((var_1*var_2)))\n",
      "Tokens: ['(', 'sqrt', '(', '(', 'var_2', '+', 'var_0', ')', ')', '*', 'log', '(', '(', 'var_1', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_515.json\n",
      "Formula: ((gaussian(var_0)*neg(var_2))+gaussian((var_1*C_0)))\n",
      "Tokens: ['(', '(', 'gaussian', '(', 'var_0', ')', '*', 'neg', '(', 'var_2', ')', ')', '+', 'gaussian', '(', '(', 'var_1', '*', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_145.json\n",
      "Formula: ((C_0*cosh(var_2))+pow_2((var_1+var_0)))\n",
      "Tokens: ['(', '(', 'C_0', '*', 'cosh', '(', 'var_2', ')', ')', '+', 'pow_2', '(', '(', 'var_1', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_391.json\n",
      "Formula: ((log(var_2)*(var_1+var_2))*tanh(cosh(var_0)))\n",
      "Tokens: ['(', '(', 'log', '(', 'var_2', ')', '*', '(', 'var_1', '+', 'var_2', ')', ')', '*', 'tanh', '(', 'cosh', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_684.json\n",
      "Formula: (cos(reverse(var_2))*exp((var_0*var_1)))\n",
      "Tokens: ['(', 'cos', '(', 'reverse', '(', 'var_2', ')', ')', '*', 'exp', '(', '(', 'var_0', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_407.json\n",
      "Formula: (tanh(sin(var_0))+tanh((var_1*var_2)))\n",
      "Tokens: ['(', 'tanh', '(', 'sin', '(', 'var_0', ')', ')', '+', 'tanh', '(', '(', 'var_1', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_112.json\n",
      "Formula: ((var_1*cos(var_2))*tanh(sqrt(var_0)))\n",
      "Tokens: ['(', '(', 'var_1', '*', 'cos', '(', 'var_2', ')', ')', '*', 'tanh', '(', 'sqrt', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_85.json\n",
      "Formula: (sinh((var_0*C_0))*sinh((var_2+var_1)))\n",
      "Tokens: ['(', 'sinh', '(', '(', 'var_0', '*', 'C_0', ')', ')', '*', 'sinh', '(', '(', 'var_2', '+', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_542.json\n",
      "Formula: (neg(cosh(var_1))+neg((var_2*var_0)))\n",
      "Tokens: ['(', 'neg', '(', 'cosh', '(', 'var_1', ')', ')', '+', 'neg', '(', '(', 'var_2', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_535.json\n",
      "Formula: (((var_2*var_1)*C_0)+tan((var_0*var_0)))\n",
      "Tokens: ['(', '(', '(', 'var_2', '*', 'var_1', ')', '*', 'C_0', ')', '+', 'tan', '(', '(', 'var_0', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_165.json\n",
      "Formula: ((pow_2(var_1)*cosh(var_0))+log(cos(var_2)))\n",
      "Tokens: ['(', '(', 'pow_2', '(', 'var_1', ')', '*', 'cosh', '(', 'var_0', ')', ')', '+', 'log', '(', 'cos', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_470.json\n",
      "Formula: (tan((var_1*var_2))+sin((var_0+C_0)))\n",
      "Tokens: ['(', 'tan', '(', '(', 'var_1', '*', 'var_2', ')', ')', '+', 'sin', '(', '(', 'var_0', '+', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_309.json\n",
      "Formula: (tanh((var_2*var_0))*reverse(pow_2(var_1)))\n",
      "Tokens: ['(', 'tanh', '(', '(', 'var_2', '*', 'var_0', ')', ')', '*', 'reverse', '(', 'pow_2', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_132.json\n",
      "Formula: (reverse(sin(var_2))+pow_2((var_1+var_0)))\n",
      "Tokens: ['(', 'reverse', '(', 'sin', '(', 'var_2', ')', ')', '+', 'pow_2', '(', '(', 'var_1', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_562.json\n",
      "Formula: (sinh(neg(var_1))+gaussian((var_2+var_0)))\n",
      "Tokens: ['(', 'sinh', '(', 'neg', '(', 'var_1', ')', ')', '+', 'gaussian', '(', '(', 'var_2', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_427.json\n",
      "Formula: (log((var_2+var_2))*log((var_1*var_0)))\n",
      "Tokens: ['(', 'log', '(', '(', 'var_2', '+', 'var_2', ')', ')', '*', 'log', '(', '(', 'var_1', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_574.json\n",
      "Formula: ((pow_2(var_0)*tan(var_1))+neg(reverse(var_2)))\n",
      "Tokens: ['(', '(', 'pow_2', '(', 'var_0', ')', '*', 'tan', '(', 'var_1', ')', ')', '+', 'neg', '(', 'reverse', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_124.json\n",
      "Formula: ((cosh(var_2)+tan(var_1))+sqrt(tan(var_0)))\n",
      "Tokens: ['(', '(', 'cosh', '(', 'var_2', ')', '+', 'tan', '(', 'var_1', ')', ')', '+', 'sqrt', '(', 'tan', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_431.json\n",
      "Formula: (tanh((var_0+var_1))+neg((var_1*var_2)))\n",
      "Tokens: ['(', 'tanh', '(', '(', 'var_0', '+', 'var_1', ')', ')', '+', 'neg', '(', '(', 'var_1', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_348.json\n",
      "Formula: (gaussian((var_2*var_1))*cosh(neg(var_0)))\n",
      "Tokens: ['(', 'gaussian', '(', '(', 'var_2', '*', 'var_1', ')', ')', '*', 'cosh', '(', 'neg', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_718.json\n",
      "Formula: (reverse(cosh(var_0))+gaussian((var_1+var_2)))\n",
      "Tokens: ['(', 'reverse', '(', 'cosh', '(', 'var_0', ')', ')', '+', 'gaussian', '(', '(', 'var_1', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_173.json\n",
      "Formula: ((cos(var_0)+sqrt(var_2))+sin(sqrt(var_1)))\n",
      "Tokens: ['(', '(', 'cos', '(', 'var_0', ')', '+', 'sqrt', '(', 'var_2', ')', ')', '+', 'sin', '(', 'sqrt', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_489.json\n",
      "Formula: ((neg(var_1)*(var_0*var_0))+neg(tan(var_2)))\n",
      "Tokens: ['(', '(', 'neg', '(', 'var_1', ')', '*', '(', 'var_0', '*', 'var_0', ')', ')', '+', 'neg', '(', 'tan', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_523.json\n",
      "Formula: ((reverse(var_1)*reverse(var_1))*tan((var_2+var_0)))\n",
      "Tokens: ['(', '(', 'reverse', '(', 'var_1', ')', '*', 'reverse', '(', 'var_1', ')', ')', '*', 'tan', '(', '(', 'var_2', '+', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_466.json\n",
      "Formula: (log((var_1+var_0))+pow_2(neg(var_2)))\n",
      "Tokens: ['(', 'log', '(', '(', 'var_1', '+', 'var_0', ')', ')', '+', 'pow_2', '(', 'neg', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_70.json\n",
      "Formula: ((tanh(var_1)*sqrt(var_0))+sin(neg(var_2)))\n",
      "Tokens: ['(', '(', 'tanh', '(', 'var_1', ')', '*', 'sqrt', '(', 'var_0', ')', ')', '+', 'sin', '(', 'neg', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_108.json\n",
      "Formula: ((log(var_0)*sqrt(var_1))+sin(pow_2(var_2)))\n",
      "Tokens: ['(', '(', 'log', '(', 'var_0', ')', '*', 'sqrt', '(', 'var_1', ')', ')', '+', 'sin', '(', 'pow_2', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_558.json\n",
      "Formula: ((log(var_2)+cos(var_0))*gaussian(sqrt(var_1)))\n",
      "Tokens: ['(', '(', 'log', '(', 'var_2', ')', '+', 'cos', '(', 'var_0', ')', ')', '*', 'gaussian', '(', 'sqrt', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_671.json\n",
      "Formula: (cosh((var_0*var_1))*reverse(cos(var_2)))\n",
      "Tokens: ['(', 'cosh', '(', '(', 'var_0', '*', 'var_1', ')', ')', '*', 'reverse', '(', 'cos', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_221.json\n",
      "Formula: ((cosh(var_2)*cosh(var_0))+(exp(var_1)+pow_2(var_1)))\n",
      "Tokens: ['(', '(', 'cosh', '(', 'var_2', ')', '*', 'cosh', '(', 'var_0', ')', ')', '+', '(', 'exp', '(', 'var_1', ')', '+', 'pow_2', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_734.json\n",
      "Formula: ((neg(var_0)*exp(var_2))*tan((var_1*var_1)))\n",
      "Tokens: ['(', '(', 'neg', '(', 'var_0', ')', '*', 'exp', '(', 'var_2', ')', ')', '*', 'tan', '(', '(', 'var_1', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_364.json\n",
      "Formula: (reverse(tanh(var_1))+log((var_2*var_0)))\n",
      "Tokens: ['(', 'reverse', '(', 'tanh', '(', 'var_1', ')', ')', '+', 'log', '(', '(', 'var_2', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_27.json\n",
      "Formula: ((pow_2(var_0)+(var_0+var_2))*cosh(pow_2(var_1)))\n",
      "Tokens: ['(', '(', 'pow_2', '(', 'var_0', ')', '+', '(', 'var_0', '+', 'var_2', ')', ')', '*', 'cosh', '(', 'pow_2', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_276.json\n",
      "Formula: ((tan(var_1)*(var_2+C_0))*(sin(var_0)+(var_0*var_1)))\n",
      "Tokens: ['(', '(', 'tan', '(', 'var_1', ')', '*', '(', 'var_2', '+', 'C_0', ')', ')', '*', '(', 'sin', '(', 'var_0', ')', '+', '(', 'var_0', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_626.json\n",
      "Formula: ((tanh(var_1)*var_0)*pow_2(log(var_2)))\n",
      "Tokens: ['(', '(', 'tanh', '(', 'var_1', ')', '*', 'var_0', ')', '*', 'pow_2', '(', 'log', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_333.json\n",
      "Formula: (sqrt((var_1+var_0))*reverse(neg(var_2)))\n",
      "Tokens: ['(', 'sqrt', '(', '(', 'var_1', '+', 'var_0', ')', ')', '*', 'reverse', '(', 'neg', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_299.json\n",
      "Formula: ((sin(var_0)*tan(var_1))*reverse(tanh(var_2)))\n",
      "Tokens: ['(', '(', 'sin', '(', 'var_0', ')', '*', 'tan', '(', 'var_1', ')', ')', '*', 'reverse', '(', 'tanh', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_31.json\n",
      "Formula: gaussian((reverse(var_1)+(var_0*var_2)))\n",
      "Tokens: ['gaussian', '(', '(', 'reverse', '(', 'var_1', ')', '+', '(', 'var_0', '*', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_149.json\n",
      "Formula: ((tan(var_1)*tan(var_2))+reverse(cosh(var_0)))\n",
      "Tokens: ['(', '(', 'tan', '(', 'var_1', ')', '*', 'tan', '(', 'var_2', ')', ')', '+', 'reverse', '(', 'cosh', '(', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_519.json\n",
      "Formula: (sinh(reverse(var_2))+sin((var_0*var_1)))\n",
      "Tokens: ['(', 'sinh', '(', 'reverse', '(', 'var_2', ')', ')', '+', 'sin', '(', '(', 'var_0', '*', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_630.json\n",
      "Formula: (sqrt((var_0*var_2))+sinh(exp(var_1)))\n",
      "Tokens: ['(', 'sqrt', '(', '(', 'var_0', '*', 'var_2', ')', ')', '+', 'sinh', '(', 'exp', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_260.json\n",
      "Formula: (sin((var_0*var_1))+gaussian(sinh(var_2)))\n",
      "Tokens: ['(', 'sin', '(', '(', 'var_0', '*', 'var_1', ')', ')', '+', 'gaussian', '(', 'sinh', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_325.json\n",
      "Formula: (cosh(tanh(var_1))+sinh((var_2*var_0)))\n",
      "Tokens: ['(', 'cosh', '(', 'tanh', '(', 'var_1', ')', ')', '+', 'sinh', '(', '(', 'var_2', '*', 'var_0', ')', ')', ')']\n",
      "\n",
      "File: f_66.json\n",
      "Formula: ((sqrt(var_1)+(var_0*C_0))+sqrt(sinh(var_2)))\n",
      "Tokens: ['(', '(', 'sqrt', '(', 'var_1', ')', '+', '(', 'var_0', '*', 'C_0', ')', ')', '+', 'sqrt', '(', 'sinh', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_89.json\n",
      "Formula: (gaussian((var_0+var_1))*exp((var_2*C_0)))\n",
      "Tokens: ['(', 'gaussian', '(', '(', 'var_0', '+', 'var_1', ')', ')', '*', 'exp', '(', '(', 'var_2', '*', 'C_0', ')', ')', ')']\n",
      "\n",
      "File: f_237.json\n",
      "Formula: ((sqrt(var_2)*tanh(var_0))*pow_2(tanh(var_1)))\n",
      "Tokens: ['(', '(', 'sqrt', '(', 'var_2', ')', '*', 'tanh', '(', 'var_0', ')', ')', '*', 'pow_2', '(', 'tanh', '(', 'var_1', ')', ')', ')']\n",
      "\n",
      "File: f_667.json\n",
      "Formula: ((sqrt(var_0)+(var_1*C_0))+reverse(cosh(var_2)))\n",
      "Tokens: ['(', '(', 'sqrt', '(', 'var_0', ')', '+', '(', 'var_1', '*', 'C_0', ')', ')', '+', 'reverse', '(', 'cosh', '(', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_372.json\n",
      "Formula: (log((var_2+var_1))*sin(var_0))\n",
      "Tokens: ['(', 'log', '(', '(', 'var_2', '+', 'var_1', ')', ')', '*', 'sin', '(', 'var_0', ')', ')']\n",
      "\n",
      "File: f_688.json\n",
      "Formula: (((var_1*var_2)*sin(var_2))+cosh((var_0+var_2)))\n",
      "Tokens: ['(', '(', '(', 'var_1', '*', 'var_2', ')', '*', 'sin', '(', 'var_2', ')', ')', '+', 'cosh', '(', '(', 'var_0', '+', 'var_2', ')', ')', ')']\n",
      "\n",
      "File: f_722.json\n",
      "Formula: (pow_2(exp(var_2))+sin((var_0*var_1)))\n",
      "Tokens: ['(', 'pow_2', '(', 'exp', '(', 'var_2', ')', ')', '+', 'sin', '(', '(', 'var_0', '*', 'var_1', ')', ')', ')']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Define the folder path containing the JSON files\n",
    "folder_path = \"data_symbolic_regression/train\"\n",
    "\n",
    "# Function to tokenize a formula\n",
    "def tokenize_formula(formula):\n",
    "    # Define a regex pattern to extract tokens (identifiers, operators, parentheses, etc.)\n",
    "    token_pattern = r\"[a-zA-Z_][a-zA-Z0-9_]*|[()+\\-*/]|\\d+\\.?\\d*\"\n",
    "    tokens = re.findall(token_pattern, formula)\n",
    "    return tokens\n",
    "\n",
    "# Iterate over all files in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\".json\") and not file_name.startswith('properties'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        # Open and read the JSON file\n",
    "        with open(file_path, \"r\") as file:\n",
    "            data = json.load(file)\n",
    "            \n",
    "            # Extract the human-readable formula\n",
    "            formula_human_readable = data.get(\"formula_human_readable\", \"\")\n",
    "            \n",
    "            if formula_human_readable:\n",
    "                # Tokenize the formula\n",
    "                tokens = tokenize_formula(formula_human_readable)\n",
    "                \n",
    "                # Print or store the tokens for further analysis\n",
    "                print(f\"File: {file_name}\")\n",
    "                print(f\"Formula: {formula_human_readable}\")\n",
    "                print(f\"Tokens: {tokens}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tokens: tensor([[17, 74, 10, 89, 27, 34, 34, 37, 47, 54],\n",
      "        [79,  9,  7, 85, 41, 22, 73, 79, 26, 36],\n",
      "        [61, 12, 62, 87, 93,  3, 22, 25,  1, 44],\n",
      "        [28, 70, 23, 27, 37, 22,  4, 26, 66, 24]])\n",
      "Noisy Tokens (probabilities): tensor([[[0.0095, 0.0100, 0.0090,  ..., 0.0095, 0.0092, 0.0088],\n",
      "         [0.0105, 0.0094, 0.0102,  ..., 0.0089, 0.0104, 0.0115],\n",
      "         [0.0087, 0.0100, 0.0099,  ..., 0.0105, 0.0095, 0.0097],\n",
      "         ...,\n",
      "         [0.0115, 0.0097, 0.0091,  ..., 0.0106, 0.0098, 0.0107],\n",
      "         [0.0087, 0.0112, 0.0086,  ..., 0.0109, 0.0098, 0.0094],\n",
      "         [0.0093, 0.0114, 0.0090,  ..., 0.0094, 0.0094, 0.0102]],\n",
      "\n",
      "        [[0.0093, 0.0087, 0.0092,  ..., 0.0099, 0.0095, 0.0095],\n",
      "         [0.0096, 0.0100, 0.0107,  ..., 0.0090, 0.0101, 0.0102],\n",
      "         [0.0099, 0.0106, 0.0098,  ..., 0.0115, 0.0097, 0.0097],\n",
      "         ...,\n",
      "         [0.0089, 0.0099, 0.0096,  ..., 0.0098, 0.0103, 0.0111],\n",
      "         [0.0109, 0.0101, 0.0084,  ..., 0.0099, 0.0113, 0.0095],\n",
      "         [0.0109, 0.0104, 0.0097,  ..., 0.0085, 0.0093, 0.0118]],\n",
      "\n",
      "        [[0.0091, 0.0116, 0.0096,  ..., 0.0109, 0.0108, 0.0107],\n",
      "         [0.0082, 0.0109, 0.0090,  ..., 0.0085, 0.0101, 0.0095],\n",
      "         [0.0104, 0.0095, 0.0079,  ..., 0.0076, 0.0094, 0.0084],\n",
      "         ...,\n",
      "         [0.0096, 0.0090, 0.0102,  ..., 0.0098, 0.0099, 0.0093],\n",
      "         [0.0110, 0.0254, 0.0082,  ..., 0.0079, 0.0098, 0.0108],\n",
      "         [0.0094, 0.0103, 0.0106,  ..., 0.0092, 0.0104, 0.0094]],\n",
      "\n",
      "        [[0.0099, 0.0107, 0.0099,  ..., 0.0085, 0.0091, 0.0103],\n",
      "         [0.0098, 0.0088, 0.0106,  ..., 0.0089, 0.0114, 0.0095],\n",
      "         [0.0111, 0.0090, 0.0099,  ..., 0.0092, 0.0092, 0.0092],\n",
      "         ...,\n",
      "         [0.0104, 0.0113, 0.0090,  ..., 0.0104, 0.0099, 0.0089],\n",
      "         [0.0097, 0.0117, 0.0090,  ..., 0.0102, 0.0092, 0.0102],\n",
      "         [0.0095, 0.0092, 0.0096,  ..., 0.0098, 0.0095, 0.0109]]])\n",
      "Sampled Tokens: tensor([[17, 74, 10, 89, 27, 34, 34, 37, 47, 54],\n",
      "        [79,  9,  7, 85, 41, 22, 73, 79, 26, 36],\n",
      "        [61, 12, 62, 87, 93,  3, 22, 25,  1, 44],\n",
      "        [28, 70, 23, 27, 37, 22,  4, 26, 66, 24]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class TextDiffusionModel:\n",
    "    def __init__(self, vocab_size, seq_len, device=\"cpu\"):\n",
    "        \"\"\"\n",
    "        Initialize the text diffusion model.\n",
    "\n",
    "        Parameters:\n",
    "        - vocab_size: Size of the vocabulary (number of unique tokens).\n",
    "        - seq_len: Length of the token sequence.\n",
    "        - device: Device to use (\"cpu\" or \"cuda\").\n",
    "        \"\"\"\n",
    "        self.vocab_size = vocab_size\n",
    "        self.seq_len = seq_len\n",
    "        self.device = device\n",
    "        self.noise_schedule = torch.linspace(0.01, 0.1, steps=1000).to(device)  # Noise variance per timestep\n",
    "\n",
    "    def add_noise(self, tokens, t):\n",
    "        \"\"\"\n",
    "        Add noise to a sequence of tokens based on timestep t.\n",
    "\n",
    "        Parameters:\n",
    "        - tokens: A tensor of token indices with shape (batch_size, seq_len).\n",
    "        - t: A tensor of timesteps with shape (batch_size,).\n",
    "\n",
    "        Returns:\n",
    "        - noisy_tokens: The tokens with added noise.\n",
    "        - noise: The noise added to the tokens.\n",
    "        \"\"\"\n",
    "        noise_std = self.noise_schedule[t].view(-1, 1, 1)  # Shape: (batch_size, 1, 1)\n",
    "\n",
    "        # Convert tokens to one-hot vectors\n",
    "        one_hot = F.one_hot(tokens, num_classes=self.vocab_size).float()\n",
    "        \n",
    "        # Add Gaussian noise to the one-hot vectors\n",
    "        noise = torch.randn_like(one_hot) * noise_std\n",
    "        noisy_one_hot = one_hot + noise\n",
    "\n",
    "        # Compute softmax to normalize the noisy one-hot vectors\n",
    "        noisy_tokens = F.softmax(noisy_one_hot, dim=-1)\n",
    "        return noisy_tokens, noise\n",
    "\n",
    "    def sample_from_noisy_tokens(self, noisy_tokens):\n",
    "        \"\"\"\n",
    "        Sample discrete tokens from the noisy token distribution.\n",
    "\n",
    "        Parameters:\n",
    "        - noisy_tokens: A tensor of noisy token distributions with shape (batch_size, seq_len, vocab_size).\n",
    "\n",
    "        Returns:\n",
    "        - sampled_tokens: A tensor of sampled token indices with shape (batch_size, seq_len).\n",
    "        \"\"\"\n",
    "        sampled_tokens = torch.argmax(noisy_tokens, dim=-1)\n",
    "        return sampled_tokens\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Hyperparameters\n",
    "    vocab_size = 100  # Example vocabulary size\n",
    "    seq_len = 10  # Example sequence length\n",
    "    batch_size = 4  # Example batch size\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Initialize the model\n",
    "    model = TextDiffusionModel(vocab_size, seq_len, device=device)\n",
    "\n",
    "    # Generate a batch of random tokens\n",
    "    tokens = torch.randint(0, vocab_size, (batch_size, seq_len), device=device)\n",
    "\n",
    "    # Choose random timesteps for each batch\n",
    "    t = torch.randint(0, 1000, (batch_size,), device=device)\n",
    "\n",
    "    # Add noise to the tokens\n",
    "    noisy_tokens, noise = model.add_noise(tokens, t)\n",
    "\n",
    "    # Sample from noisy tokens\n",
    "    sampled_tokens = model.sample_from_noisy_tokens(noisy_tokens)\n",
    "\n",
    "    # Print results\n",
    "    print(\"Original Tokens:\", tokens)\n",
    "    print(\"Noisy Tokens (probabilities):\", noisy_tokens)\n",
    "    print(\"Sampled Tokens:\", sampled_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([747, 4, 100])\n",
      "Output shape: torch.Size([747, 128])\n",
      "Original Tokens shape: torch.Size([747, 24])\n",
      "Noisy Tokens (probabilities) shape: torch.Size([747, 24, 23])\n",
      "Sampled Tokens shape: torch.Size([747, 24])\n",
      "Epoch [1/1000], Loss: 0.0465, Val Loss: 0.0438\n",
      "Epoch [2/1000], Loss: 0.0336, Val Loss: 0.0343\n",
      "Epoch [3/1000], Loss: 0.0276, Val Loss: 0.0304\n",
      "Epoch [4/1000], Loss: 0.0248, Val Loss: 0.0280\n",
      "Epoch [5/1000], Loss: 0.0232, Val Loss: 0.0266\n",
      "Epoch [6/1000], Loss: 0.0223, Val Loss: 0.0255\n",
      "Epoch [7/1000], Loss: 0.0212, Val Loss: 0.0247\n",
      "Epoch [8/1000], Loss: 0.0209, Val Loss: 0.0243\n",
      "Epoch [9/1000], Loss: 0.0203, Val Loss: 0.0231\n",
      "Epoch [10/1000], Loss: 0.0202, Val Loss: 0.0233\n",
      "Epoch [11/1000], Loss: 0.0195, Val Loss: 0.0227\n",
      "Epoch [12/1000], Loss: 0.0193, Val Loss: 0.0224\n",
      "Epoch [13/1000], Loss: 0.0191, Val Loss: 0.0223\n",
      "Epoch [14/1000], Loss: 0.0187, Val Loss: 0.0222\n",
      "Epoch [15/1000], Loss: 0.0185, Val Loss: 0.0216\n",
      "Epoch [16/1000], Loss: 0.0182, Val Loss: 0.0213\n",
      "Epoch [17/1000], Loss: 0.0179, Val Loss: 0.0209\n",
      "Epoch [18/1000], Loss: 0.0178, Val Loss: 0.0211\n",
      "Epoch [19/1000], Loss: 0.0175, Val Loss: 0.0209\n",
      "Epoch [20/1000], Loss: 0.0175, Val Loss: 0.0207\n",
      "Epoch [21/1000], Loss: 0.0175, Val Loss: 0.0207\n",
      "Epoch [22/1000], Loss: 0.0174, Val Loss: 0.0206\n",
      "Epoch [23/1000], Loss: 0.0174, Val Loss: 0.0207\n",
      "Epoch [24/1000], Loss: 0.0174, Val Loss: 0.0206\n",
      "Epoch [25/1000], Loss: 0.0173, Val Loss: 0.0205\n",
      "Epoch [26/1000], Loss: 0.0173, Val Loss: 0.0205\n",
      "Epoch [27/1000], Loss: 0.0173, Val Loss: 0.0205\n",
      "Epoch [28/1000], Loss: 0.0173, Val Loss: 0.0205\n",
      "Epoch [29/1000], Loss: 0.0173, Val Loss: 0.0205\n",
      "Epoch [30/1000], Loss: 0.0173, Val Loss: 0.0204\n",
      "Epoch [31/1000], Loss: 0.0173, Val Loss: 0.0205\n",
      "Epoch [32/1000], Loss: 0.0173, Val Loss: 0.0204\n",
      "Epoch [33/1000], Loss: 0.0173, Val Loss: 0.0204\n",
      "Epoch [34/1000], Loss: 0.0172, Val Loss: 0.0205\n",
      "Epoch [35/1000], Loss: 0.0172, Val Loss: 0.0204\n",
      "Epoch [36/1000], Loss: 0.0172, Val Loss: 0.0204\n",
      "Epoch [37/1000], Loss: 0.0172, Val Loss: 0.0204\n",
      "Epoch [38/1000], Loss: 0.0172, Val Loss: 0.0204\n",
      "Epoch [39/1000], Loss: 0.0172, Val Loss: 0.0204\n",
      "Epoch [40/1000], Loss: 0.0172, Val Loss: 0.0204\n",
      "Epoch [41/1000], Loss: 0.0172, Val Loss: 0.0204\n",
      "Epoch [42/1000], Loss: 0.0172, Val Loss: 0.0204\n",
      "Epoch [43/1000], Loss: 0.0172, Val Loss: 0.0204\n",
      "Epoch [44/1000], Loss: 0.0172, Val Loss: 0.0204\n",
      "Epoch [45/1000], Loss: 0.0172, Val Loss: 0.0204\n",
      "Epoch [46/1000], Loss: 0.0172, Val Loss: 0.0204\n",
      "Epoch [47/1000], Loss: 0.0172, Val Loss: 0.0204\n",
      "Epoch [48/1000], Loss: 0.0172, Val Loss: 0.0203\n",
      "Epoch [49/1000], Loss: 0.0172, Val Loss: 0.0203\n",
      "Epoch [50/1000], Loss: 0.0171, Val Loss: 0.0204\n",
      "Epoch [51/1000], Loss: 0.0172, Val Loss: 0.0204\n",
      "Epoch [52/1000], Loss: 0.0171, Val Loss: 0.0203\n",
      "Epoch [53/1000], Loss: 0.0171, Val Loss: 0.0203\n",
      "Epoch [54/1000], Loss: 0.0171, Val Loss: 0.0203\n",
      "Epoch [55/1000], Loss: 0.0171, Val Loss: 0.0203\n",
      "Epoch [56/1000], Loss: 0.0171, Val Loss: 0.0204\n",
      "Epoch [57/1000], Loss: 0.0171, Val Loss: 0.0203\n",
      "Epoch [58/1000], Loss: 0.0171, Val Loss: 0.0202\n",
      "Epoch [59/1000], Loss: 0.0171, Val Loss: 0.0203\n",
      "Epoch [60/1000], Loss: 0.0171, Val Loss: 0.0203\n",
      "Epoch [61/1000], Loss: 0.0171, Val Loss: 0.0203\n",
      "Epoch [62/1000], Loss: 0.0171, Val Loss: 0.0203\n",
      "Epoch [63/1000], Loss: 0.0171, Val Loss: 0.0202\n",
      "Epoch [64/1000], Loss: 0.0171, Val Loss: 0.0203\n",
      "Epoch [65/1000], Loss: 0.0171, Val Loss: 0.0202\n",
      "Epoch [66/1000], Loss: 0.0170, Val Loss: 0.0202\n",
      "Epoch [67/1000], Loss: 0.0171, Val Loss: 0.0202\n",
      "Epoch [68/1000], Loss: 0.0170, Val Loss: 0.0202\n",
      "Epoch [69/1000], Loss: 0.0170, Val Loss: 0.0202\n",
      "Epoch [70/1000], Loss: 0.0170, Val Loss: 0.0202\n",
      "Epoch [71/1000], Loss: 0.0170, Val Loss: 0.0202\n",
      "Epoch [72/1000], Loss: 0.0170, Val Loss: 0.0202\n",
      "Epoch [73/1000], Loss: 0.0170, Val Loss: 0.0203\n",
      "Epoch [74/1000], Loss: 0.0170, Val Loss: 0.0202\n",
      "Epoch [75/1000], Loss: 0.0170, Val Loss: 0.0202\n",
      "Epoch [76/1000], Loss: 0.0169, Val Loss: 0.0202\n",
      "Epoch [77/1000], Loss: 0.0169, Val Loss: 0.0201\n",
      "Epoch [78/1000], Loss: 0.0169, Val Loss: 0.0200\n",
      "Epoch [79/1000], Loss: 0.0169, Val Loss: 0.0202\n",
      "Epoch [80/1000], Loss: 0.0169, Val Loss: 0.0200\n",
      "Epoch [81/1000], Loss: 0.0169, Val Loss: 0.0201\n",
      "Epoch [82/1000], Loss: 0.0169, Val Loss: 0.0201\n",
      "Epoch [83/1000], Loss: 0.0169, Val Loss: 0.0201\n",
      "Epoch [84/1000], Loss: 0.0168, Val Loss: 0.0200\n",
      "Epoch [85/1000], Loss: 0.0168, Val Loss: 0.0200\n",
      "Epoch [86/1000], Loss: 0.0168, Val Loss: 0.0201\n",
      "Epoch [87/1000], Loss: 0.0168, Val Loss: 0.0201\n",
      "Epoch [88/1000], Loss: 0.0168, Val Loss: 0.0200\n",
      "Epoch [89/1000], Loss: 0.0167, Val Loss: 0.0199\n",
      "Epoch [90/1000], Loss: 0.0167, Val Loss: 0.0199\n",
      "Epoch [91/1000], Loss: 0.0167, Val Loss: 0.0200\n",
      "Epoch [92/1000], Loss: 0.0167, Val Loss: 0.0198\n",
      "Epoch [93/1000], Loss: 0.0166, Val Loss: 0.0198\n",
      "Epoch [94/1000], Loss: 0.0166, Val Loss: 0.0198\n",
      "Epoch [95/1000], Loss: 0.0166, Val Loss: 0.0198\n",
      "Epoch [96/1000], Loss: 0.0166, Val Loss: 0.0197\n",
      "Epoch [97/1000], Loss: 0.0166, Val Loss: 0.0198\n",
      "Epoch [98/1000], Loss: 0.0165, Val Loss: 0.0197\n",
      "Epoch [99/1000], Loss: 0.0165, Val Loss: 0.0197\n",
      "Epoch [100/1000], Loss: 0.0164, Val Loss: 0.0196\n",
      "Epoch [101/1000], Loss: 0.0164, Val Loss: 0.0195\n",
      "Epoch [102/1000], Loss: 0.0163, Val Loss: 0.0195\n",
      "Epoch [103/1000], Loss: 0.0163, Val Loss: 0.0195\n",
      "Epoch [104/1000], Loss: 0.0162, Val Loss: 0.0195\n",
      "Epoch [105/1000], Loss: 0.0162, Val Loss: 0.0196\n",
      "Epoch [106/1000], Loss: 0.0162, Val Loss: 0.0195\n",
      "Epoch [107/1000], Loss: 0.0161, Val Loss: 0.0195\n",
      "Epoch [108/1000], Loss: 0.0162, Val Loss: 0.0191\n",
      "Epoch [109/1000], Loss: 0.0160, Val Loss: 0.0193\n",
      "Epoch [110/1000], Loss: 0.0159, Val Loss: 0.0192\n",
      "Epoch [111/1000], Loss: 0.0159, Val Loss: 0.0191\n",
      "Epoch [112/1000], Loss: 0.0159, Val Loss: 0.0194\n",
      "Epoch [113/1000], Loss: 0.0160, Val Loss: 0.0190\n",
      "Epoch [114/1000], Loss: 0.0158, Val Loss: 0.0191\n",
      "Epoch [115/1000], Loss: 0.0158, Val Loss: 0.0192\n",
      "Epoch [116/1000], Loss: 0.0157, Val Loss: 0.0188\n",
      "Epoch [117/1000], Loss: 0.0156, Val Loss: 0.0187\n",
      "Epoch [118/1000], Loss: 0.0155, Val Loss: 0.0185\n",
      "Epoch [119/1000], Loss: 0.0154, Val Loss: 0.0186\n",
      "Epoch [120/1000], Loss: 0.0154, Val Loss: 0.0186\n",
      "Epoch [121/1000], Loss: 0.0153, Val Loss: 0.0185\n",
      "Epoch [122/1000], Loss: 0.0153, Val Loss: 0.0182\n",
      "Epoch [123/1000], Loss: 0.0153, Val Loss: 0.0183\n",
      "Epoch [124/1000], Loss: 0.0152, Val Loss: 0.0182\n",
      "Epoch [125/1000], Loss: 0.0151, Val Loss: 0.0181\n",
      "Epoch [126/1000], Loss: 0.0150, Val Loss: 0.0179\n",
      "Epoch [127/1000], Loss: 0.0149, Val Loss: 0.0179\n",
      "Epoch [128/1000], Loss: 0.0148, Val Loss: 0.0177\n",
      "Epoch [129/1000], Loss: 0.0147, Val Loss: 0.0177\n",
      "Epoch [130/1000], Loss: 0.0146, Val Loss: 0.0176\n",
      "Epoch [131/1000], Loss: 0.0146, Val Loss: 0.0175\n",
      "Epoch [132/1000], Loss: 0.0145, Val Loss: 0.0174\n",
      "Epoch [133/1000], Loss: 0.0144, Val Loss: 0.0174\n",
      "Epoch [134/1000], Loss: 0.0143, Val Loss: 0.0172\n",
      "Epoch [135/1000], Loss: 0.0143, Val Loss: 0.0171\n",
      "Epoch [136/1000], Loss: 0.0142, Val Loss: 0.0171\n",
      "Epoch [137/1000], Loss: 0.0142, Val Loss: 0.0170\n",
      "Epoch [138/1000], Loss: 0.0141, Val Loss: 0.0169\n",
      "Epoch [139/1000], Loss: 0.0140, Val Loss: 0.0168\n",
      "Epoch [140/1000], Loss: 0.0139, Val Loss: 0.0167\n",
      "Epoch [141/1000], Loss: 0.0139, Val Loss: 0.0167\n",
      "Epoch [142/1000], Loss: 0.0138, Val Loss: 0.0166\n",
      "Epoch [143/1000], Loss: 0.0138, Val Loss: 0.0166\n",
      "Epoch [144/1000], Loss: 0.0137, Val Loss: 0.0165\n",
      "Epoch [145/1000], Loss: 0.0136, Val Loss: 0.0165\n",
      "Epoch [146/1000], Loss: 0.0136, Val Loss: 0.0164\n",
      "Epoch [147/1000], Loss: 0.0135, Val Loss: 0.0163\n",
      "Epoch [148/1000], Loss: 0.0135, Val Loss: 0.0163\n",
      "Epoch [149/1000], Loss: 0.0134, Val Loss: 0.0161\n",
      "Epoch [150/1000], Loss: 0.0134, Val Loss: 0.0161\n",
      "Epoch [151/1000], Loss: 0.0133, Val Loss: 0.0160\n",
      "Epoch [152/1000], Loss: 0.0133, Val Loss: 0.0160\n",
      "Epoch [153/1000], Loss: 0.0132, Val Loss: 0.0160\n",
      "Epoch [154/1000], Loss: 0.0132, Val Loss: 0.0159\n",
      "Epoch [155/1000], Loss: 0.0132, Val Loss: 0.0159\n",
      "Epoch [156/1000], Loss: 0.0131, Val Loss: 0.0158\n",
      "Epoch [157/1000], Loss: 0.0131, Val Loss: 0.0157\n",
      "Epoch [158/1000], Loss: 0.0130, Val Loss: 0.0157\n",
      "Epoch [159/1000], Loss: 0.0130, Val Loss: 0.0157\n",
      "Epoch [160/1000], Loss: 0.0130, Val Loss: 0.0156\n",
      "Epoch [161/1000], Loss: 0.0129, Val Loss: 0.0156\n",
      "Epoch [162/1000], Loss: 0.0129, Val Loss: 0.0155\n",
      "Epoch [163/1000], Loss: 0.0129, Val Loss: 0.0155\n",
      "Epoch [164/1000], Loss: 0.0129, Val Loss: 0.0155\n",
      "Epoch [165/1000], Loss: 0.0128, Val Loss: 0.0154\n",
      "Epoch [166/1000], Loss: 0.0128, Val Loss: 0.0155\n",
      "Epoch [167/1000], Loss: 0.0128, Val Loss: 0.0154\n",
      "Epoch [168/1000], Loss: 0.0127, Val Loss: 0.0154\n",
      "Epoch [169/1000], Loss: 0.0127, Val Loss: 0.0153\n",
      "Epoch [170/1000], Loss: 0.0127, Val Loss: 0.0153\n",
      "Epoch [171/1000], Loss: 0.0127, Val Loss: 0.0153\n",
      "Epoch [172/1000], Loss: 0.0126, Val Loss: 0.0153\n",
      "Epoch [173/1000], Loss: 0.0126, Val Loss: 0.0153\n",
      "Epoch [174/1000], Loss: 0.0126, Val Loss: 0.0152\n",
      "Epoch [175/1000], Loss: 0.0126, Val Loss: 0.0152\n",
      "Epoch [176/1000], Loss: 0.0126, Val Loss: 0.0152\n",
      "Epoch [177/1000], Loss: 0.0126, Val Loss: 0.0151\n",
      "Epoch [178/1000], Loss: 0.0125, Val Loss: 0.0151\n",
      "Epoch [179/1000], Loss: 0.0125, Val Loss: 0.0151\n",
      "Epoch [180/1000], Loss: 0.0125, Val Loss: 0.0151\n",
      "Epoch [181/1000], Loss: 0.0125, Val Loss: 0.0150\n",
      "Epoch [182/1000], Loss: 0.0124, Val Loss: 0.0150\n",
      "Epoch [183/1000], Loss: 0.0124, Val Loss: 0.0150\n",
      "Epoch [184/1000], Loss: 0.0124, Val Loss: 0.0150\n",
      "Epoch [185/1000], Loss: 0.0124, Val Loss: 0.0150\n",
      "Epoch [186/1000], Loss: 0.0124, Val Loss: 0.0149\n",
      "Epoch [187/1000], Loss: 0.0124, Val Loss: 0.0149\n",
      "Epoch [188/1000], Loss: 0.0123, Val Loss: 0.0150\n",
      "Epoch [189/1000], Loss: 0.0123, Val Loss: 0.0149\n",
      "Epoch [190/1000], Loss: 0.0123, Val Loss: 0.0149\n",
      "Epoch [191/1000], Loss: 0.0123, Val Loss: 0.0149\n",
      "Epoch [192/1000], Loss: 0.0123, Val Loss: 0.0149\n",
      "Epoch [193/1000], Loss: 0.0123, Val Loss: 0.0148\n",
      "Epoch [194/1000], Loss: 0.0122, Val Loss: 0.0148\n",
      "Epoch [195/1000], Loss: 0.0122, Val Loss: 0.0148\n",
      "Epoch [196/1000], Loss: 0.0122, Val Loss: 0.0147\n",
      "Epoch [197/1000], Loss: 0.0122, Val Loss: 0.0147\n",
      "Epoch [198/1000], Loss: 0.0122, Val Loss: 0.0148\n",
      "Epoch [199/1000], Loss: 0.0121, Val Loss: 0.0147\n",
      "Epoch [200/1000], Loss: 0.0122, Val Loss: 0.0148\n",
      "Epoch [201/1000], Loss: 0.0121, Val Loss: 0.0147\n",
      "Epoch [202/1000], Loss: 0.0121, Val Loss: 0.0147\n",
      "Epoch [203/1000], Loss: 0.0121, Val Loss: 0.0147\n",
      "Epoch [204/1000], Loss: 0.0121, Val Loss: 0.0147\n",
      "Epoch [205/1000], Loss: 0.0121, Val Loss: 0.0146\n",
      "Epoch [206/1000], Loss: 0.0121, Val Loss: 0.0146\n",
      "Epoch [207/1000], Loss: 0.0120, Val Loss: 0.0146\n",
      "Epoch [208/1000], Loss: 0.0120, Val Loss: 0.0146\n",
      "Epoch [209/1000], Loss: 0.0120, Val Loss: 0.0146\n",
      "Epoch [210/1000], Loss: 0.0120, Val Loss: 0.0145\n",
      "Epoch [211/1000], Loss: 0.0120, Val Loss: 0.0145\n",
      "Epoch [212/1000], Loss: 0.0120, Val Loss: 0.0146\n",
      "Epoch [213/1000], Loss: 0.0120, Val Loss: 0.0145\n",
      "Epoch [214/1000], Loss: 0.0119, Val Loss: 0.0145\n",
      "Epoch [215/1000], Loss: 0.0119, Val Loss: 0.0144\n",
      "Epoch [216/1000], Loss: 0.0119, Val Loss: 0.0144\n",
      "Epoch [217/1000], Loss: 0.0119, Val Loss: 0.0144\n",
      "Epoch [218/1000], Loss: 0.0119, Val Loss: 0.0144\n",
      "Epoch [219/1000], Loss: 0.0119, Val Loss: 0.0144\n",
      "Epoch [220/1000], Loss: 0.0118, Val Loss: 0.0144\n",
      "Epoch [221/1000], Loss: 0.0118, Val Loss: 0.0144\n",
      "Epoch [222/1000], Loss: 0.0118, Val Loss: 0.0143\n",
      "Epoch [223/1000], Loss: 0.0118, Val Loss: 0.0144\n",
      "Epoch [224/1000], Loss: 0.0118, Val Loss: 0.0143\n",
      "Epoch [225/1000], Loss: 0.0117, Val Loss: 0.0143\n",
      "Epoch [226/1000], Loss: 0.0118, Val Loss: 0.0143\n",
      "Epoch [227/1000], Loss: 0.0117, Val Loss: 0.0143\n",
      "Epoch [228/1000], Loss: 0.0117, Val Loss: 0.0142\n",
      "Epoch [229/1000], Loss: 0.0117, Val Loss: 0.0142\n",
      "Epoch [230/1000], Loss: 0.0117, Val Loss: 0.0142\n",
      "Epoch [231/1000], Loss: 0.0116, Val Loss: 0.0142\n",
      "Epoch [232/1000], Loss: 0.0116, Val Loss: 0.0141\n",
      "Epoch [233/1000], Loss: 0.0116, Val Loss: 0.0141\n",
      "Epoch [234/1000], Loss: 0.0116, Val Loss: 0.0141\n",
      "Epoch [235/1000], Loss: 0.0116, Val Loss: 0.0141\n",
      "Epoch [236/1000], Loss: 0.0116, Val Loss: 0.0141\n",
      "Epoch [237/1000], Loss: 0.0115, Val Loss: 0.0141\n",
      "Epoch [238/1000], Loss: 0.0115, Val Loss: 0.0140\n",
      "Epoch [239/1000], Loss: 0.0115, Val Loss: 0.0140\n",
      "Epoch [240/1000], Loss: 0.0115, Val Loss: 0.0140\n",
      "Epoch [241/1000], Loss: 0.0115, Val Loss: 0.0140\n",
      "Epoch [242/1000], Loss: 0.0115, Val Loss: 0.0139\n",
      "Epoch [243/1000], Loss: 0.0114, Val Loss: 0.0140\n",
      "Epoch [244/1000], Loss: 0.0114, Val Loss: 0.0140\n",
      "Epoch [245/1000], Loss: 0.0114, Val Loss: 0.0139\n",
      "Epoch [246/1000], Loss: 0.0114, Val Loss: 0.0139\n",
      "Epoch [247/1000], Loss: 0.0113, Val Loss: 0.0139\n",
      "Epoch [248/1000], Loss: 0.0113, Val Loss: 0.0138\n",
      "Epoch [249/1000], Loss: 0.0113, Val Loss: 0.0138\n",
      "Epoch [250/1000], Loss: 0.0113, Val Loss: 0.0138\n",
      "Epoch [251/1000], Loss: 0.0113, Val Loss: 0.0138\n",
      "Epoch [252/1000], Loss: 0.0112, Val Loss: 0.0138\n",
      "Epoch [253/1000], Loss: 0.0112, Val Loss: 0.0137\n",
      "Epoch [254/1000], Loss: 0.0112, Val Loss: 0.0137\n",
      "Epoch [255/1000], Loss: 0.0112, Val Loss: 0.0137\n",
      "Epoch [256/1000], Loss: 0.0112, Val Loss: 0.0137\n",
      "Epoch [257/1000], Loss: 0.0111, Val Loss: 0.0137\n",
      "Epoch [258/1000], Loss: 0.0111, Val Loss: 0.0136\n",
      "Epoch [259/1000], Loss: 0.0111, Val Loss: 0.0136\n",
      "Epoch [260/1000], Loss: 0.0111, Val Loss: 0.0136\n",
      "Epoch [261/1000], Loss: 0.0111, Val Loss: 0.0135\n",
      "Epoch [262/1000], Loss: 0.0110, Val Loss: 0.0135\n",
      "Epoch [263/1000], Loss: 0.0110, Val Loss: 0.0135\n",
      "Epoch [264/1000], Loss: 0.0110, Val Loss: 0.0135\n",
      "Epoch [265/1000], Loss: 0.0110, Val Loss: 0.0135\n",
      "Epoch [266/1000], Loss: 0.0110, Val Loss: 0.0134\n",
      "Epoch [267/1000], Loss: 0.0110, Val Loss: 0.0134\n",
      "Epoch [268/1000], Loss: 0.0109, Val Loss: 0.0134\n",
      "Epoch [269/1000], Loss: 0.0109, Val Loss: 0.0133\n",
      "Epoch [270/1000], Loss: 0.0109, Val Loss: 0.0133\n",
      "Epoch [271/1000], Loss: 0.0109, Val Loss: 0.0133\n",
      "Epoch [272/1000], Loss: 0.0108, Val Loss: 0.0133\n",
      "Epoch [273/1000], Loss: 0.0108, Val Loss: 0.0133\n",
      "Epoch [274/1000], Loss: 0.0108, Val Loss: 0.0132\n",
      "Epoch [275/1000], Loss: 0.0108, Val Loss: 0.0131\n",
      "Epoch [276/1000], Loss: 0.0107, Val Loss: 0.0132\n",
      "Epoch [277/1000], Loss: 0.0107, Val Loss: 0.0131\n",
      "Epoch [278/1000], Loss: 0.0107, Val Loss: 0.0131\n",
      "Epoch [279/1000], Loss: 0.0107, Val Loss: 0.0131\n",
      "Epoch [280/1000], Loss: 0.0107, Val Loss: 0.0131\n",
      "Epoch [281/1000], Loss: 0.0106, Val Loss: 0.0130\n",
      "Epoch [282/1000], Loss: 0.0106, Val Loss: 0.0130\n",
      "Epoch [283/1000], Loss: 0.0106, Val Loss: 0.0130\n",
      "Epoch [284/1000], Loss: 0.0106, Val Loss: 0.0129\n",
      "Epoch [285/1000], Loss: 0.0105, Val Loss: 0.0130\n",
      "Epoch [286/1000], Loss: 0.0105, Val Loss: 0.0129\n",
      "Epoch [287/1000], Loss: 0.0105, Val Loss: 0.0129\n",
      "Epoch [288/1000], Loss: 0.0105, Val Loss: 0.0129\n",
      "Epoch [289/1000], Loss: 0.0104, Val Loss: 0.0128\n",
      "Epoch [290/1000], Loss: 0.0104, Val Loss: 0.0128\n",
      "Epoch [291/1000], Loss: 0.0104, Val Loss: 0.0128\n",
      "Epoch [292/1000], Loss: 0.0104, Val Loss: 0.0128\n",
      "Epoch [293/1000], Loss: 0.0103, Val Loss: 0.0128\n",
      "Epoch [294/1000], Loss: 0.0103, Val Loss: 0.0127\n",
      "Epoch [295/1000], Loss: 0.0103, Val Loss: 0.0127\n",
      "Epoch [296/1000], Loss: 0.0103, Val Loss: 0.0127\n",
      "Epoch [297/1000], Loss: 0.0103, Val Loss: 0.0128\n",
      "Epoch [298/1000], Loss: 0.0104, Val Loss: 0.0127\n",
      "Epoch [299/1000], Loss: 0.0104, Val Loss: 0.0126\n",
      "Epoch [300/1000], Loss: 0.0103, Val Loss: 0.0126\n",
      "Epoch [301/1000], Loss: 0.0102, Val Loss: 0.0125\n",
      "Epoch [302/1000], Loss: 0.0102, Val Loss: 0.0125\n",
      "Epoch [303/1000], Loss: 0.0102, Val Loss: 0.0125\n",
      "Epoch [304/1000], Loss: 0.0101, Val Loss: 0.0124\n",
      "Epoch [305/1000], Loss: 0.0101, Val Loss: 0.0124\n",
      "Epoch [306/1000], Loss: 0.0101, Val Loss: 0.0124\n",
      "Epoch [307/1000], Loss: 0.0101, Val Loss: 0.0124\n",
      "Epoch [308/1000], Loss: 0.0101, Val Loss: 0.0124\n",
      "Epoch [309/1000], Loss: 0.0100, Val Loss: 0.0123\n",
      "Epoch [310/1000], Loss: 0.0100, Val Loss: 0.0123\n",
      "Epoch [311/1000], Loss: 0.0100, Val Loss: 0.0123\n",
      "Epoch [312/1000], Loss: 0.0100, Val Loss: 0.0123\n",
      "Epoch [313/1000], Loss: 0.0099, Val Loss: 0.0123\n",
      "Epoch [314/1000], Loss: 0.0099, Val Loss: 0.0123\n",
      "Epoch [315/1000], Loss: 0.0099, Val Loss: 0.0122\n",
      "Epoch [316/1000], Loss: 0.0099, Val Loss: 0.0122\n",
      "Epoch [317/1000], Loss: 0.0099, Val Loss: 0.0122\n",
      "Epoch [318/1000], Loss: 0.0099, Val Loss: 0.0122\n",
      "Epoch [319/1000], Loss: 0.0099, Val Loss: 0.0123\n",
      "Epoch [320/1000], Loss: 0.0099, Val Loss: 0.0122\n",
      "Epoch [321/1000], Loss: 0.0098, Val Loss: 0.0122\n",
      "Epoch [322/1000], Loss: 0.0098, Val Loss: 0.0122\n",
      "Epoch [323/1000], Loss: 0.0098, Val Loss: 0.0121\n",
      "Epoch [324/1000], Loss: 0.0098, Val Loss: 0.0121\n",
      "Epoch [325/1000], Loss: 0.0097, Val Loss: 0.0121\n",
      "Epoch [326/1000], Loss: 0.0097, Val Loss: 0.0120\n",
      "Epoch [327/1000], Loss: 0.0097, Val Loss: 0.0119\n",
      "Epoch [328/1000], Loss: 0.0097, Val Loss: 0.0120\n",
      "Epoch [329/1000], Loss: 0.0097, Val Loss: 0.0120\n",
      "Epoch [330/1000], Loss: 0.0096, Val Loss: 0.0119\n",
      "Epoch [331/1000], Loss: 0.0096, Val Loss: 0.0119\n",
      "Epoch [332/1000], Loss: 0.0096, Val Loss: 0.0119\n",
      "Epoch [333/1000], Loss: 0.0096, Val Loss: 0.0119\n",
      "Epoch [334/1000], Loss: 0.0096, Val Loss: 0.0118\n",
      "Epoch [335/1000], Loss: 0.0096, Val Loss: 0.0118\n",
      "Epoch [336/1000], Loss: 0.0095, Val Loss: 0.0118\n",
      "Epoch [337/1000], Loss: 0.0095, Val Loss: 0.0118\n",
      "Epoch [338/1000], Loss: 0.0095, Val Loss: 0.0118\n",
      "Epoch [339/1000], Loss: 0.0095, Val Loss: 0.0118\n",
      "Epoch [340/1000], Loss: 0.0095, Val Loss: 0.0118\n",
      "Epoch [341/1000], Loss: 0.0095, Val Loss: 0.0118\n",
      "Epoch [342/1000], Loss: 0.0095, Val Loss: 0.0117\n",
      "Epoch [343/1000], Loss: 0.0095, Val Loss: 0.0118\n",
      "Epoch [344/1000], Loss: 0.0095, Val Loss: 0.0118\n",
      "Epoch [345/1000], Loss: 0.0094, Val Loss: 0.0118\n",
      "Epoch [346/1000], Loss: 0.0094, Val Loss: 0.0117\n",
      "Epoch [347/1000], Loss: 0.0094, Val Loss: 0.0117\n",
      "Epoch [348/1000], Loss: 0.0094, Val Loss: 0.0116\n",
      "Epoch [349/1000], Loss: 0.0094, Val Loss: 0.0116\n",
      "Epoch [350/1000], Loss: 0.0094, Val Loss: 0.0116\n",
      "Epoch [351/1000], Loss: 0.0094, Val Loss: 0.0116\n",
      "Epoch [352/1000], Loss: 0.0094, Val Loss: 0.0117\n",
      "Epoch [353/1000], Loss: 0.0094, Val Loss: 0.0116\n",
      "Epoch [354/1000], Loss: 0.0094, Val Loss: 0.0115\n",
      "Epoch [355/1000], Loss: 0.0093, Val Loss: 0.0115\n",
      "Epoch [356/1000], Loss: 0.0093, Val Loss: 0.0115\n",
      "Epoch [357/1000], Loss: 0.0093, Val Loss: 0.0115\n",
      "Epoch [358/1000], Loss: 0.0093, Val Loss: 0.0114\n",
      "Epoch [359/1000], Loss: 0.0092, Val Loss: 0.0115\n",
      "Epoch [360/1000], Loss: 0.0092, Val Loss: 0.0115\n",
      "Epoch [361/1000], Loss: 0.0093, Val Loss: 0.0115\n",
      "Epoch [362/1000], Loss: 0.0092, Val Loss: 0.0115\n",
      "Epoch [363/1000], Loss: 0.0092, Val Loss: 0.0114\n",
      "Epoch [364/1000], Loss: 0.0092, Val Loss: 0.0114\n",
      "Epoch [365/1000], Loss: 0.0092, Val Loss: 0.0114\n",
      "Epoch [366/1000], Loss: 0.0092, Val Loss: 0.0113\n",
      "Epoch [367/1000], Loss: 0.0091, Val Loss: 0.0113\n",
      "Epoch [368/1000], Loss: 0.0091, Val Loss: 0.0113\n",
      "Epoch [369/1000], Loss: 0.0091, Val Loss: 0.0113\n",
      "Epoch [370/1000], Loss: 0.0091, Val Loss: 0.0113\n",
      "Epoch [371/1000], Loss: 0.0091, Val Loss: 0.0113\n",
      "Epoch [372/1000], Loss: 0.0092, Val Loss: 0.0113\n",
      "Epoch [373/1000], Loss: 0.0091, Val Loss: 0.0113\n",
      "Epoch [374/1000], Loss: 0.0091, Val Loss: 0.0113\n",
      "Epoch [375/1000], Loss: 0.0091, Val Loss: 0.0112\n",
      "Epoch [376/1000], Loss: 0.0091, Val Loss: 0.0112\n",
      "Epoch [377/1000], Loss: 0.0091, Val Loss: 0.0112\n",
      "Epoch [378/1000], Loss: 0.0091, Val Loss: 0.0112\n",
      "Epoch [379/1000], Loss: 0.0090, Val Loss: 0.0112\n",
      "Epoch [380/1000], Loss: 0.0090, Val Loss: 0.0112\n",
      "Epoch [381/1000], Loss: 0.0090, Val Loss: 0.0112\n",
      "Epoch [382/1000], Loss: 0.0090, Val Loss: 0.0112\n",
      "Epoch [383/1000], Loss: 0.0090, Val Loss: 0.0112\n",
      "Epoch [384/1000], Loss: 0.0090, Val Loss: 0.0111\n",
      "Epoch [385/1000], Loss: 0.0090, Val Loss: 0.0111\n",
      "Epoch [386/1000], Loss: 0.0090, Val Loss: 0.0111\n",
      "Epoch [387/1000], Loss: 0.0089, Val Loss: 0.0111\n",
      "Epoch [388/1000], Loss: 0.0089, Val Loss: 0.0111\n",
      "Epoch [389/1000], Loss: 0.0089, Val Loss: 0.0111\n",
      "Epoch [390/1000], Loss: 0.0089, Val Loss: 0.0111\n",
      "Epoch [391/1000], Loss: 0.0089, Val Loss: 0.0111\n",
      "Epoch [392/1000], Loss: 0.0089, Val Loss: 0.0111\n",
      "Epoch [393/1000], Loss: 0.0089, Val Loss: 0.0111\n",
      "Epoch [394/1000], Loss: 0.0089, Val Loss: 0.0110\n",
      "Epoch [395/1000], Loss: 0.0089, Val Loss: 0.0111\n",
      "Epoch [396/1000], Loss: 0.0089, Val Loss: 0.0111\n",
      "Epoch [397/1000], Loss: 0.0089, Val Loss: 0.0110\n",
      "Epoch [398/1000], Loss: 0.0089, Val Loss: 0.0110\n",
      "Epoch [399/1000], Loss: 0.0089, Val Loss: 0.0110\n",
      "Epoch [400/1000], Loss: 0.0089, Val Loss: 0.0110\n",
      "Epoch [401/1000], Loss: 0.0088, Val Loss: 0.0110\n",
      "Epoch [402/1000], Loss: 0.0088, Val Loss: 0.0110\n",
      "Epoch [403/1000], Loss: 0.0088, Val Loss: 0.0110\n",
      "Epoch [404/1000], Loss: 0.0088, Val Loss: 0.0110\n",
      "Epoch [405/1000], Loss: 0.0088, Val Loss: 0.0110\n",
      "Epoch [406/1000], Loss: 0.0088, Val Loss: 0.0110\n",
      "Epoch [407/1000], Loss: 0.0088, Val Loss: 0.0109\n",
      "Epoch [408/1000], Loss: 0.0088, Val Loss: 0.0109\n",
      "Epoch [409/1000], Loss: 0.0088, Val Loss: 0.0109\n",
      "Epoch [410/1000], Loss: 0.0088, Val Loss: 0.0109\n",
      "Epoch [411/1000], Loss: 0.0088, Val Loss: 0.0109\n",
      "Epoch [412/1000], Loss: 0.0088, Val Loss: 0.0109\n",
      "Epoch [413/1000], Loss: 0.0088, Val Loss: 0.0109\n",
      "Epoch [414/1000], Loss: 0.0087, Val Loss: 0.0109\n",
      "Epoch [415/1000], Loss: 0.0087, Val Loss: 0.0109\n",
      "Epoch [416/1000], Loss: 0.0087, Val Loss: 0.0108\n",
      "Epoch [417/1000], Loss: 0.0087, Val Loss: 0.0109\n",
      "Epoch [418/1000], Loss: 0.0087, Val Loss: 0.0109\n",
      "Epoch [419/1000], Loss: 0.0087, Val Loss: 0.0108\n",
      "Epoch [420/1000], Loss: 0.0087, Val Loss: 0.0108\n",
      "Epoch [421/1000], Loss: 0.0087, Val Loss: 0.0109\n",
      "Epoch [422/1000], Loss: 0.0087, Val Loss: 0.0108\n",
      "Epoch [423/1000], Loss: 0.0087, Val Loss: 0.0108\n",
      "Epoch [424/1000], Loss: 0.0087, Val Loss: 0.0108\n",
      "Epoch [425/1000], Loss: 0.0087, Val Loss: 0.0108\n",
      "Epoch [426/1000], Loss: 0.0087, Val Loss: 0.0108\n",
      "Epoch [427/1000], Loss: 0.0086, Val Loss: 0.0108\n",
      "Epoch [428/1000], Loss: 0.0086, Val Loss: 0.0108\n",
      "Epoch [429/1000], Loss: 0.0086, Val Loss: 0.0108\n",
      "Epoch [430/1000], Loss: 0.0086, Val Loss: 0.0107\n",
      "Epoch [431/1000], Loss: 0.0086, Val Loss: 0.0108\n",
      "Epoch [432/1000], Loss: 0.0086, Val Loss: 0.0107\n",
      "Epoch [433/1000], Loss: 0.0086, Val Loss: 0.0108\n",
      "Epoch [434/1000], Loss: 0.0086, Val Loss: 0.0108\n",
      "Epoch [435/1000], Loss: 0.0086, Val Loss: 0.0107\n",
      "Epoch [436/1000], Loss: 0.0086, Val Loss: 0.0107\n",
      "Epoch [437/1000], Loss: 0.0086, Val Loss: 0.0107\n",
      "Epoch [438/1000], Loss: 0.0086, Val Loss: 0.0107\n",
      "Epoch [439/1000], Loss: 0.0086, Val Loss: 0.0107\n",
      "Epoch [440/1000], Loss: 0.0085, Val Loss: 0.0107\n",
      "Epoch [441/1000], Loss: 0.0085, Val Loss: 0.0107\n",
      "Epoch [442/1000], Loss: 0.0085, Val Loss: 0.0107\n",
      "Epoch [443/1000], Loss: 0.0085, Val Loss: 0.0107\n",
      "Epoch [444/1000], Loss: 0.0085, Val Loss: 0.0107\n",
      "Epoch [445/1000], Loss: 0.0085, Val Loss: 0.0107\n",
      "Epoch [446/1000], Loss: 0.0085, Val Loss: 0.0106\n",
      "Epoch [447/1000], Loss: 0.0085, Val Loss: 0.0106\n",
      "Epoch [448/1000], Loss: 0.0085, Val Loss: 0.0107\n",
      "Epoch [449/1000], Loss: 0.0085, Val Loss: 0.0106\n",
      "Epoch [450/1000], Loss: 0.0085, Val Loss: 0.0106\n",
      "Epoch [451/1000], Loss: 0.0085, Val Loss: 0.0106\n",
      "Epoch [452/1000], Loss: 0.0085, Val Loss: 0.0107\n",
      "Epoch [453/1000], Loss: 0.0085, Val Loss: 0.0106\n",
      "Epoch [454/1000], Loss: 0.0085, Val Loss: 0.0107\n",
      "Epoch [455/1000], Loss: 0.0085, Val Loss: 0.0106\n",
      "Epoch [456/1000], Loss: 0.0085, Val Loss: 0.0106\n",
      "Epoch [457/1000], Loss: 0.0085, Val Loss: 0.0106\n",
      "Epoch [458/1000], Loss: 0.0085, Val Loss: 0.0106\n",
      "Epoch [459/1000], Loss: 0.0084, Val Loss: 0.0106\n",
      "Epoch [460/1000], Loss: 0.0084, Val Loss: 0.0106\n",
      "Epoch [461/1000], Loss: 0.0084, Val Loss: 0.0106\n",
      "Epoch [462/1000], Loss: 0.0084, Val Loss: 0.0106\n",
      "Epoch [463/1000], Loss: 0.0084, Val Loss: 0.0105\n",
      "Epoch [464/1000], Loss: 0.0084, Val Loss: 0.0105\n",
      "Epoch [465/1000], Loss: 0.0084, Val Loss: 0.0106\n",
      "Epoch [466/1000], Loss: 0.0084, Val Loss: 0.0106\n",
      "Epoch [467/1000], Loss: 0.0084, Val Loss: 0.0105\n",
      "Epoch [468/1000], Loss: 0.0084, Val Loss: 0.0105\n",
      "Epoch [469/1000], Loss: 0.0084, Val Loss: 0.0105\n",
      "Epoch [470/1000], Loss: 0.0084, Val Loss: 0.0105\n",
      "Epoch [471/1000], Loss: 0.0084, Val Loss: 0.0105\n",
      "Epoch [472/1000], Loss: 0.0084, Val Loss: 0.0105\n",
      "Epoch [473/1000], Loss: 0.0084, Val Loss: 0.0105\n",
      "Epoch [474/1000], Loss: 0.0084, Val Loss: 0.0105\n",
      "Epoch [475/1000], Loss: 0.0084, Val Loss: 0.0105\n",
      "Epoch [476/1000], Loss: 0.0084, Val Loss: 0.0105\n",
      "Epoch [477/1000], Loss: 0.0083, Val Loss: 0.0105\n",
      "Epoch [478/1000], Loss: 0.0083, Val Loss: 0.0105\n",
      "Epoch [479/1000], Loss: 0.0083, Val Loss: 0.0105\n",
      "Epoch [480/1000], Loss: 0.0083, Val Loss: 0.0104\n",
      "Epoch [481/1000], Loss: 0.0083, Val Loss: 0.0104\n",
      "Epoch [482/1000], Loss: 0.0083, Val Loss: 0.0104\n",
      "Epoch [483/1000], Loss: 0.0083, Val Loss: 0.0104\n",
      "Epoch [484/1000], Loss: 0.0083, Val Loss: 0.0105\n",
      "Epoch [485/1000], Loss: 0.0083, Val Loss: 0.0104\n",
      "Epoch [486/1000], Loss: 0.0083, Val Loss: 0.0104\n",
      "Epoch [487/1000], Loss: 0.0083, Val Loss: 0.0104\n",
      "Epoch [488/1000], Loss: 0.0083, Val Loss: 0.0104\n",
      "Epoch [489/1000], Loss: 0.0083, Val Loss: 0.0104\n",
      "Epoch [490/1000], Loss: 0.0083, Val Loss: 0.0105\n",
      "Epoch [491/1000], Loss: 0.0083, Val Loss: 0.0104\n",
      "Epoch [492/1000], Loss: 0.0083, Val Loss: 0.0104\n",
      "Epoch [493/1000], Loss: 0.0083, Val Loss: 0.0104\n",
      "Epoch [494/1000], Loss: 0.0082, Val Loss: 0.0104\n",
      "Epoch [495/1000], Loss: 0.0083, Val Loss: 0.0104\n",
      "Epoch [496/1000], Loss: 0.0083, Val Loss: 0.0103\n",
      "Epoch [497/1000], Loss: 0.0082, Val Loss: 0.0104\n",
      "Epoch [498/1000], Loss: 0.0082, Val Loss: 0.0104\n",
      "Epoch [499/1000], Loss: 0.0082, Val Loss: 0.0104\n",
      "Epoch [500/1000], Loss: 0.0082, Val Loss: 0.0103\n",
      "Epoch [501/1000], Loss: 0.0082, Val Loss: 0.0103\n",
      "Epoch [502/1000], Loss: 0.0082, Val Loss: 0.0103\n",
      "Epoch [503/1000], Loss: 0.0082, Val Loss: 0.0103\n",
      "Epoch [504/1000], Loss: 0.0082, Val Loss: 0.0103\n",
      "Epoch [505/1000], Loss: 0.0082, Val Loss: 0.0103\n",
      "Epoch [506/1000], Loss: 0.0082, Val Loss: 0.0103\n",
      "Epoch [507/1000], Loss: 0.0082, Val Loss: 0.0103\n",
      "Epoch [508/1000], Loss: 0.0082, Val Loss: 0.0103\n",
      "Epoch [509/1000], Loss: 0.0082, Val Loss: 0.0103\n",
      "Epoch [510/1000], Loss: 0.0082, Val Loss: 0.0103\n",
      "Epoch [511/1000], Loss: 0.0082, Val Loss: 0.0103\n",
      "Epoch [512/1000], Loss: 0.0082, Val Loss: 0.0103\n",
      "Epoch [513/1000], Loss: 0.0082, Val Loss: 0.0103\n",
      "Epoch [514/1000], Loss: 0.0081, Val Loss: 0.0103\n",
      "Epoch [515/1000], Loss: 0.0081, Val Loss: 0.0103\n",
      "Epoch [516/1000], Loss: 0.0082, Val Loss: 0.0103\n",
      "Epoch [517/1000], Loss: 0.0081, Val Loss: 0.0103\n",
      "Epoch [518/1000], Loss: 0.0081, Val Loss: 0.0103\n",
      "Epoch [519/1000], Loss: 0.0081, Val Loss: 0.0103\n",
      "Epoch [520/1000], Loss: 0.0081, Val Loss: 0.0102\n",
      "Epoch [521/1000], Loss: 0.0081, Val Loss: 0.0102\n",
      "Epoch [522/1000], Loss: 0.0081, Val Loss: 0.0102\n",
      "Epoch [523/1000], Loss: 0.0081, Val Loss: 0.0102\n",
      "Epoch [524/1000], Loss: 0.0081, Val Loss: 0.0102\n",
      "Epoch [525/1000], Loss: 0.0081, Val Loss: 0.0102\n",
      "Epoch [526/1000], Loss: 0.0081, Val Loss: 0.0102\n",
      "Epoch [527/1000], Loss: 0.0081, Val Loss: 0.0102\n",
      "Epoch [528/1000], Loss: 0.0081, Val Loss: 0.0102\n",
      "Epoch [529/1000], Loss: 0.0081, Val Loss: 0.0102\n",
      "Epoch [530/1000], Loss: 0.0081, Val Loss: 0.0102\n",
      "Epoch [531/1000], Loss: 0.0081, Val Loss: 0.0102\n",
      "Epoch [532/1000], Loss: 0.0081, Val Loss: 0.0102\n",
      "Epoch [533/1000], Loss: 0.0081, Val Loss: 0.0102\n",
      "Epoch [534/1000], Loss: 0.0081, Val Loss: 0.0102\n",
      "Epoch [535/1000], Loss: 0.0081, Val Loss: 0.0102\n",
      "Epoch [536/1000], Loss: 0.0081, Val Loss: 0.0101\n",
      "Epoch [537/1000], Loss: 0.0080, Val Loss: 0.0101\n",
      "Epoch [538/1000], Loss: 0.0081, Val Loss: 0.0102\n",
      "Epoch [539/1000], Loss: 0.0080, Val Loss: 0.0101\n",
      "Epoch [540/1000], Loss: 0.0080, Val Loss: 0.0101\n",
      "Epoch [541/1000], Loss: 0.0080, Val Loss: 0.0101\n",
      "Epoch [542/1000], Loss: 0.0080, Val Loss: 0.0101\n",
      "Epoch [543/1000], Loss: 0.0080, Val Loss: 0.0101\n",
      "Epoch [544/1000], Loss: 0.0080, Val Loss: 0.0101\n",
      "Epoch [545/1000], Loss: 0.0080, Val Loss: 0.0101\n",
      "Epoch [546/1000], Loss: 0.0080, Val Loss: 0.0101\n",
      "Epoch [547/1000], Loss: 0.0080, Val Loss: 0.0101\n",
      "Epoch [548/1000], Loss: 0.0080, Val Loss: 0.0101\n",
      "Epoch [549/1000], Loss: 0.0080, Val Loss: 0.0101\n",
      "Epoch [550/1000], Loss: 0.0080, Val Loss: 0.0101\n",
      "Epoch [551/1000], Loss: 0.0080, Val Loss: 0.0101\n",
      "Epoch [552/1000], Loss: 0.0080, Val Loss: 0.0101\n",
      "Epoch [553/1000], Loss: 0.0080, Val Loss: 0.0101\n",
      "Epoch [554/1000], Loss: 0.0080, Val Loss: 0.0101\n",
      "Epoch [555/1000], Loss: 0.0080, Val Loss: 0.0101\n",
      "Epoch [556/1000], Loss: 0.0079, Val Loss: 0.0100\n",
      "Epoch [557/1000], Loss: 0.0079, Val Loss: 0.0100\n",
      "Epoch [558/1000], Loss: 0.0080, Val Loss: 0.0101\n",
      "Epoch [559/1000], Loss: 0.0079, Val Loss: 0.0100\n",
      "Epoch [560/1000], Loss: 0.0079, Val Loss: 0.0100\n",
      "Epoch [561/1000], Loss: 0.0079, Val Loss: 0.0100\n",
      "Epoch [562/1000], Loss: 0.0079, Val Loss: 0.0100\n",
      "Epoch [563/1000], Loss: 0.0079, Val Loss: 0.0100\n",
      "Epoch [564/1000], Loss: 0.0079, Val Loss: 0.0100\n",
      "Epoch [565/1000], Loss: 0.0079, Val Loss: 0.0100\n",
      "Epoch [566/1000], Loss: 0.0079, Val Loss: 0.0100\n",
      "Epoch [567/1000], Loss: 0.0079, Val Loss: 0.0100\n",
      "Epoch [568/1000], Loss: 0.0079, Val Loss: 0.0100\n",
      "Epoch [569/1000], Loss: 0.0079, Val Loss: 0.0100\n",
      "Epoch [570/1000], Loss: 0.0079, Val Loss: 0.0100\n",
      "Epoch [571/1000], Loss: 0.0079, Val Loss: 0.0100\n",
      "Epoch [572/1000], Loss: 0.0079, Val Loss: 0.0100\n",
      "Epoch [573/1000], Loss: 0.0079, Val Loss: 0.0100\n",
      "Epoch [574/1000], Loss: 0.0079, Val Loss: 0.0100\n",
      "Epoch [575/1000], Loss: 0.0079, Val Loss: 0.0100\n",
      "Epoch [576/1000], Loss: 0.0079, Val Loss: 0.0100\n",
      "Epoch [577/1000], Loss: 0.0078, Val Loss: 0.0100\n",
      "Epoch [578/1000], Loss: 0.0079, Val Loss: 0.0100\n",
      "Epoch [579/1000], Loss: 0.0078, Val Loss: 0.0099\n",
      "Epoch [580/1000], Loss: 0.0078, Val Loss: 0.0099\n",
      "Epoch [581/1000], Loss: 0.0078, Val Loss: 0.0099\n",
      "Epoch [582/1000], Loss: 0.0078, Val Loss: 0.0099\n",
      "Epoch [583/1000], Loss: 0.0078, Val Loss: 0.0099\n",
      "Epoch [584/1000], Loss: 0.0078, Val Loss: 0.0099\n",
      "Epoch [585/1000], Loss: 0.0078, Val Loss: 0.0099\n",
      "Epoch [586/1000], Loss: 0.0078, Val Loss: 0.0099\n",
      "Epoch [587/1000], Loss: 0.0078, Val Loss: 0.0099\n",
      "Epoch [588/1000], Loss: 0.0078, Val Loss: 0.0099\n",
      "Epoch [589/1000], Loss: 0.0078, Val Loss: 0.0099\n",
      "Epoch [590/1000], Loss: 0.0078, Val Loss: 0.0099\n",
      "Epoch [591/1000], Loss: 0.0078, Val Loss: 0.0099\n",
      "Epoch [592/1000], Loss: 0.0078, Val Loss: 0.0099\n",
      "Epoch [593/1000], Loss: 0.0078, Val Loss: 0.0099\n",
      "Epoch [594/1000], Loss: 0.0078, Val Loss: 0.0099\n",
      "Epoch [595/1000], Loss: 0.0078, Val Loss: 0.0099\n",
      "Epoch [596/1000], Loss: 0.0078, Val Loss: 0.0099\n",
      "Epoch [597/1000], Loss: 0.0078, Val Loss: 0.0099\n",
      "Epoch [598/1000], Loss: 0.0078, Val Loss: 0.0099\n",
      "Epoch [599/1000], Loss: 0.0078, Val Loss: 0.0098\n",
      "Epoch [600/1000], Loss: 0.0077, Val Loss: 0.0098\n",
      "Epoch [601/1000], Loss: 0.0078, Val Loss: 0.0099\n",
      "Epoch [602/1000], Loss: 0.0077, Val Loss: 0.0098\n",
      "Epoch [603/1000], Loss: 0.0077, Val Loss: 0.0098\n",
      "Epoch [604/1000], Loss: 0.0077, Val Loss: 0.0099\n",
      "Epoch [605/1000], Loss: 0.0078, Val Loss: 0.0099\n",
      "Epoch [606/1000], Loss: 0.0077, Val Loss: 0.0098\n",
      "Epoch [607/1000], Loss: 0.0077, Val Loss: 0.0098\n",
      "Epoch [608/1000], Loss: 0.0077, Val Loss: 0.0098\n",
      "Epoch [609/1000], Loss: 0.0077, Val Loss: 0.0098\n",
      "Epoch [610/1000], Loss: 0.0077, Val Loss: 0.0098\n",
      "Epoch [611/1000], Loss: 0.0077, Val Loss: 0.0098\n",
      "Epoch [612/1000], Loss: 0.0077, Val Loss: 0.0098\n",
      "Epoch [613/1000], Loss: 0.0077, Val Loss: 0.0098\n",
      "Epoch [614/1000], Loss: 0.0077, Val Loss: 0.0097\n",
      "Epoch [615/1000], Loss: 0.0077, Val Loss: 0.0098\n",
      "Epoch [616/1000], Loss: 0.0077, Val Loss: 0.0098\n",
      "Epoch [617/1000], Loss: 0.0077, Val Loss: 0.0098\n",
      "Epoch [618/1000], Loss: 0.0077, Val Loss: 0.0098\n",
      "Epoch [619/1000], Loss: 0.0077, Val Loss: 0.0098\n",
      "Epoch [620/1000], Loss: 0.0077, Val Loss: 0.0097\n",
      "Epoch [621/1000], Loss: 0.0076, Val Loss: 0.0097\n",
      "Epoch [622/1000], Loss: 0.0076, Val Loss: 0.0097\n",
      "Epoch [623/1000], Loss: 0.0077, Val Loss: 0.0097\n",
      "Epoch [624/1000], Loss: 0.0076, Val Loss: 0.0097\n",
      "Epoch [625/1000], Loss: 0.0076, Val Loss: 0.0098\n",
      "Epoch [626/1000], Loss: 0.0076, Val Loss: 0.0097\n",
      "Epoch [627/1000], Loss: 0.0076, Val Loss: 0.0097\n",
      "Epoch [628/1000], Loss: 0.0076, Val Loss: 0.0097\n",
      "Epoch [629/1000], Loss: 0.0076, Val Loss: 0.0097\n",
      "Epoch [630/1000], Loss: 0.0076, Val Loss: 0.0097\n",
      "Epoch [631/1000], Loss: 0.0076, Val Loss: 0.0097\n",
      "Epoch [632/1000], Loss: 0.0076, Val Loss: 0.0097\n",
      "Epoch [633/1000], Loss: 0.0076, Val Loss: 0.0097\n",
      "Epoch [634/1000], Loss: 0.0076, Val Loss: 0.0097\n",
      "Epoch [635/1000], Loss: 0.0076, Val Loss: 0.0097\n",
      "Epoch [636/1000], Loss: 0.0076, Val Loss: 0.0097\n",
      "Epoch [637/1000], Loss: 0.0076, Val Loss: 0.0097\n",
      "Epoch [638/1000], Loss: 0.0076, Val Loss: 0.0097\n",
      "Epoch [639/1000], Loss: 0.0076, Val Loss: 0.0096\n",
      "Epoch [640/1000], Loss: 0.0076, Val Loss: 0.0096\n",
      "Epoch [641/1000], Loss: 0.0076, Val Loss: 0.0096\n",
      "Epoch [642/1000], Loss: 0.0076, Val Loss: 0.0096\n",
      "Epoch [643/1000], Loss: 0.0076, Val Loss: 0.0096\n",
      "Epoch [644/1000], Loss: 0.0075, Val Loss: 0.0096\n",
      "Epoch [645/1000], Loss: 0.0075, Val Loss: 0.0097\n",
      "Epoch [646/1000], Loss: 0.0075, Val Loss: 0.0096\n",
      "Epoch [647/1000], Loss: 0.0075, Val Loss: 0.0096\n",
      "Epoch [648/1000], Loss: 0.0075, Val Loss: 0.0096\n",
      "Epoch [649/1000], Loss: 0.0075, Val Loss: 0.0096\n",
      "Epoch [650/1000], Loss: 0.0075, Val Loss: 0.0096\n",
      "Epoch [651/1000], Loss: 0.0075, Val Loss: 0.0096\n",
      "Epoch [652/1000], Loss: 0.0075, Val Loss: 0.0096\n",
      "Epoch [653/1000], Loss: 0.0075, Val Loss: 0.0096\n",
      "Epoch [654/1000], Loss: 0.0075, Val Loss: 0.0096\n",
      "Epoch [655/1000], Loss: 0.0075, Val Loss: 0.0096\n",
      "Epoch [656/1000], Loss: 0.0075, Val Loss: 0.0096\n",
      "Epoch [657/1000], Loss: 0.0075, Val Loss: 0.0096\n",
      "Epoch [658/1000], Loss: 0.0075, Val Loss: 0.0096\n",
      "Epoch [659/1000], Loss: 0.0075, Val Loss: 0.0095\n",
      "Epoch [660/1000], Loss: 0.0075, Val Loss: 0.0096\n",
      "Epoch [661/1000], Loss: 0.0075, Val Loss: 0.0095\n",
      "Epoch [662/1000], Loss: 0.0075, Val Loss: 0.0096\n",
      "Epoch [663/1000], Loss: 0.0075, Val Loss: 0.0096\n",
      "Epoch [664/1000], Loss: 0.0075, Val Loss: 0.0095\n",
      "Epoch [665/1000], Loss: 0.0074, Val Loss: 0.0096\n",
      "Epoch [666/1000], Loss: 0.0074, Val Loss: 0.0095\n",
      "Epoch [667/1000], Loss: 0.0074, Val Loss: 0.0095\n",
      "Epoch [668/1000], Loss: 0.0074, Val Loss: 0.0095\n",
      "Epoch [669/1000], Loss: 0.0075, Val Loss: 0.0095\n",
      "Epoch [670/1000], Loss: 0.0074, Val Loss: 0.0095\n",
      "Epoch [671/1000], Loss: 0.0074, Val Loss: 0.0095\n",
      "Epoch [672/1000], Loss: 0.0074, Val Loss: 0.0095\n",
      "Epoch [673/1000], Loss: 0.0074, Val Loss: 0.0095\n",
      "Epoch [674/1000], Loss: 0.0074, Val Loss: 0.0095\n",
      "Epoch [675/1000], Loss: 0.0074, Val Loss: 0.0095\n",
      "Epoch [676/1000], Loss: 0.0074, Val Loss: 0.0095\n",
      "Epoch [677/1000], Loss: 0.0074, Val Loss: 0.0094\n",
      "Epoch [678/1000], Loss: 0.0074, Val Loss: 0.0095\n",
      "Epoch [679/1000], Loss: 0.0074, Val Loss: 0.0095\n",
      "Epoch [680/1000], Loss: 0.0074, Val Loss: 0.0094\n",
      "Epoch [681/1000], Loss: 0.0074, Val Loss: 0.0095\n",
      "Epoch [682/1000], Loss: 0.0074, Val Loss: 0.0095\n",
      "Epoch [683/1000], Loss: 0.0074, Val Loss: 0.0094\n",
      "Epoch [684/1000], Loss: 0.0074, Val Loss: 0.0094\n",
      "Epoch [685/1000], Loss: 0.0074, Val Loss: 0.0094\n",
      "Epoch [686/1000], Loss: 0.0073, Val Loss: 0.0094\n",
      "Epoch [687/1000], Loss: 0.0074, Val Loss: 0.0094\n",
      "Epoch [688/1000], Loss: 0.0073, Val Loss: 0.0095\n",
      "Epoch [689/1000], Loss: 0.0073, Val Loss: 0.0094\n",
      "Epoch [690/1000], Loss: 0.0073, Val Loss: 0.0094\n",
      "Epoch [691/1000], Loss: 0.0073, Val Loss: 0.0094\n",
      "Epoch [692/1000], Loss: 0.0073, Val Loss: 0.0094\n",
      "Epoch [693/1000], Loss: 0.0073, Val Loss: 0.0094\n",
      "Epoch [694/1000], Loss: 0.0073, Val Loss: 0.0094\n",
      "Epoch [695/1000], Loss: 0.0073, Val Loss: 0.0094\n",
      "Epoch [696/1000], Loss: 0.0073, Val Loss: 0.0094\n",
      "Epoch [697/1000], Loss: 0.0073, Val Loss: 0.0094\n",
      "Epoch [698/1000], Loss: 0.0073, Val Loss: 0.0094\n",
      "Epoch [699/1000], Loss: 0.0073, Val Loss: 0.0094\n",
      "Epoch [700/1000], Loss: 0.0073, Val Loss: 0.0094\n",
      "Epoch [701/1000], Loss: 0.0073, Val Loss: 0.0094\n",
      "Epoch [702/1000], Loss: 0.0073, Val Loss: 0.0094\n",
      "Epoch [703/1000], Loss: 0.0073, Val Loss: 0.0093\n",
      "Epoch [704/1000], Loss: 0.0073, Val Loss: 0.0094\n",
      "Epoch [705/1000], Loss: 0.0073, Val Loss: 0.0093\n",
      "Epoch [706/1000], Loss: 0.0073, Val Loss: 0.0093\n",
      "Epoch [707/1000], Loss: 0.0073, Val Loss: 0.0093\n",
      "Epoch [708/1000], Loss: 0.0073, Val Loss: 0.0093\n",
      "Epoch [709/1000], Loss: 0.0072, Val Loss: 0.0094\n",
      "Epoch [710/1000], Loss: 0.0073, Val Loss: 0.0093\n",
      "Epoch [711/1000], Loss: 0.0072, Val Loss: 0.0093\n",
      "Epoch [712/1000], Loss: 0.0072, Val Loss: 0.0093\n",
      "Epoch [713/1000], Loss: 0.0073, Val Loss: 0.0093\n",
      "Epoch [714/1000], Loss: 0.0072, Val Loss: 0.0093\n",
      "Epoch [715/1000], Loss: 0.0072, Val Loss: 0.0093\n",
      "Epoch [716/1000], Loss: 0.0072, Val Loss: 0.0093\n",
      "Epoch [717/1000], Loss: 0.0072, Val Loss: 0.0093\n",
      "Epoch [718/1000], Loss: 0.0072, Val Loss: 0.0093\n",
      "Epoch [719/1000], Loss: 0.0072, Val Loss: 0.0093\n",
      "Epoch [720/1000], Loss: 0.0072, Val Loss: 0.0093\n",
      "Epoch [721/1000], Loss: 0.0072, Val Loss: 0.0093\n",
      "Epoch [722/1000], Loss: 0.0072, Val Loss: 0.0093\n",
      "Epoch [723/1000], Loss: 0.0072, Val Loss: 0.0093\n",
      "Epoch [724/1000], Loss: 0.0072, Val Loss: 0.0093\n",
      "Epoch [725/1000], Loss: 0.0072, Val Loss: 0.0092\n",
      "Epoch [726/1000], Loss: 0.0072, Val Loss: 0.0093\n",
      "Epoch [727/1000], Loss: 0.0072, Val Loss: 0.0093\n",
      "Epoch [728/1000], Loss: 0.0072, Val Loss: 0.0093\n",
      "Epoch [729/1000], Loss: 0.0072, Val Loss: 0.0092\n",
      "Epoch [730/1000], Loss: 0.0072, Val Loss: 0.0092\n",
      "Epoch [731/1000], Loss: 0.0071, Val Loss: 0.0092\n",
      "Epoch [732/1000], Loss: 0.0071, Val Loss: 0.0092\n",
      "Epoch [733/1000], Loss: 0.0071, Val Loss: 0.0092\n",
      "Epoch [734/1000], Loss: 0.0071, Val Loss: 0.0092\n",
      "Epoch [735/1000], Loss: 0.0071, Val Loss: 0.0092\n",
      "Epoch [736/1000], Loss: 0.0071, Val Loss: 0.0092\n",
      "Epoch [737/1000], Loss: 0.0071, Val Loss: 0.0092\n",
      "Epoch [738/1000], Loss: 0.0071, Val Loss: 0.0092\n",
      "Epoch [739/1000], Loss: 0.0071, Val Loss: 0.0092\n",
      "Epoch [740/1000], Loss: 0.0071, Val Loss: 0.0092\n",
      "Epoch [741/1000], Loss: 0.0071, Val Loss: 0.0092\n",
      "Epoch [742/1000], Loss: 0.0071, Val Loss: 0.0092\n",
      "Epoch [743/1000], Loss: 0.0071, Val Loss: 0.0092\n",
      "Epoch [744/1000], Loss: 0.0071, Val Loss: 0.0092\n",
      "Epoch [745/1000], Loss: 0.0071, Val Loss: 0.0091\n",
      "Epoch [746/1000], Loss: 0.0071, Val Loss: 0.0091\n",
      "Epoch [747/1000], Loss: 0.0071, Val Loss: 0.0092\n",
      "Epoch [748/1000], Loss: 0.0071, Val Loss: 0.0091\n",
      "Epoch [749/1000], Loss: 0.0071, Val Loss: 0.0092\n",
      "Epoch [750/1000], Loss: 0.0071, Val Loss: 0.0091\n",
      "Epoch [751/1000], Loss: 0.0071, Val Loss: 0.0092\n",
      "Epoch [752/1000], Loss: 0.0071, Val Loss: 0.0091\n",
      "Epoch [753/1000], Loss: 0.0070, Val Loss: 0.0092\n",
      "Epoch [754/1000], Loss: 0.0071, Val Loss: 0.0091\n",
      "Epoch [755/1000], Loss: 0.0070, Val Loss: 0.0091\n",
      "Epoch [756/1000], Loss: 0.0070, Val Loss: 0.0091\n",
      "Epoch [757/1000], Loss: 0.0070, Val Loss: 0.0091\n",
      "Epoch [758/1000], Loss: 0.0070, Val Loss: 0.0091\n",
      "Epoch [759/1000], Loss: 0.0070, Val Loss: 0.0091\n",
      "Epoch [760/1000], Loss: 0.0070, Val Loss: 0.0091\n",
      "Epoch [761/1000], Loss: 0.0070, Val Loss: 0.0091\n",
      "Epoch [762/1000], Loss: 0.0070, Val Loss: 0.0091\n",
      "Epoch [763/1000], Loss: 0.0070, Val Loss: 0.0091\n",
      "Epoch [764/1000], Loss: 0.0070, Val Loss: 0.0091\n",
      "Epoch [765/1000], Loss: 0.0070, Val Loss: 0.0091\n",
      "Epoch [766/1000], Loss: 0.0070, Val Loss: 0.0091\n",
      "Epoch [767/1000], Loss: 0.0070, Val Loss: 0.0090\n",
      "Epoch [768/1000], Loss: 0.0070, Val Loss: 0.0090\n",
      "Epoch [769/1000], Loss: 0.0070, Val Loss: 0.0090\n",
      "Epoch [770/1000], Loss: 0.0070, Val Loss: 0.0090\n",
      "Epoch [771/1000], Loss: 0.0070, Val Loss: 0.0091\n",
      "Epoch [772/1000], Loss: 0.0070, Val Loss: 0.0091\n",
      "Epoch [773/1000], Loss: 0.0070, Val Loss: 0.0091\n",
      "Epoch [774/1000], Loss: 0.0070, Val Loss: 0.0090\n",
      "Epoch [775/1000], Loss: 0.0070, Val Loss: 0.0090\n",
      "Epoch [776/1000], Loss: 0.0070, Val Loss: 0.0091\n",
      "Epoch [777/1000], Loss: 0.0070, Val Loss: 0.0090\n",
      "Epoch [778/1000], Loss: 0.0070, Val Loss: 0.0091\n",
      "Epoch [779/1000], Loss: 0.0070, Val Loss: 0.0091\n",
      "Epoch [780/1000], Loss: 0.0070, Val Loss: 0.0090\n",
      "Epoch [781/1000], Loss: 0.0069, Val Loss: 0.0090\n",
      "Epoch [782/1000], Loss: 0.0070, Val Loss: 0.0090\n",
      "Epoch [783/1000], Loss: 0.0069, Val Loss: 0.0090\n",
      "Epoch [784/1000], Loss: 0.0069, Val Loss: 0.0090\n",
      "Epoch [785/1000], Loss: 0.0069, Val Loss: 0.0090\n",
      "Epoch [786/1000], Loss: 0.0069, Val Loss: 0.0090\n",
      "Epoch [787/1000], Loss: 0.0069, Val Loss: 0.0090\n",
      "Epoch [788/1000], Loss: 0.0069, Val Loss: 0.0090\n",
      "Epoch [789/1000], Loss: 0.0069, Val Loss: 0.0090\n",
      "Epoch [790/1000], Loss: 0.0069, Val Loss: 0.0090\n",
      "Epoch [791/1000], Loss: 0.0069, Val Loss: 0.0090\n",
      "Epoch [792/1000], Loss: 0.0069, Val Loss: 0.0089\n",
      "Epoch [793/1000], Loss: 0.0069, Val Loss: 0.0089\n",
      "Epoch [794/1000], Loss: 0.0069, Val Loss: 0.0090\n",
      "Epoch [795/1000], Loss: 0.0069, Val Loss: 0.0089\n",
      "Epoch [796/1000], Loss: 0.0069, Val Loss: 0.0089\n",
      "Epoch [797/1000], Loss: 0.0069, Val Loss: 0.0090\n",
      "Epoch [798/1000], Loss: 0.0069, Val Loss: 0.0089\n",
      "Epoch [799/1000], Loss: 0.0069, Val Loss: 0.0090\n",
      "Epoch [800/1000], Loss: 0.0069, Val Loss: 0.0089\n",
      "Epoch [801/1000], Loss: 0.0068, Val Loss: 0.0089\n",
      "Epoch [802/1000], Loss: 0.0069, Val Loss: 0.0089\n",
      "Epoch [803/1000], Loss: 0.0068, Val Loss: 0.0089\n",
      "Epoch [804/1000], Loss: 0.0068, Val Loss: 0.0089\n",
      "Epoch [805/1000], Loss: 0.0068, Val Loss: 0.0089\n",
      "Epoch [806/1000], Loss: 0.0069, Val Loss: 0.0089\n",
      "Epoch [807/1000], Loss: 0.0068, Val Loss: 0.0089\n",
      "Epoch [808/1000], Loss: 0.0068, Val Loss: 0.0089\n",
      "Epoch [809/1000], Loss: 0.0068, Val Loss: 0.0089\n",
      "Epoch [810/1000], Loss: 0.0068, Val Loss: 0.0089\n",
      "Epoch [811/1000], Loss: 0.0068, Val Loss: 0.0089\n",
      "Epoch [812/1000], Loss: 0.0068, Val Loss: 0.0089\n",
      "Epoch [813/1000], Loss: 0.0068, Val Loss: 0.0089\n",
      "Epoch [814/1000], Loss: 0.0068, Val Loss: 0.0089\n",
      "Epoch [815/1000], Loss: 0.0068, Val Loss: 0.0089\n",
      "Epoch [816/1000], Loss: 0.0068, Val Loss: 0.0089\n",
      "Epoch [817/1000], Loss: 0.0068, Val Loss: 0.0088\n",
      "Epoch [818/1000], Loss: 0.0068, Val Loss: 0.0089\n",
      "Epoch [819/1000], Loss: 0.0068, Val Loss: 0.0088\n",
      "Epoch [820/1000], Loss: 0.0068, Val Loss: 0.0088\n",
      "Epoch [821/1000], Loss: 0.0068, Val Loss: 0.0088\n",
      "Epoch [822/1000], Loss: 0.0068, Val Loss: 0.0088\n",
      "Epoch [823/1000], Loss: 0.0068, Val Loss: 0.0088\n",
      "Epoch [824/1000], Loss: 0.0068, Val Loss: 0.0088\n",
      "Epoch [825/1000], Loss: 0.0067, Val Loss: 0.0089\n",
      "Epoch [826/1000], Loss: 0.0068, Val Loss: 0.0088\n",
      "Epoch [827/1000], Loss: 0.0067, Val Loss: 0.0088\n",
      "Epoch [828/1000], Loss: 0.0067, Val Loss: 0.0088\n",
      "Epoch [829/1000], Loss: 0.0067, Val Loss: 0.0088\n",
      "Epoch [830/1000], Loss: 0.0067, Val Loss: 0.0088\n",
      "Epoch [831/1000], Loss: 0.0067, Val Loss: 0.0088\n",
      "Epoch [832/1000], Loss: 0.0067, Val Loss: 0.0088\n",
      "Epoch [833/1000], Loss: 0.0067, Val Loss: 0.0088\n",
      "Epoch [834/1000], Loss: 0.0067, Val Loss: 0.0088\n",
      "Epoch [835/1000], Loss: 0.0067, Val Loss: 0.0088\n",
      "Epoch [836/1000], Loss: 0.0067, Val Loss: 0.0088\n",
      "Epoch [837/1000], Loss: 0.0067, Val Loss: 0.0088\n",
      "Epoch [838/1000], Loss: 0.0067, Val Loss: 0.0087\n",
      "Epoch [839/1000], Loss: 0.0067, Val Loss: 0.0087\n",
      "Epoch [840/1000], Loss: 0.0067, Val Loss: 0.0088\n",
      "Epoch [841/1000], Loss: 0.0067, Val Loss: 0.0088\n",
      "Epoch [842/1000], Loss: 0.0067, Val Loss: 0.0087\n",
      "Epoch [843/1000], Loss: 0.0067, Val Loss: 0.0087\n",
      "Epoch [844/1000], Loss: 0.0067, Val Loss: 0.0087\n",
      "Epoch [845/1000], Loss: 0.0067, Val Loss: 0.0087\n",
      "Epoch [846/1000], Loss: 0.0067, Val Loss: 0.0088\n",
      "Epoch [847/1000], Loss: 0.0067, Val Loss: 0.0087\n",
      "Epoch [848/1000], Loss: 0.0067, Val Loss: 0.0087\n",
      "Epoch [849/1000], Loss: 0.0066, Val Loss: 0.0087\n",
      "Epoch [850/1000], Loss: 0.0067, Val Loss: 0.0088\n",
      "Epoch [851/1000], Loss: 0.0067, Val Loss: 0.0087\n",
      "Epoch [852/1000], Loss: 0.0067, Val Loss: 0.0087\n",
      "Epoch [853/1000], Loss: 0.0066, Val Loss: 0.0087\n",
      "Epoch [854/1000], Loss: 0.0066, Val Loss: 0.0088\n",
      "Epoch [855/1000], Loss: 0.0067, Val Loss: 0.0087\n",
      "Epoch [856/1000], Loss: 0.0066, Val Loss: 0.0087\n",
      "Epoch [857/1000], Loss: 0.0066, Val Loss: 0.0087\n",
      "Epoch [858/1000], Loss: 0.0066, Val Loss: 0.0087\n",
      "Epoch [859/1000], Loss: 0.0066, Val Loss: 0.0087\n",
      "Epoch [860/1000], Loss: 0.0066, Val Loss: 0.0087\n",
      "Epoch [861/1000], Loss: 0.0066, Val Loss: 0.0086\n",
      "Epoch [862/1000], Loss: 0.0066, Val Loss: 0.0087\n",
      "Epoch [863/1000], Loss: 0.0066, Val Loss: 0.0087\n",
      "Epoch [864/1000], Loss: 0.0066, Val Loss: 0.0086\n",
      "Epoch [865/1000], Loss: 0.0066, Val Loss: 0.0086\n",
      "Epoch [866/1000], Loss: 0.0066, Val Loss: 0.0087\n",
      "Epoch [867/1000], Loss: 0.0066, Val Loss: 0.0086\n",
      "Epoch [868/1000], Loss: 0.0066, Val Loss: 0.0087\n",
      "Epoch [869/1000], Loss: 0.0066, Val Loss: 0.0087\n",
      "Epoch [870/1000], Loss: 0.0066, Val Loss: 0.0086\n",
      "Epoch [871/1000], Loss: 0.0066, Val Loss: 0.0086\n",
      "Epoch [872/1000], Loss: 0.0066, Val Loss: 0.0087\n",
      "Epoch [873/1000], Loss: 0.0066, Val Loss: 0.0086\n",
      "Epoch [874/1000], Loss: 0.0066, Val Loss: 0.0087\n",
      "Epoch [875/1000], Loss: 0.0065, Val Loss: 0.0086\n",
      "Epoch [876/1000], Loss: 0.0066, Val Loss: 0.0086\n",
      "Epoch [877/1000], Loss: 0.0065, Val Loss: 0.0086\n",
      "Epoch [878/1000], Loss: 0.0065, Val Loss: 0.0086\n",
      "Epoch [879/1000], Loss: 0.0065, Val Loss: 0.0086\n",
      "Epoch [880/1000], Loss: 0.0065, Val Loss: 0.0086\n",
      "Epoch [881/1000], Loss: 0.0065, Val Loss: 0.0086\n",
      "Epoch [882/1000], Loss: 0.0065, Val Loss: 0.0086\n",
      "Epoch [883/1000], Loss: 0.0065, Val Loss: 0.0086\n",
      "Epoch [884/1000], Loss: 0.0065, Val Loss: 0.0086\n",
      "Epoch [885/1000], Loss: 0.0065, Val Loss: 0.0086\n",
      "Epoch [886/1000], Loss: 0.0065, Val Loss: 0.0086\n",
      "Epoch [887/1000], Loss: 0.0065, Val Loss: 0.0086\n",
      "Epoch [888/1000], Loss: 0.0065, Val Loss: 0.0086\n",
      "Epoch [889/1000], Loss: 0.0065, Val Loss: 0.0086\n",
      "Epoch [890/1000], Loss: 0.0065, Val Loss: 0.0085\n",
      "Epoch [891/1000], Loss: 0.0065, Val Loss: 0.0085\n",
      "Epoch [892/1000], Loss: 0.0065, Val Loss: 0.0086\n",
      "Epoch [893/1000], Loss: 0.0065, Val Loss: 0.0086\n",
      "Epoch [894/1000], Loss: 0.0065, Val Loss: 0.0085\n",
      "Epoch [895/1000], Loss: 0.0065, Val Loss: 0.0085\n",
      "Epoch [896/1000], Loss: 0.0065, Val Loss: 0.0085\n",
      "Epoch [897/1000], Loss: 0.0065, Val Loss: 0.0085\n",
      "Epoch [898/1000], Loss: 0.0064, Val Loss: 0.0086\n",
      "Epoch [899/1000], Loss: 0.0065, Val Loss: 0.0085\n",
      "Epoch [900/1000], Loss: 0.0064, Val Loss: 0.0086\n",
      "Epoch [901/1000], Loss: 0.0064, Val Loss: 0.0085\n",
      "Epoch [902/1000], Loss: 0.0064, Val Loss: 0.0085\n",
      "Epoch [903/1000], Loss: 0.0064, Val Loss: 0.0085\n",
      "Epoch [904/1000], Loss: 0.0064, Val Loss: 0.0085\n",
      "Epoch [905/1000], Loss: 0.0065, Val Loss: 0.0085\n",
      "Epoch [906/1000], Loss: 0.0064, Val Loss: 0.0085\n",
      "Epoch [907/1000], Loss: 0.0064, Val Loss: 0.0086\n",
      "Epoch [908/1000], Loss: 0.0064, Val Loss: 0.0085\n",
      "Epoch [909/1000], Loss: 0.0064, Val Loss: 0.0085\n",
      "Epoch [910/1000], Loss: 0.0064, Val Loss: 0.0085\n",
      "Epoch [911/1000], Loss: 0.0065, Val Loss: 0.0085\n",
      "Epoch [912/1000], Loss: 0.0064, Val Loss: 0.0085\n",
      "Epoch [913/1000], Loss: 0.0064, Val Loss: 0.0085\n",
      "Epoch [914/1000], Loss: 0.0064, Val Loss: 0.0085\n",
      "Epoch [915/1000], Loss: 0.0064, Val Loss: 0.0085\n",
      "Epoch [916/1000], Loss: 0.0064, Val Loss: 0.0084\n",
      "Epoch [917/1000], Loss: 0.0064, Val Loss: 0.0084\n",
      "Epoch [918/1000], Loss: 0.0064, Val Loss: 0.0085\n",
      "Epoch [919/1000], Loss: 0.0064, Val Loss: 0.0085\n",
      "Epoch [920/1000], Loss: 0.0064, Val Loss: 0.0084\n",
      "Epoch [921/1000], Loss: 0.0064, Val Loss: 0.0085\n",
      "Epoch [922/1000], Loss: 0.0064, Val Loss: 0.0085\n",
      "Epoch [923/1000], Loss: 0.0064, Val Loss: 0.0085\n",
      "Epoch [924/1000], Loss: 0.0064, Val Loss: 0.0085\n",
      "Epoch [925/1000], Loss: 0.0064, Val Loss: 0.0084\n",
      "Epoch [926/1000], Loss: 0.0064, Val Loss: 0.0085\n",
      "Epoch [927/1000], Loss: 0.0064, Val Loss: 0.0085\n",
      "Epoch [928/1000], Loss: 0.0064, Val Loss: 0.0084\n",
      "Epoch [929/1000], Loss: 0.0063, Val Loss: 0.0084\n",
      "Epoch [930/1000], Loss: 0.0063, Val Loss: 0.0084\n",
      "Early stopping triggered. Restoring best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fm/3vzr0bd54y38wk6x2_8f9xlm0000gn/T/ipykernel_58530/2012633839.py:441: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  reverse_model.load_state_dict(torch.load('best_model.pth'))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Define a function to tokenize a formula\n",
    "def tokenize_formula(formula):\n",
    "    token_pattern = r\"[a-zA-Z_][a-zA-Z0-9_]*|[()+\\-*/]|\\d+\\.?\\d*\"\n",
    "    tokens = re.findall(token_pattern, formula)\n",
    "    return tokens\n",
    "\n",
    "@dataclass\n",
    "class tNetConfig:\n",
    "    num_vars: int\n",
    "    embedding_size: int\n",
    "\n",
    "class tNet(nn.Module):\n",
    "    def __init__(self, config: tNetConfig):\n",
    "        super(tNet, self).__init__()\n",
    "\n",
    "        self.config = config\n",
    "        self.num_vars = config.num_vars\n",
    "        self.n_embd = config.embedding_size\n",
    "\n",
    "        self.activation_func = F.relu\n",
    "\n",
    "        self.conv1 = nn.Conv1d(self.num_vars + 1, self.n_embd, 1)\n",
    "        self.conv2 = nn.Conv1d(self.n_embd, 2 * self.n_embd, 1)\n",
    "        self.conv3 = nn.Conv1d(2 * self.n_embd, 4 * self.n_embd, 1)\n",
    "\n",
    "        self.fc1 = nn.Linear(4 * self.n_embd, 2 * self.n_embd)\n",
    "        self.fc2 = nn.Linear(2 * self.n_embd, self.n_embd)\n",
    "\n",
    "        self.input_batch_norm = nn.GroupNorm(1, self.num_vars + 1)\n",
    "\n",
    "        self.bn1 = nn.GroupNorm(1, self.n_embd)\n",
    "        self.bn2 = nn.GroupNorm(1, 2 * self.n_embd)\n",
    "        self.bn3 = nn.GroupNorm(1, 4 * self.n_embd)\n",
    "        self.bn4 = nn.GroupNorm(1, 2 * self.n_embd)\n",
    "        self.bn5 = nn.GroupNorm(1, self.n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: [batch, #features + 1, #points]\n",
    "        :return: logit: [batch, embedding_size]\n",
    "        \"\"\"\n",
    "        x = self.input_batch_norm(x)\n",
    "        x = self.activation_func(self.bn1(self.conv1(x)))\n",
    "        x = self.activation_func(self.bn2(self.conv2(x)))\n",
    "        x = self.activation_func(self.bn3(self.conv3(x)))\n",
    "        x, _ = torch.max(x, dim=2)  # global max pooling\n",
    "        assert x.size(1) == 4 * self.n_embd\n",
    "\n",
    "        x = self.activation_func(self.bn4(self.fc1(x)))\n",
    "        x = self.activation_func(self.bn5(self.fc2(x)))\n",
    "\n",
    "        return x\n",
    "\n",
    "class TextDiffusionModel:\n",
    "    def __init__(self, vocab_size, seq_len, device=\"cpu\"):\n",
    "        \"\"\"\n",
    "        Initialize the text diffusion model.\n",
    "\n",
    "        Parameters:\n",
    "        - vocab_size: Size of the vocabulary (number of unique tokens).\n",
    "        - seq_len: Length of the token sequence.\n",
    "        - device: Device to use (\"cpu\" or \"cuda\").\n",
    "        \"\"\"\n",
    "        self.vocab_size = vocab_size\n",
    "        self.seq_len = seq_len\n",
    "        self.device = device\n",
    "        # self.noise_schedule = torch.linspace(0.01, 0.1, steps=1000).to(device)  # Noise variance per timestep\n",
    "        self.noise_schedule = torch.linspace(1e-4, 2e-2, steps=1000).to(device)  # Noise variance per timestep\n",
    "\n",
    "    def add_noise(self, tokens, t):\n",
    "        \"\"\"\n",
    "        Add noise to a sequence of tokens based on timestep t.\n",
    "\n",
    "        Parameters:\n",
    "        - tokens: A tensor of token indices with shape (batch_size, seq_len).\n",
    "        - t: A tensor of timesteps with shape (batch_size,).\n",
    "\n",
    "        Returns:\n",
    "        - noisy_tokens: The tokens with added noise.\n",
    "        - noise: The noise added to the tokens.\n",
    "        \"\"\"\n",
    "        noise_std = self.noise_schedule[t].view(-1, 1, 1)  # Shape: (batch_size, 1, 1)\n",
    "\n",
    "        # Convert tokens to one-hot vectors\n",
    "        one_hot = F.one_hot(tokens.long(), num_classes=self.vocab_size).float()\n",
    "        \n",
    "        # Add Gaussian noise to the one-hot vectors\n",
    "        noise = torch.randn_like(one_hot) * noise_std\n",
    "        noisy_one_hot = one_hot + noise\n",
    "\n",
    "        # Compute softmax to normalize the noisy one-hot vectors\n",
    "        noisy_tokens = F.softmax(noisy_one_hot, dim=-1)\n",
    "        return noisy_tokens, noise\n",
    "\n",
    "    def sample_from_noisy_tokens(self, noisy_tokens):\n",
    "        \"\"\"\n",
    "        Sample discrete tokens from the noisy token distribution.\n",
    "\n",
    "        Parameters:\n",
    "        - noisy_tokens: A tensor of noisy token distributions with shape (batch_size, seq_len, vocab_size).\n",
    "\n",
    "        Returns:\n",
    "        - sampled_tokens: A tensor of sampled token indices with shape (batch_size, seq_len).\n",
    "        \"\"\"\n",
    "        sampled_tokens = torch.argmax(noisy_tokens, dim=-1)\n",
    "        return sampled_tokens\n",
    "\n",
    "class ReverseProcessModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, num_vars, seq_len):\n",
    "        super(ReverseProcessModel, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.num_vars = num_vars\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "        # Calculate the correct input size for fc1\n",
    "        input_size = embedding_size + (seq_len * vocab_size) + 1  # embeddings + noisy_tokens + timestep\n",
    "\n",
    "        # Define layers for the reverse process model\n",
    "        self.fc1 = nn.Linear(input_size, 512)  # Adjusted input size\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, seq_len * vocab_size)  # Output for all tokens in the sequence\n",
    "\n",
    "    def forward(self, noisy_tokens, embeddings, t):\n",
    "        \"\"\"\n",
    "        Forward pass for the reverse process model.\n",
    "\n",
    "        :param noisy_tokens: Tensor of noisy tokens with shape [batch_size, seq_len, vocab_size].\n",
    "        :param embeddings: Tensor of embeddings with shape [batch_size, embedding_size].\n",
    "        :param t: Tensor of timesteps with shape [batch_size].\n",
    "        :return: Predicted noise.\n",
    "        \"\"\"\n",
    "        # Flatten noisy tokens to [batch_size, seq_len * vocab_size]\n",
    "        noisy_tokens_flat = noisy_tokens.view(noisy_tokens.size(0), -1)\n",
    "\n",
    "        # Concatenate embeddings, flattened noisy tokens, and timestep information\n",
    "        timestep_embedding = torch.cat([embeddings, noisy_tokens_flat, t.unsqueeze(1).float()], dim=-1)\n",
    "        \n",
    "        # Pass through the fully connected layers\n",
    "        x = F.relu(self.fc1(timestep_embedding))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        predicted_noise = self.fc3(x)\n",
    "\n",
    "        # Reshape to [batch_size, seq_len, vocab_size]\n",
    "        predicted_noise = predicted_noise.view(-1, self.seq_len, self.vocab_size)\n",
    "        \n",
    "        return predicted_noise\n",
    "\n",
    "# Main function\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Define the device \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    folder_path = \"data_symbolic_regression/train\"\n",
    "    val_folder_path = \"data_symbolic_regression/val\"\n",
    "\n",
    "    # Load and tokenize formulas from the training set; Convert the data points to a Pytorch tensor\n",
    "    tokenized_formulas = []\n",
    "    points_list = []\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".json\") and not file_name.startswith('properties'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            with open(file_path, \"r\") as file:\n",
    "                data = json.load(file)\n",
    "\n",
    "                formula_human_readable = data.get(\"formula_human_readable\", \"\")\n",
    "                if formula_human_readable:\n",
    "                    tokens = tokenize_formula(formula_human_readable)\n",
    "                    tokenized_formulas.append(tokens)\n",
    "                \n",
    "                points = data.get(\"points\")\n",
    "                if points:\n",
    "                    points_array = np.array([points[\"var_0\"], points[\"var_1\"], points[\"var_2\"], points[\"target\"]])\n",
    "                    points_tensor = torch.tensor(points_array, dtype=torch.float32, device=device).unsqueeze(0)  # Add batch dimension\n",
    "                    points_list.append(points_tensor)\n",
    "                    # Need below line if points_array is transposed\n",
    "                    # points_tensor = torch.tensor(points_array, dtype=torch.float32, device=device).unsqueeze(0).permute(0, 2, 1)  # Add batch dimension and transpose\n",
    "\n",
    "    # # Create the vocabulary from the tokens\n",
    "    # vocab_mapping = {token: idx for idx, token in enumerate(set(t for tokens in tokenized_formulas for t in tokens))}\n",
    "    # vocab_size = len(vocab_mapping)\n",
    "\n",
    "    # token_sequences = [[vocab_mapping[token] for token in tokens] for tokens in tokenized_formulas]\n",
    "\n",
    "    # formula_lengths = [len(tokens) for tokens in tokenized_formulas]\n",
    "    # seq_len = int(np.percentile(formula_lengths, 95))  # Use 95th percentile\n",
    "\n",
    "    val_tokenized_formulas = []\n",
    "    val_points_list = []\n",
    "\n",
    "    # Create the vocabulary from the tokens\n",
    "    for file_name in os.listdir(val_folder_path):\n",
    "        if file_name.endswith(\".json\") and not file_name.startswith('properties'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            with open(file_path, \"r\") as file:\n",
    "                val_data = json.load(file)\n",
    "\n",
    "                val_formula_human_readable = val_data.get(\"formula_human_readable\", \"\")\n",
    "                if val_formula_human_readable:\n",
    "                    val_tokens = tokenize_formula(val_formula_human_readable)\n",
    "                    val_tokenized_formulas.append(val_tokens)\n",
    "                \n",
    "                val_points = val_data.get(\"points\")\n",
    "                if val_points:\n",
    "                    val_points_array = np.array([val_points[\"var_0\"], val_points[\"var_1\"], val_points[\"var_2\"], val_points[\"target\"]])\n",
    "                    val_points_tensor = torch.tensor(val_points_array, dtype=torch.float32, device=device).unsqueeze(0)  # Add batch dimension\n",
    "                    val_points_list.append(val_points_tensor)\n",
    "\n",
    "    vocab_mapping = {token: idx for idx, token in enumerate(set(t for tokens in tokenized_formulas for t in tokens))}\n",
    "    vocab_size = len(vocab_mapping)\n",
    "\n",
    "    # Define EOS and PAD token IDs\n",
    "    eos_token_id = vocab_size - 1  # Assuming the last ID in the vocabulary is for EOS\n",
    "    pad_token_id = vocab_size - 2  # Assuming the second-to-last ID in the vocabulary is for PAD\n",
    "\n",
    "    # Add EOS and PAD tokens to vocab_mapping if not already present\n",
    "    if eos_token_id not in vocab_mapping.values():\n",
    "        vocab_mapping['<EOS>'] = eos_token_id\n",
    "    if pad_token_id not in vocab_mapping.values():\n",
    "        vocab_mapping['<PAD>'] = pad_token_id\n",
    "\n",
    "    # Tokenize and map tokens to vocabulary indices\n",
    "    token_sequences = [[vocab_mapping.get(token, pad_token_id) for token in tokens] for tokens in tokenized_formulas]\n",
    "\n",
    "    # Calculate sequence length based on the 95th percentile of formula lengths\n",
    "    formula_lengths = [len(tokens) for tokens in tokenized_formulas]\n",
    "    seq_len = int(np.percentile(formula_lengths, 95))  # Use 95th percentile\n",
    "    batch_size = 100  # Example batch size\n",
    "\n",
    "    # Pad or truncate sequences to seq_len, adding EOS token last\n",
    "    token_sequences = [\n",
    "        seq[:seq_len] + [pad_token_id] * max(0, seq_len - len(seq)) + [eos_token_id] \n",
    "        if len(seq) < seq_len else seq[:seq_len] + [eos_token_id]  # Add EOS token at the end after padding\n",
    "        for seq in token_sequences\n",
    "    ]\n",
    "\n",
    "    # Convert to tensor\n",
    "    token_tensor = torch.tensor(token_sequences, device=device)\n",
    "\n",
    "    # Initialize the model\n",
    "    diffusion_model = TextDiffusionModel(vocab_size, seq_len, device=device)\n",
    "    \n",
    "    # Pad or truncate sequences to seq_len\n",
    "    token_sequences = [seq[:seq_len] + [0] * max(0, seq_len - len(seq)) for seq in token_sequences]\n",
    "    token_tensor = torch.tensor(token_sequences, device=device)\n",
    "\n",
    "    val_vocab_mapping = {token: idx for idx, token in enumerate(set(t for tokens in val_tokenized_formulas for t in tokens))}\n",
    "    val_vocab_size = len(val_vocab_mapping)\n",
    "\n",
    "    # Add EOS and PAD tokens to vocab_mapping if not already present\n",
    "    if eos_token_id not in val_vocab_mapping.values():\n",
    "        val_vocab_mapping['<EOS>'] = eos_token_id\n",
    "    if pad_token_id not in val_vocab_mapping.values():\n",
    "        val_vocab_mapping['<PAD>'] = pad_token_id\n",
    "\n",
    "    # Tokenize and map tokens to vocabulary indices\n",
    "    val_token_sequences = [[val_vocab_mapping.get(token, pad_token_id) for token in tokens] for tokens in val_tokenized_formulas]\n",
    "\n",
    "    # Calculate sequence length based on the 95th percentile of formula lengths\n",
    "    val_formula_lengths = [len(tokens) for tokens in val_tokenized_formulas]\n",
    "    val_seq_len = int(np.percentile(val_formula_lengths, 95))  # Use 95th percentile\n",
    "\n",
    "    # Pad or truncate sequences to seq_len, adding EOS token last\n",
    "    val_token_sequences = [\n",
    "        seq[:seq_len] + [pad_token_id] * max(0, seq_len - len(seq)) + [eos_token_id] \n",
    "        if len(seq) < seq_len else seq[:seq_len] + [eos_token_id]  # Add EOS token at the end after padding\n",
    "        for seq in val_token_sequences\n",
    "    ]\n",
    "\n",
    "    # Convert to tensor\n",
    "    val_token_tensor = torch.tensor(val_token_sequences, device=device)\n",
    "\n",
    "    # Initialize the model\n",
    "    diffusion_model = TextDiffusionModel(vocab_size, seq_len, device=device)\n",
    "    \n",
    "    # Pad or truncate sequences to seq_len\n",
    "    val_token_sequences = [seq[:seq_len] + [0] * max(0, seq_len - len(seq)) for seq in val_token_sequences]\n",
    "    val_token_tensor = torch.tensor(val_token_sequences, device=device)\n",
    "\n",
    "    # # Add EOS token and pad sequences\n",
    "    # # Define EOS and PAD token IDs\n",
    "    # eos_token_id = vocab_size - 1  # Assuming the last ID in the vocabulary is for EOS\n",
    "    # pad_token_id = vocab_size - 2  # Assuming the second-to-last ID is for PAD\n",
    "\n",
    "    # # Add EOS token and pad sequences\n",
    "    # max_seq_len = max(len(seq) for seq in token_tensor)\n",
    "    # padded_token_tensor = []\n",
    "    # for seq in token_tensor:\n",
    "    #     seq = torch.cat([seq, torch.tensor([eos_token_id])])  # Add EOS token\n",
    "    #     padding = torch.tensor([pad_token_id] * (max_seq_len - len(seq)))  # Add padding\n",
    "    #     seq = torch.cat([seq, padding])  # Concatenate the sequence and padding\n",
    "    #     padded_token_tensor.append(seq)\n",
    "\n",
    "    # # Convert to a tensor\n",
    "    # token_tensor = torch.stack(padded_token_tensor)\n",
    "\n",
    "    # Choose random timesteps for each sequence\n",
    "    t = torch.randint(0, 1000, (len(token_tensor),), device=device)\n",
    "\n",
    "    # Add noise to the tokens\n",
    "    noisy_tokens, noise = diffusion_model.add_noise(token_tensor, t)\n",
    "\n",
    "    # Sample from noisy tokens\n",
    "    sampled_tokens = diffusion_model.sample_from_noisy_tokens(noisy_tokens)\n",
    "\n",
    "    # Configuration for tNet\n",
    "    num_vars = 3\n",
    "    embedding_size = 128  # Example embedding size\n",
    "    config = tNetConfig(num_vars=num_vars, embedding_size=embedding_size)\n",
    "\n",
    "    # Instantiate the model\n",
    "    tnet_model = tNet(config)\n",
    "\n",
    "    # Input: batch_size x (num_vars + 1) x num_points\n",
    "    batch_size = 1\n",
    "\n",
    "    # Generate embeddings\n",
    "    # input_tensor = torch.rand(batch_size, num_vars, 100)\n",
    "\n",
    "    output_embeddings = []\n",
    "    for pt in points_list:\n",
    "        output_embedding = tnet_model(pt)\n",
    "        output_embeddings.append(output_embedding)\n",
    "    \n",
    "    points_tensors = torch.cat(points_list, dim=0)\n",
    "    \n",
    "    output_embeddings_tensor = torch.cat(output_embeddings, dim=0)\n",
    "    # Print the output\n",
    "    print(\"Input shape:\", points_tensors.shape)\n",
    "    print(\"Output shape:\", output_embeddings_tensor.shape)\n",
    "\n",
    "    # Print results\n",
    "    print(\"Original Tokens shape:\", token_tensor.shape)\n",
    "    print(\"Noisy Tokens (probabilities) shape:\", noisy_tokens.shape)\n",
    "    print(\"Sampled Tokens shape:\", sampled_tokens.shape)\n",
    "\n",
    "    # Initialize reverse model (denoiser)\n",
    "    reverse_model = ReverseProcessModel(vocab_size, embedding_size, num_vars, seq_len).to(device)\n",
    "\n",
    "    # Cross-entropy loss function\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Train the reverse process model\n",
    "    epochs = 1000  # Define the number of epochs for training\n",
    "    batch_size = 100  # Example batch size\n",
    "\n",
    "    # Optimizer for the reverse process model\n",
    "    optimizer = torch.optim.Adam(reverse_model.parameters(), lr=1e-4)\n",
    "\n",
    "    # Early stopping parameters\n",
    "    patience = 10\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        reverse_model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        # Training Phase\n",
    "        for batch_idx in range(0, len(points_list), batch_size):\n",
    "            batch_points = points_list[batch_idx:batch_idx + batch_size]\n",
    "            batch_token_tensor = token_tensor[batch_idx:batch_idx + batch_size]\n",
    "\n",
    "            # Random timesteps\n",
    "            t_batch = torch.randint(0, 1000, (len(batch_points),), device=device)\n",
    "\n",
    "            # Add noise\n",
    "            noisy_tokens, _ = diffusion_model.add_noise(batch_token_tensor, t_batch)\n",
    "\n",
    "            # Get embeddings\n",
    "            batch_embeddings = [tnet_model(pt) for pt in batch_points]\n",
    "            embeddings_tensor = torch.cat(batch_embeddings, dim=0)\n",
    "\n",
    "            # Predict logits\n",
    "            logits = reverse_model(noisy_tokens, embeddings_tensor, t_batch)\n",
    "\n",
    "            # Reshape logits and target tokens for CrossEntropyLoss\n",
    "            logits_flat = logits.view(-1, vocab_size)\n",
    "            target_tokens = batch_token_tensor.view(-1)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_fn(logits_flat, target_tokens)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation Phase\n",
    "        reverse_model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for val_batch_idx in range(0, len(val_points_list), batch_size):\n",
    "                val_batch_points = val_points_list[val_batch_idx:val_batch_idx + batch_size]\n",
    "                val_batch_token_tensor = val_token_tensor[val_batch_idx:val_batch_idx + batch_size]\n",
    "\n",
    "                val_t_batch = torch.randint(0, 1000, (len(val_batch_points),), device=device)\n",
    "\n",
    "                val_noisy_tokens, _ = diffusion_model.add_noise(val_batch_token_tensor, val_t_batch)\n",
    "\n",
    "                val_embeddings = [tnet_model(pt) for pt in val_batch_points]\n",
    "                val_embeddings_tensor = torch.cat(val_embeddings, dim=0)\n",
    "\n",
    "                val_logits = reverse_model(val_noisy_tokens, val_embeddings_tensor, val_t_batch)\n",
    "                val_logits_flat = val_logits.view(-1, vocab_size)\n",
    "                val_target_tokens = val_batch_token_tensor.view(-1)\n",
    "\n",
    "                val_loss += loss_fn(val_logits_flat, val_target_tokens).item()\n",
    "\n",
    "        val_loss /= len(val_points_list)\n",
    "\n",
    "        # Print progress\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {total_loss / len(points_list):.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Early stopping logic\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(reverse_model.state_dict(), 'best_model.pth')  # Save the best model\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stopping triggered. Restoring best model...\")\n",
    "            reverse_model.load_state_dict(torch.load('best_model.pth'))\n",
    "            break\n",
    "\n",
    "    # for epoch in range(epochs):\n",
    "    #     reverse_model.train()\n",
    "        \n",
    "    #     total_loss = 0\n",
    "    #     for batch_idx in range(0, len(points_list), batch_size):\n",
    "    #         # Select batch of noisy tokens and corresponding points\n",
    "    #         batch_points = points_list[batch_idx:batch_idx + batch_size]\n",
    "    #         batch_token_tensor = token_tensor[batch_idx:batch_idx + batch_size]\n",
    "            \n",
    "    #         # Choose random timesteps for the batch\n",
    "    #         t_batch = torch.randint(0, 1000, (len(batch_points),), device=device)\n",
    "            \n",
    "    #         # Add noise to the tokens (forward diffusion)\n",
    "    #         noisy_tokens, _ = diffusion_model.add_noise(batch_token_tensor, t_batch)\n",
    "            \n",
    "    #         # Get embeddings from tNet model\n",
    "    #         batch_embeddings = []\n",
    "    #         for pt in batch_points:\n",
    "    #             embedding = tnet_model(pt)\n",
    "    #             batch_embeddings.append(embedding)\n",
    "            \n",
    "    #         embeddings_tensor = torch.cat(batch_embeddings, dim=0)\n",
    "\n",
    "    #         # Pass noisy tokens, embeddings, and timestep through reverse model to predict logits\n",
    "    #         logits = reverse_model(noisy_tokens, embeddings_tensor, t_batch)\n",
    "\n",
    "        #     # Reshape logits and target tokens for CrossEntropyLoss\n",
    "        #     # Logits shape: (batch_size, seq_len, vocab_size) -> (batch_size * seq_len, vocab_size)\n",
    "        #     logits_flat = logits.view(-1, vocab_size)\n",
    "\n",
    "        #     # Target tokens shape: (batch_size, seq_len) -> (batch_size * seq_len)\n",
    "        #     target_tokens = batch_token_tensor.view(-1)\n",
    "\n",
    "        #     # Compute cross-entropy loss\n",
    "        #     loss = loss_fn(logits_flat, target_tokens)\n",
    "            \n",
    "        #     # Backpropagate and optimize\n",
    "        #     optimizer.zero_grad()\n",
    "        #     loss.backward()\n",
    "        #     optimizer.step()\n",
    "\n",
    "        #     total_loss += loss.item()\n",
    "\n",
    "        # # Print progress every epoch\n",
    "        # avg_loss = total_loss / len(points_list)\n",
    "        # print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "\n",
    "    # Optimizer for the reverse process model\n",
    "    # optimizer = torch.optim.Adam(reverse_model.parameters(), lr=1e-4)\n",
    "\n",
    "    # # Loss function: MSE between predicted noise and actual noise\n",
    "    # loss_fn = nn.MSELoss()\n",
    "\n",
    "    # # Train the reverse process\n",
    "    # epochs = 100  # Define the number of epochs for training\n",
    "\n",
    "    # for epoch in range(epochs):\n",
    "    #     reverse_model.train()\n",
    "        \n",
    "    #     total_loss = 0\n",
    "    #     for batch_idx in range(0, len(points_list), batch_size):\n",
    "    #         # Select batch of noisy tokens and corresponding points\n",
    "    #         batch_points = points_list[batch_idx:batch_idx + batch_size]\n",
    "    #         batch_token_tensor = token_tensor[batch_idx:batch_idx + batch_size]\n",
    "            \n",
    "    #         # Choose random timesteps for the batch\n",
    "    #         t_batch = torch.randint(0, 1000, (len(batch_points),), device=device)\n",
    "            \n",
    "    #         # Add noise to the tokens (forward diffusion)\n",
    "    #         noisy_tokens, noise = diffusion_model.add_noise(batch_token_tensor, t_batch)\n",
    "            \n",
    "    #         # Get embeddings from tNet model\n",
    "    #         batch_embeddings = []\n",
    "    #         for pt in batch_points:\n",
    "    #             embedding = tnet_model(pt)\n",
    "    #             batch_embeddings.append(embedding)\n",
    "            \n",
    "        #     embeddings_tensor = torch.cat(batch_embeddings, dim=0)\n",
    "\n",
    "        #     # Pass noisy tokens, embeddings, and timestep through reverse model to predict noise\n",
    "        #     predicted_noise = reverse_model(noisy_tokens, embeddings_tensor, t_batch)\n",
    "            \n",
    "        #     # Compute loss (MSE between predicted noise and actual noise)\n",
    "        #     loss = loss_fn(predicted_noise, noise.view(-1, vocab_size))\n",
    "            \n",
    "        #     # Backpropagate and optimize\n",
    "        #     optimizer.zero_grad()\n",
    "        #     loss.backward()\n",
    "        #     optimizer.step()\n",
    "\n",
    "        #     total_loss += loss.item()\n",
    "\n",
    "        # # Print progress every epoch\n",
    "        # print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss / len(points_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_diffusion_model(test_folder, diffusion_model, reverse_model, tnet_model, vocab_mapping, seq_len, device):\n",
    "    \"\"\"\n",
    "    Evaluate the diffusion model on the test set.\n",
    "\n",
    "    Parameters:\n",
    "    - test_folder: Path to the folder containing the test JSON files.\n",
    "    - diffusion_model: Instance of the TextDiffusionModel.\n",
    "    - reverse_model: Instance of the ReverseProcessModel.\n",
    "    - tnet_model: Instance of the tNet model for generating embeddings.\n",
    "    - vocab_mapping: Dictionary mapping tokens to indices.\n",
    "    - seq_len: Length of the token sequence.\n",
    "    - device: Device to use (\"cpu\" or \"cuda\").\n",
    "\n",
    "    Returns:\n",
    "    - results: List of tuples (actual_formula, reconstructed_formula).\n",
    "    \"\"\"\n",
    "    reverse_vocab_mapping = {idx: token for token, idx in vocab_mapping.items()}\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for file_name in os.listdir(test_folder):\n",
    "        if file_name.endswith(\".json\") and not file_name.startswith('properties'):\n",
    "            file_path = os.path.join(test_folder, file_name)\n",
    "\n",
    "            with open(file_path, \"r\") as file:\n",
    "                data = json.load(file)\n",
    "\n",
    "                formula_human_readable = data.get(\"formula_human_readable\", \"\")\n",
    "                tokens = tokenize_formula(formula_human_readable)\n",
    "\n",
    "                # Convert tokens to indices\n",
    "                token_indices = [vocab_mapping.get(token, 0) for token in tokens]\n",
    "\n",
    "                # Pad or truncate to seq_len\n",
    "                token_indices = token_indices[:seq_len] + [0] * max(0, seq_len - len(token_indices))\n",
    "                token_tensor = torch.tensor(token_indices, device=device).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "                points = data.get(\"points\")\n",
    "                if points:\n",
    "                    points_array = np.array([points[\"var_0\"], points[\"var_1\"], points[\"var_2\"], points[\"target\"]])\n",
    "                    points_tensor = torch.tensor(points_array, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "                    # Generate embeddings using tNet model\n",
    "                    embedding = tnet_model(points_tensor)\n",
    "\n",
    "                    # Choose random timestep\n",
    "                    t = torch.randint(0, 1000, (1,), device=device)\n",
    "\n",
    "                    # Add noise to the tokens\n",
    "                    noisy_tokens, _ = diffusion_model.add_noise(token_tensor, t)\n",
    "\n",
    "                    # Use reverse model to reconstruct the clean tokens\n",
    "                    reconstructed_noise = reverse_model(noisy_tokens, embedding, t)\n",
    "\n",
    "                    # Convert reconstructed noise to token indices\n",
    "                    reconstructed_tokens = torch.argmax(reconstructed_noise, dim=-1)\n",
    "\n",
    "                    # Ensure reconstructed_tokens is a list\n",
    "                    if reconstructed_tokens.dim() == 2:  # Case: (batch_size, seq_len)\n",
    "                        reconstructed_tokens = reconstructed_tokens.squeeze(0)  # Remove batch dimension\n",
    "                    elif reconstructed_tokens.dim() == 1:  # Case: (seq_len,)\n",
    "                        pass  # Already correct\n",
    "                    else:\n",
    "                        raise ValueError(f\"Unexpected shape for reconstructed_tokens: {reconstructed_tokens.shape}\")\n",
    "\n",
    "                    # Remove padding (0s) and EOS token\n",
    "                    reconstructed_tokens = reconstructed_tokens[reconstructed_tokens != 0]  # Remove PAD tokens\n",
    "                    reconstructed_tokens = reconstructed_tokens[reconstructed_tokens != 22]  # Remove EOS tokens\n",
    "\n",
    "                    # Map token indices back to tokens\n",
    "                    reconstructed_formula = \" \".join(\n",
    "                        reverse_vocab_mapping[idx] if idx in reverse_vocab_mapping else \"<UNK>\" for idx in reconstructed_tokens.tolist()\n",
    "                    )\n",
    "\n",
    "                    actual_formula = \" \".join(tokens)\n",
    "\n",
    "                    results.append((actual_formula, reconstructed_formula))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Formula: ( tanh ( ( var_0 + var_2 ) ) + cos ( var_1 ) )\n",
      "Reconstructed Formula: ( ( ( ( var_1 + var_2 ) ) * sin ( ( ( ) ) pow_2 ) pow_2 pow_2 pow_2 pow_2 pow_2 pow_2\n"
     ]
    }
   ],
   "source": [
    "# Define the device \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "folder_path_test = \"data_symbolic_regression/test\"\n",
    "\n",
    "# Load and tokenize formulas from the training set; Convert the data points to a Pytorch tensor\n",
    "tokenized_formulas_test = []\n",
    "points_list_test = []\n",
    "\n",
    "for file_name in os.listdir(folder_path_test):\n",
    "    if file_name.endswith(\".json\") and not file_name.startswith('properties'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        with open(file_path, \"r\") as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "            formula_human_readable_test = data.get(\"formula_human_readable\", \"\")\n",
    "            if formula_human_readable_test:\n",
    "                tokens_test = tokenize_formula(formula_human_readable_test)\n",
    "                tokenized_formulas_test.append(tokens_test)\n",
    "                \n",
    "            points_test = data.get(\"points\")\n",
    "            if points_test:\n",
    "                points_array_test = np.array([points_test[\"var_0\"], points_test[\"var_1\"], points_test[\"var_2\"], points_test[\"target\"]])\n",
    "                points_tensor_test = torch.tensor(points_array_test, dtype=torch.float32, device=device).unsqueeze(0)  # Add batch dimension\n",
    "                points_list_test.append(points_tensor_test)\n",
    "                # Need below line if points_array is transposed\n",
    "                # points_tensor = torch.tensor(points_array, dtype=torch.float32, device=device).unsqueeze(0).permute(0, 2, 1)  # Add batch dimension and transpose\n",
    "\n",
    "# Create the vocabulary from the tokens\n",
    "# vocab_mapping_test = {token: idx for idx, token in enumerate(set(t for tokens in tokenized_formulas_test for t in tokens))}\n",
    "# vocab_size_test = len(vocab_mapping_test)\n",
    "\n",
    "# token_sequences_test = [[vocab_mapping_test[token] for token in tokens] for tokens in tokenized_formulas_test]\n",
    "\n",
    "# formula_lengths_test = [len(tokens) for tokens in tokenized_formulas_test]\n",
    "# seq_len_test = int(np.percentile(formula_lengths_test, 95))  # Use 95th percentile\n",
    "\n",
    "# # Initialize the model\n",
    "# diffusion_model_test = TextDiffusionModel(vocab_size_test, seq_len_test, device=device)\n",
    "    \n",
    "# # Pad or truncate sequences to seq_len\n",
    "# token_sequences_test = [seq[:seq_len] + [0] * max(0, seq_len - len(seq)) for seq in token_sequences_test]\n",
    "# token_tensor_test = torch.tensor(token_sequences_test, device=device)\n",
    "\n",
    "# # Choose random timesteps for each sequence\n",
    "# t = torch.randint(0, 1000, (len(token_tensor_test),), device=device)\n",
    "\n",
    "# # Configuration for tNet\n",
    "# num_vars_test = 3\n",
    "# embedding_size_test = 32  # Example embedding size\n",
    "# config_test = tNetConfig(num_vars=num_vars_test, embedding_size=embedding_size_test)\n",
    "\n",
    "# # Instantiate the model\n",
    "# tnet_model_test = tNet(config_test)\n",
    "\n",
    "# reverse_model = ReverseProcessModel(vocab_size_test, embedding_size_test, num_vars_test, seq_len_test).to(device)\n",
    "\n",
    "# Evaluate the model\n",
    "results = evaluate_diffusion_model(folder_path_test, diffusion_model, reverse_model, tnet_model, vocab_mapping, seq_len, device)\n",
    "\n",
    "# Display example results\n",
    "example_idx = 1  # Index of the example to display\n",
    "\n",
    "if results:\n",
    "    actual, reconstructed = results[example_idx]\n",
    "    print(f\"Actual Formula: {actual}\")\n",
    "    print(f\"Reconstructed Formula: {reconstructed}\")\n",
    "\n",
    "# Calculate accuracy or similarity score (optional)\n",
    "# accuracies = [accuracy_score(list(actual), list(reconstructed)) for actual, reconstructed in results]\n",
    "# print(f\"Average Reconstruction Accuracy: {np.mean(accuracies):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_diffusion_model(test_folder, diffusion_model, reverse_model, tnet_model, vocab_mapping, seq_len, device):\n",
    "    \"\"\"\n",
    "    Evaluate the diffusion model on the test set.\n",
    "\n",
    "    Parameters:\n",
    "    - test_folder: Path to the folder containing the test JSON files.\n",
    "    - diffusion_model: Instance of the TextDiffusionModel.\n",
    "    - reverse_model: Instance of the ReverseProcessModel.\n",
    "    - tnet_model: Instance of the tNet model for generating embeddings.\n",
    "    - vocab_mapping: Dictionary mapping tokens to indices.\n",
    "    - seq_len: Length of the token sequence.\n",
    "    - device: Device to use (\"cpu\" or \"cuda\").\n",
    "\n",
    "    Returns:\n",
    "    - results: List of tuples (actual_formula, reconstructed_formula).\n",
    "    \"\"\"\n",
    "    reverse_vocab_mapping = {idx: token for token, idx in vocab_mapping.items()}\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for file_name in os.listdir(test_folder):\n",
    "        if file_name.endswith(\".json\") and not file_name.startswith('properties'):\n",
    "            file_path = os.path.join(test_folder, file_name)\n",
    "\n",
    "            with open(file_path, \"r\") as file:\n",
    "                data = json.load(file)\n",
    "\n",
    "                formula_human_readable = data.get(\"formula_human_readable\", \"\")\n",
    "                tokens = tokenize_formula(formula_human_readable)\n",
    "\n",
    "                # Convert tokens to indices\n",
    "                token_indices = [vocab_mapping.get(token, 0) for token in tokens]\n",
    "\n",
    "                # Pad or truncate to seq_len\n",
    "                token_indices = token_indices[:seq_len] + [0] * max(0, seq_len - len(token_indices))\n",
    "                token_tensor = torch.tensor(token_indices, device=device).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "                points = data.get(\"points\")\n",
    "                if points:\n",
    "                    points_array = np.array([points[\"var_0\"], points[\"var_1\"], points[\"var_2\"], points[\"target\"]])\n",
    "                    points_tensor = torch.tensor(points_array, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "                    # Generate embeddings using tNet model\n",
    "                    embedding = tnet_model(points_tensor)\n",
    "\n",
    "                    # Choose random timestep\n",
    "                    t = torch.randint(0, 1000, (1,), device=device)\n",
    "\n",
    "                    # Add noise to the tokens\n",
    "                    noisy_tokens, _ = diffusion_model.add_noise(token_tensor, t)\n",
    "\n",
    "                    # Use reverse model to reconstruct the clean tokens\n",
    "                    reconstructed_noise = reverse_model(noisy_tokens, embedding, t)\n",
    "                    # print(f\"Reconstructed Noise Shape: {reconstructed_noise.shape}\")\n",
    "                    # Convert reconstructed noise to token indices\n",
    "                    # reconstructed_tokens = torch.argmax(reconstructed_noise, dim=-1).squeeze(0)\n",
    "\n",
    "                    # Ensure reconstructed_tokens is a list\n",
    "                    reconstructed_tokens = torch.argmax(reconstructed_noise, dim=-1)\n",
    "                    # print(reconstructed_tokens)\n",
    "                    if reconstructed_tokens.dim() == 2:  # Case: (batch_size, seq_len)\n",
    "                        reconstructed_tokens = reconstructed_tokens.squeeze(0)  # Remove batch dimension\n",
    "                    elif reconstructed_tokens.dim() == 1:  # Case: (seq_len,)\n",
    "                        pass  # Already correct\n",
    "                    else:\n",
    "                        raise ValueError(f\"Unexpected shape for reconstructed_tokens: {reconstructed_tokens.shape}\")\n",
    "\n",
    "                    # print(reconstructed_tokens)\n",
    "                    # Map token indices back to tokens\n",
    "                    reconstructed_formula = \" \".join(\n",
    "                        reverse_vocab_mapping[idx] if idx in reverse_vocab_mapping else \"<UNK>\" for idx in reconstructed_tokens.tolist()\n",
    "                    )\n",
    "                    \n",
    "                    actual_formula = \" \".join(tokens)\n",
    "\n",
    "                    results.append((actual_formula, reconstructed_formula))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Formula: ( ( C_0 + cosh ( var_0 ) ) + ( sin ( var_2 ) + sqrt ( var_1 ) ) )\n",
      "Reconstructed Formula: ( ( ( ( var_1 var_1 + ( ( + + ) ) + * ( var_0 ) ) pow_2 pow_2 pow_2 pow_2 pow_2\n"
     ]
    }
   ],
   "source": [
    "# Define the device \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "folder_path_test = \"data_symbolic_regression/test\"\n",
    "\n",
    "# Load and tokenize formulas from the training set; Convert the data points to a Pytorch tensor\n",
    "tokenized_formulas_test = []\n",
    "points_list_test = []\n",
    "\n",
    "for file_name in os.listdir(folder_path_test):\n",
    "    if file_name.endswith(\".json\") and not file_name.startswith('properties'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        with open(file_path, \"r\") as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "            formula_human_readable_test = data.get(\"formula_human_readable\", \"\")\n",
    "            if formula_human_readable_test:\n",
    "                tokens_test = tokenize_formula(formula_human_readable_test)\n",
    "                tokenized_formulas_test.append(tokens_test)\n",
    "                \n",
    "            points_test = data.get(\"points\")\n",
    "            if points_test:\n",
    "                points_array_test = np.array([points_test[\"var_0\"], points_test[\"var_1\"], points_test[\"var_2\"], points_test[\"target\"]])\n",
    "                points_tensor_test = torch.tensor(points_array_test, dtype=torch.float32, device=device).unsqueeze(0)  # Add batch dimension\n",
    "                points_list_test.append(points_tensor_test)\n",
    "                # Need below line if points_array is transposed\n",
    "                # points_tensor = torch.tensor(points_array, dtype=torch.float32, device=device).unsqueeze(0).permute(0, 2, 1)  # Add batch dimension and transpose\n",
    "\n",
    "# Create the vocabulary from the tokens\n",
    "# vocab_mapping_test = {token: idx for idx, token in enumerate(set(t for tokens in tokenized_formulas_test for t in tokens))}\n",
    "# vocab_size_test = len(vocab_mapping_test)\n",
    "\n",
    "# token_sequences_test = [[vocab_mapping_test[token] for token in tokens] for tokens in tokenized_formulas_test]\n",
    "\n",
    "# formula_lengths_test = [len(tokens) for tokens in tokenized_formulas_test]\n",
    "# seq_len_test = int(np.percentile(formula_lengths_test, 95))  # Use 95th percentile\n",
    "\n",
    "# # Initialize the model\n",
    "# diffusion_model_test = TextDiffusionModel(vocab_size_test, seq_len_test, device=device)\n",
    "    \n",
    "# # Pad or truncate sequences to seq_len\n",
    "# token_sequences_test = [seq[:seq_len] + [0] * max(0, seq_len - len(seq)) for seq in token_sequences_test]\n",
    "# token_tensor_test = torch.tensor(token_sequences_test, device=device)\n",
    "\n",
    "# # Choose random timesteps for each sequence\n",
    "# t = torch.randint(0, 1000, (len(token_tensor_test),), device=device)\n",
    "\n",
    "# # Configuration for tNet\n",
    "# num_vars_test = 3\n",
    "# embedding_size_test = 32  # Example embedding size\n",
    "# config_test = tNetConfig(num_vars=num_vars_test, embedding_size=embedding_size_test)\n",
    "\n",
    "# # Instantiate the model\n",
    "# tnet_model_test = tNet(config_test)\n",
    "\n",
    "# reverse_model = ReverseProcessModel(vocab_size_test, embedding_size_test, num_vars_test, seq_len_test).to(device)\n",
    "\n",
    "# Evaluate the model\n",
    "results = evaluate_diffusion_model(folder_path_test, diffusion_model, reverse_model, tnet_model, vocab_mapping, seq_len, device)\n",
    "\n",
    "# Display example results\n",
    "example_idx = 0  # Index of the example to display\n",
    "\n",
    "if results:\n",
    "    actual, reconstructed = results[example_idx]\n",
    "    print(f\"Actual Formula: {actual}\")\n",
    "    print(f\"Reconstructed Formula: {reconstructed}\")\n",
    "\n",
    "# Calculate accuracy or similarity score (optional)\n",
    "# accuracies = [accuracy_score(list(actual), list(reconstructed)) for actual, reconstructed in results]\n",
    "# print(f\"Average Reconstruction Accuracy: {np.mean(accuracies):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 21\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"data_symbolic_regression/train\"\n",
    "\n",
    "# Load and tokenize formulas from the training set; Convert the data points to a Pytorch tensor\n",
    "tokenized_formulas = []\n",
    "points_list = []\n",
    "\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\".json\") and not file_name.startswith('properties'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        with open(file_path, \"r\") as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "            formula_human_readable = data.get(\"formula_human_readable\", \"\")\n",
    "            if formula_human_readable:\n",
    "                tokens = tokenize_formula(formula_human_readable)\n",
    "                tokenized_formulas.append(tokens)\n",
    "                \n",
    "            points = data.get(\"points\")\n",
    "            if points:\n",
    "                points_array = np.array([points[\"var_0\"], points[\"var_1\"], points[\"var_2\"], points[\"target\"]])\n",
    "                points_tensor = torch.tensor(points_array, dtype=torch.float32, device=device).unsqueeze(0)  # Add batch dimension\n",
    "                points_list.append(points_tensor)\n",
    "\n",
    "vocab_mapping = {token: idx for idx, token in enumerate(set(t for tokens in tokenized_formulas for t in tokens))}\n",
    "vocab_size = len(vocab_mapping)\n",
    "\n",
    "# Define EOS and PAD token IDs\n",
    "eos_token_id = vocab_size - 1  # Assuming the last ID in the vocabulary is for EOS\n",
    "pad_token_id = vocab_size - 2  # Assuming the second-to-last ID in the vocabulary is for PAD\n",
    "\n",
    "print(eos_token_id, pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([747, 4, 100])\n",
      "Output shape: torch.Size([747, 128])\n",
      "Original Tokens shape: torch.Size([747, 24])\n",
      "Noisy Tokens (probabilities) shape: torch.Size([747, 24, 23])\n",
      "Sampled Tokens shape: torch.Size([747, 24])\n",
      "Epoch [1/1000], Loss: 0.0425, Val Loss: 0.0443\n",
      "Epoch [2/1000], Loss: 0.0318, Val Loss: 0.0432\n",
      "Epoch [3/1000], Loss: 0.0275, Val Loss: 0.0433\n",
      "Epoch [4/1000], Loss: 0.0250, Val Loss: 0.0439\n",
      "Epoch [5/1000], Loss: 0.0233, Val Loss: 0.0425\n",
      "Epoch [6/1000], Loss: 0.0222, Val Loss: 0.0444\n",
      "Epoch [7/1000], Loss: 0.0213, Val Loss: 0.0457\n",
      "Epoch [8/1000], Loss: 0.0207, Val Loss: 0.0455\n",
      "Epoch [9/1000], Loss: 0.0202, Val Loss: 0.0458\n",
      "Epoch [10/1000], Loss: 0.0199, Val Loss: 0.0473\n",
      "Epoch [11/1000], Loss: 0.0197, Val Loss: 0.0469\n",
      "Epoch [12/1000], Loss: 0.0193, Val Loss: 0.0486\n",
      "Epoch [13/1000], Loss: 0.0192, Val Loss: 0.0465\n",
      "Epoch [14/1000], Loss: 0.0188, Val Loss: 0.0478\n",
      "Epoch [15/1000], Loss: 0.0185, Val Loss: 0.0480\n",
      "Early stopping triggered. Restoring best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fm/3vzr0bd54y38wk6x2_8f9xlm0000gn/T/ipykernel_66268/34852021.py:438: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  reverse_model.load_state_dict(torch.load('best_model.pth'))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Define a function to tokenize a formula\n",
    "def tokenize_formula(formula):\n",
    "    token_pattern = r\"[a-zA-Z_][a-zA-Z0-9_]*|[()+\\-*/]|\\d+\\.?\\d*\"\n",
    "    tokens = re.findall(token_pattern, formula)\n",
    "    return tokens\n",
    "\n",
    "@dataclass\n",
    "class tNetConfig:\n",
    "    num_vars: int\n",
    "    embedding_size: int\n",
    "\n",
    "class tNet(nn.Module):\n",
    "    def __init__(self, config: tNetConfig):\n",
    "        super(tNet, self).__init__()\n",
    "\n",
    "        self.config = config\n",
    "        self.num_vars = config.num_vars\n",
    "        self.n_embd = config.embedding_size\n",
    "\n",
    "        self.activation_func = F.relu\n",
    "\n",
    "        self.conv1 = nn.Conv1d(self.num_vars + 1, self.n_embd, 1)\n",
    "        self.conv2 = nn.Conv1d(self.n_embd, 2 * self.n_embd, 1)\n",
    "        self.conv3 = nn.Conv1d(2 * self.n_embd, 4 * self.n_embd, 1)\n",
    "\n",
    "        self.fc1 = nn.Linear(4 * self.n_embd, 2 * self.n_embd)\n",
    "        self.fc2 = nn.Linear(2 * self.n_embd, self.n_embd)\n",
    "\n",
    "        self.input_batch_norm = nn.GroupNorm(1, self.num_vars + 1)\n",
    "\n",
    "        self.bn1 = nn.GroupNorm(1, self.n_embd)\n",
    "        self.bn2 = nn.GroupNorm(1, 2 * self.n_embd)\n",
    "        self.bn3 = nn.GroupNorm(1, 4 * self.n_embd)\n",
    "        self.bn4 = nn.GroupNorm(1, 2 * self.n_embd)\n",
    "        self.bn5 = nn.GroupNorm(1, self.n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: [batch, #features + 1, #points]\n",
    "        :return: logit: [batch, embedding_size]\n",
    "        \"\"\"\n",
    "        x = self.input_batch_norm(x)\n",
    "        x = self.activation_func(self.bn1(self.conv1(x)))\n",
    "        x = self.activation_func(self.bn2(self.conv2(x)))\n",
    "        x = self.activation_func(self.bn3(self.conv3(x)))\n",
    "        x, _ = torch.max(x, dim=2)  # global max pooling\n",
    "        assert x.size(1) == 4 * self.n_embd\n",
    "\n",
    "        x = self.activation_func(self.bn4(self.fc1(x)))\n",
    "        x = self.activation_func(self.bn5(self.fc2(x)))\n",
    "\n",
    "        return x\n",
    "\n",
    "class TextDiffusionModel:\n",
    "    def __init__(self, vocab_size, seq_len, device=\"cpu\"):\n",
    "        \"\"\"\n",
    "        Initialize the text diffusion model.\n",
    "\n",
    "        Parameters:\n",
    "        - vocab_size: Size of the vocabulary (number of unique tokens).\n",
    "        - seq_len: Length of the token sequence.\n",
    "        - device: Device to use (\"cpu\" or \"cuda\").\n",
    "        \"\"\"\n",
    "        self.vocab_size = vocab_size\n",
    "        self.seq_len = seq_len\n",
    "        self.device = device\n",
    "        # self.noise_schedule = torch.linspace(0.01, 0.1, steps=1000).to(device)  # Noise variance per timestep\n",
    "        self.noise_schedule = torch.linspace(1e-4, 2e-2, steps=1000).to(device)  # Noise variance per timestep\n",
    "\n",
    "    def add_noise(self, tokens, t):\n",
    "        \"\"\"\n",
    "        Add noise to a sequence of tokens based on timestep t.\n",
    "\n",
    "        Parameters:\n",
    "        - tokens: A tensor of token indices with shape (batch_size, seq_len).\n",
    "        - t: A tensor of timesteps with shape (batch_size,).\n",
    "\n",
    "        Returns:\n",
    "        - noisy_tokens: The tokens with added noise.\n",
    "        - noise: The noise added to the tokens.\n",
    "        \"\"\"\n",
    "        noise_std = self.noise_schedule[t].view(-1, 1, 1)  # Shape: (batch_size, 1, 1)\n",
    "\n",
    "        # Convert tokens to one-hot vectors\n",
    "        one_hot = F.one_hot(tokens.long(), num_classes=self.vocab_size).float()\n",
    "        \n",
    "        # Add Gaussian noise to the one-hot vectors\n",
    "        noise = torch.randn_like(one_hot) * noise_std\n",
    "        noisy_one_hot = one_hot + noise\n",
    "\n",
    "        # Compute softmax to normalize the noisy one-hot vectors\n",
    "        noisy_tokens = F.softmax(noisy_one_hot, dim=-1)\n",
    "        return noisy_tokens, noise\n",
    "\n",
    "    def sample_from_noisy_tokens(self, noisy_tokens):\n",
    "        \"\"\"\n",
    "        Sample discrete tokens from the noisy token distribution.\n",
    "\n",
    "        Parameters:\n",
    "        - noisy_tokens: A tensor of noisy token distributions with shape (batch_size, seq_len, vocab_size).\n",
    "\n",
    "        Returns:\n",
    "        - sampled_tokens: A tensor of sampled token indices with shape (batch_size, seq_len).\n",
    "        \"\"\"\n",
    "        sampled_tokens = torch.argmax(noisy_tokens, dim=-1)\n",
    "        return sampled_tokens\n",
    "\n",
    "class ReverseProcessModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, num_vars, seq_len):\n",
    "        super(ReverseProcessModel, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.num_vars = num_vars\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "        # Calculate the correct input size for fc1\n",
    "        input_size = embedding_size + (seq_len * vocab_size) + 1  # embeddings + noisy_tokens + timestep\n",
    "\n",
    "        # Define layers for the reverse process model\n",
    "        self.fc1 = nn.Linear(input_size, 512)  # Adjusted input size\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, seq_len * vocab_size)  # Output for all tokens in the sequence\n",
    "\n",
    "    def forward(self, noisy_tokens, embeddings, t):\n",
    "        \"\"\"\n",
    "        Forward pass for the reverse process model.\n",
    "\n",
    "        :param noisy_tokens: Tensor of noisy tokens with shape [batch_size, seq_len, vocab_size].\n",
    "        :param embeddings: Tensor of embeddings with shape [batch_size, embedding_size].\n",
    "        :param t: Tensor of timesteps with shape [batch_size].\n",
    "        :return: Predicted noise.\n",
    "        \"\"\"\n",
    "        # Flatten noisy tokens to [batch_size, seq_len * vocab_size]\n",
    "        noisy_tokens_flat = noisy_tokens.view(noisy_tokens.size(0), -1)\n",
    "\n",
    "        # Concatenate embeddings, flattened noisy tokens, and timestep information\n",
    "        timestep_embedding = torch.cat([embeddings, noisy_tokens_flat, t.unsqueeze(1).float()], dim=-1)\n",
    "        \n",
    "        # Pass through the fully connected layers\n",
    "        x = F.relu(self.fc1(timestep_embedding))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        predicted_noise = self.fc3(x)\n",
    "\n",
    "        # Reshape to [batch_size, seq_len, vocab_size]\n",
    "        predicted_noise = predicted_noise.view(-1, self.seq_len, self.vocab_size)\n",
    "        \n",
    "        return predicted_noise\n",
    "\n",
    "# Main function\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Define the device \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    folder_path = \"data_symbolic_regression/train\"\n",
    "    val_folder_path = \"data_symbolic_regression/val\"\n",
    "\n",
    "    # Load and tokenize formulas from the training set; Convert the data points to a Pytorch tensor\n",
    "    tokenized_formulas = []\n",
    "    points_list = []\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".json\") and not file_name.startswith('properties'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            with open(file_path, \"r\") as file:\n",
    "                data = json.load(file)\n",
    "\n",
    "                formula_human_readable = data.get(\"formula_human_readable\", \"\")\n",
    "                if formula_human_readable:\n",
    "                    tokens = tokenize_formula(formula_human_readable)\n",
    "                    tokenized_formulas.append(tokens)\n",
    "                \n",
    "                points = data.get(\"points\")\n",
    "                if points:\n",
    "                    points_array = np.array([points[\"var_0\"], points[\"var_1\"], points[\"var_2\"], points[\"target\"]])\n",
    "                    points_tensor = torch.tensor(points_array, dtype=torch.float32, device=device).unsqueeze(0)  # Add batch dimension\n",
    "                    points_list.append(points_tensor)\n",
    "                    # Need below line if points_array is transposed\n",
    "                    # points_tensor = torch.tensor(points_array, dtype=torch.float32, device=device).unsqueeze(0).permute(0, 2, 1)  # Add batch dimension and transpose\n",
    "\n",
    "    # # Create the vocabulary from the tokens\n",
    "    # vocab_mapping = {token: idx for idx, token in enumerate(set(t for tokens in tokenized_formulas for t in tokens))}\n",
    "    # vocab_size = len(vocab_mapping)\n",
    "\n",
    "    # token_sequences = [[vocab_mapping[token] for token in tokens] for tokens in tokenized_formulas]\n",
    "\n",
    "    # formula_lengths = [len(tokens) for tokens in tokenized_formulas]\n",
    "    # seq_len = int(np.percentile(formula_lengths, 95))  # Use 95th percentile\n",
    "\n",
    "    val_tokenized_formulas = []\n",
    "    val_points_list = []\n",
    "\n",
    "    # Create the vocabulary from the tokens\n",
    "    for file_name in os.listdir(val_folder_path):\n",
    "        if file_name.endswith(\".json\") and not file_name.startswith('properties'):\n",
    "            file_path = os.path.join(val_folder_path, file_name)\n",
    "            with open(file_path, \"r\") as file:\n",
    "                val_data = json.load(file)\n",
    "\n",
    "                val_formula_human_readable = val_data.get(\"formula_human_readable\", \"\")\n",
    "                if val_formula_human_readable:\n",
    "                    val_tokens = tokenize_formula(val_formula_human_readable)\n",
    "                    val_tokenized_formulas.append(val_tokens)\n",
    "                \n",
    "                val_points = val_data.get(\"points\")\n",
    "                if val_points:\n",
    "                    val_points_array = np.array([val_points[\"var_0\"], val_points[\"var_1\"], val_points[\"var_2\"], val_points[\"target\"]])\n",
    "                    val_points_tensor = torch.tensor(val_points_array, dtype=torch.float32, device=device).unsqueeze(0)  # Add batch dimension\n",
    "                    val_points_list.append(val_points_tensor)\n",
    "\n",
    "    vocab_mapping = {token: idx for idx, token in enumerate(set(t for tokens in tokenized_formulas for t in tokens))}\n",
    "    vocab_size = len(vocab_mapping)\n",
    "\n",
    "    # Define EOS and PAD token IDs\n",
    "    eos_token_id = vocab_size - 1  # Assuming the last ID in the vocabulary is for EOS\n",
    "    pad_token_id = vocab_size - 2  # Assuming the second-to-last ID in the vocabulary is for PAD\n",
    "\n",
    "    # Add EOS and PAD tokens to vocab_mapping if not already present\n",
    "    if eos_token_id not in vocab_mapping.values():\n",
    "        vocab_mapping['<EOS>'] = eos_token_id\n",
    "    if pad_token_id not in vocab_mapping.values():\n",
    "        vocab_mapping['<PAD>'] = pad_token_id\n",
    "\n",
    "    # Tokenize and map tokens to vocabulary indices\n",
    "    token_sequences = [[vocab_mapping.get(token, pad_token_id) for token in tokens] for tokens in tokenized_formulas]\n",
    "\n",
    "    # Calculate sequence length based on the 95th percentile of formula lengths\n",
    "    formula_lengths = [len(tokens) for tokens in tokenized_formulas]\n",
    "    seq_len = int(np.percentile(formula_lengths, 95))  # Use 95th percentile\n",
    "    batch_size = 100  # Example batch size\n",
    "\n",
    "    # Pad or truncate sequences to seq_len, adding EOS token last\n",
    "    token_sequences = [\n",
    "        seq[:seq_len] + [pad_token_id] * max(0, seq_len - len(seq)) + [eos_token_id] \n",
    "        if len(seq) < seq_len else seq[:seq_len] + [eos_token_id]  # Add EOS token at the end after padding\n",
    "        for seq in token_sequences\n",
    "    ]\n",
    "\n",
    "    # Convert to tensor\n",
    "    token_tensor = torch.tensor(token_sequences, device=device)\n",
    "\n",
    "    # Initialize the model\n",
    "    diffusion_model = TextDiffusionModel(vocab_size, seq_len, device=device)\n",
    "    \n",
    "    # Pad or truncate sequences to seq_len\n",
    "    token_sequences = [seq[:seq_len] + [0] * max(0, seq_len - len(seq)) for seq in token_sequences]\n",
    "    token_tensor = torch.tensor(token_sequences, device=device)\n",
    "\n",
    "    val_vocab_mapping = {token: idx for idx, token in enumerate(set(t for tokens in val_tokenized_formulas for t in tokens))}\n",
    "    val_vocab_size = len(val_vocab_mapping)\n",
    "\n",
    "    # Add EOS and PAD tokens to vocab_mapping if not already present\n",
    "    if eos_token_id not in val_vocab_mapping.values():\n",
    "        val_vocab_mapping['<EOS>'] = eos_token_id\n",
    "    if pad_token_id not in val_vocab_mapping.values():\n",
    "        val_vocab_mapping['<PAD>'] = pad_token_id\n",
    "\n",
    "    # Tokenize and map tokens to vocabulary indices\n",
    "    val_token_sequences = [[val_vocab_mapping.get(token, pad_token_id) for token in tokens] for tokens in val_tokenized_formulas]\n",
    "\n",
    "    # Calculate sequence length based on the 95th percentile of formula lengths\n",
    "    val_formula_lengths = [len(tokens) for tokens in val_tokenized_formulas]\n",
    "    val_seq_len = int(np.percentile(val_formula_lengths, 95))  # Use 95th percentile\n",
    "\n",
    "    # Pad or truncate sequences to seq_len, adding EOS token last\n",
    "    val_token_sequences = [\n",
    "        seq[:seq_len] + [pad_token_id] * max(0, seq_len - len(seq)) + [eos_token_id] \n",
    "        if len(seq) < seq_len else seq[:seq_len] + [eos_token_id]  # Add EOS token at the end after padding\n",
    "        for seq in val_token_sequences\n",
    "    ]\n",
    "\n",
    "    # Convert to tensor\n",
    "    val_token_tensor = torch.tensor(val_token_sequences, device=device)\n",
    "\n",
    "    # Initialize the model\n",
    "    diffusion_model = TextDiffusionModel(vocab_size, seq_len, device=device)\n",
    "    \n",
    "    # Pad or truncate sequences to seq_len\n",
    "    val_token_sequences = [seq[:seq_len] + [0] * max(0, seq_len - len(seq)) for seq in val_token_sequences]\n",
    "    val_token_tensor = torch.tensor(val_token_sequences, device=device)\n",
    "\n",
    "    # # Add EOS token and pad sequences\n",
    "    # # Define EOS and PAD token IDs\n",
    "    # eos_token_id = vocab_size - 1  # Assuming the last ID in the vocabulary is for EOS\n",
    "    # pad_token_id = vocab_size - 2  # Assuming the second-to-last ID is for PAD\n",
    "\n",
    "    # # Add EOS token and pad sequences\n",
    "    # max_seq_len = max(len(seq) for seq in token_tensor)\n",
    "    # padded_token_tensor = []\n",
    "    # for seq in token_tensor:\n",
    "    #     seq = torch.cat([seq, torch.tensor([eos_token_id])])  # Add EOS token\n",
    "    #     padding = torch.tensor([pad_token_id] * (max_seq_len - len(seq)))  # Add padding\n",
    "    #     seq = torch.cat([seq, padding])  # Concatenate the sequence and padding\n",
    "    #     padded_token_tensor.append(seq)\n",
    "\n",
    "    # # Convert to a tensor\n",
    "    # token_tensor = torch.stack(padded_token_tensor)\n",
    "\n",
    "    # Choose random timesteps for each sequence\n",
    "    t = torch.randint(0, 1000, (len(token_tensor),), device=device)\n",
    "\n",
    "    # Add noise to the tokens\n",
    "    noisy_tokens, noise = diffusion_model.add_noise(token_tensor, t)\n",
    "\n",
    "    # Sample from noisy tokens\n",
    "    sampled_tokens = diffusion_model.sample_from_noisy_tokens(noisy_tokens)\n",
    "\n",
    "    # Configuration for tNet\n",
    "    num_vars = 3\n",
    "    embedding_size = 128  # Example embedding size\n",
    "    config = tNetConfig(num_vars=num_vars, embedding_size=embedding_size)\n",
    "\n",
    "    # Instantiate the model\n",
    "    tnet_model = tNet(config)\n",
    "\n",
    "    # Input: batch_size x (num_vars + 1) x num_points\n",
    "    batch_size = 1\n",
    "\n",
    "    # Generate embeddings\n",
    "    # input_tensor = torch.rand(batch_size, num_vars, 100)\n",
    "\n",
    "    output_embeddings = []\n",
    "    for pt in points_list:\n",
    "        output_embedding = tnet_model(pt)\n",
    "        output_embeddings.append(output_embedding)\n",
    "    \n",
    "    points_tensors = torch.cat(points_list, dim=0)\n",
    "    \n",
    "    output_embeddings_tensor = torch.cat(output_embeddings, dim=0)\n",
    "    # Print the output\n",
    "    print(\"Input shape:\", points_tensors.shape)\n",
    "    print(\"Output shape:\", output_embeddings_tensor.shape)\n",
    "\n",
    "    # Print results\n",
    "    print(\"Original Tokens shape:\", token_tensor.shape)\n",
    "    print(\"Noisy Tokens (probabilities) shape:\", noisy_tokens.shape)\n",
    "    print(\"Sampled Tokens shape:\", sampled_tokens.shape)\n",
    "\n",
    "    # Initialize reverse model (denoiser)\n",
    "    reverse_model = ReverseProcessModel(vocab_size, embedding_size, num_vars, seq_len).to(device)\n",
    "\n",
    "    # Cross-entropy loss function\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Train the reverse process model\n",
    "    epochs = 1000  # Define the number of epochs for training\n",
    "    batch_size = 100  # Example batch size\n",
    "\n",
    "    # Optimizer for the reverse process model\n",
    "    optimizer = torch.optim.Adam(reverse_model.parameters(), lr=1e-4)\n",
    "\n",
    "    # Early stopping parameters\n",
    "    patience = 10\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Initialize lists to store training and validation losses\n",
    "    training_losses = []\n",
    "    validation_losses = []\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        reverse_model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        # Training Phase\n",
    "        for batch_idx in range(0, len(points_list), batch_size):\n",
    "            batch_points = points_list[batch_idx:batch_idx + batch_size]\n",
    "            batch_token_tensor = token_tensor[batch_idx:batch_idx + batch_size]\n",
    "\n",
    "            # Random timesteps\n",
    "            t_batch = torch.randint(0, 1000, (len(batch_points),), device=device)\n",
    "\n",
    "            # Add noise\n",
    "            noisy_tokens, _ = diffusion_model.add_noise(batch_token_tensor, t_batch)\n",
    "\n",
    "            # Get embeddings\n",
    "            batch_embeddings = [tnet_model(pt) for pt in batch_points]\n",
    "            embeddings_tensor = torch.cat(batch_embeddings, dim=0)\n",
    "\n",
    "            # Predict logits\n",
    "            logits = reverse_model(noisy_tokens, embeddings_tensor, t_batch)\n",
    "\n",
    "            # Reshape logits and target tokens for CrossEntropyLoss\n",
    "            logits_flat = logits.view(-1, vocab_size)\n",
    "            target_tokens = batch_token_tensor.view(-1)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_fn(logits_flat, target_tokens)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation Phase\n",
    "        reverse_model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for val_batch_idx in range(0, len(val_points_list), batch_size):\n",
    "                val_batch_points = val_points_list[val_batch_idx:val_batch_idx + batch_size]\n",
    "                val_batch_token_tensor = val_token_tensor[val_batch_idx:val_batch_idx + batch_size]\n",
    "\n",
    "                val_t_batch = torch.randint(0, 1000, (len(val_batch_points),), device=device)\n",
    "\n",
    "                val_noisy_tokens, _ = diffusion_model.add_noise(val_batch_token_tensor, val_t_batch)\n",
    "\n",
    "                val_embeddings = [tnet_model(pt) for pt in val_batch_points]\n",
    "                val_embeddings_tensor = torch.cat(val_embeddings, dim=0)\n",
    "\n",
    "                val_logits = reverse_model(val_noisy_tokens, val_embeddings_tensor, val_t_batch)\n",
    "                val_logits_flat = val_logits.view(-1, vocab_size)\n",
    "                val_target_tokens = val_batch_token_tensor.view(-1)\n",
    "\n",
    "                val_loss += loss_fn(val_logits_flat, val_target_tokens).item()\n",
    "\n",
    "        val_loss /= len(val_points_list)\n",
    "\n",
    "        # Store losses for plotting\n",
    "        training_losses.append(total_loss / len(points_list))\n",
    "        validation_losses.append(val_loss)\n",
    "\n",
    "        # Print progress\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {training_losses[-1]:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Early stopping logic\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(reverse_model.state_dict(), 'best_model.pth')  # Save the best model\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stopping triggered. Restoring best model...\")\n",
    "            reverse_model.load_state_dict(torch.load('best_model.pth'))\n",
    "            break\n",
    "\n",
    "    # Plot training and validation losses\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(training_losses) + 1), training_losses, label='Training Loss', color='blue')\n",
    "    plt.plot(range(1, len(validation_losses) + 1), validation_losses, label='Validation Loss', color='orange')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss Curves')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([747, 4, 100])\n",
      "Output shape: torch.Size([747, 128])\n",
      "Original Tokens shape: torch.Size([747, 24])\n",
      "Noisy Tokens (probabilities) shape: torch.Size([747, 24, 23])\n",
      "Sampled Tokens shape: torch.Size([747, 24])\n",
      "Epoch [1/1000], Loss: 0.0460, Val Loss: 0.0437\n",
      "Epoch [2/1000], Loss: 0.0338, Val Loss: 0.0351\n",
      "Epoch [3/1000], Loss: 0.0281, Val Loss: 0.0309\n",
      "Epoch [4/1000], Loss: 0.0252, Val Loss: 0.0290\n",
      "Epoch [5/1000], Loss: 0.0235, Val Loss: 0.0276\n",
      "Epoch [6/1000], Loss: 0.0221, Val Loss: 0.0258\n",
      "Epoch [7/1000], Loss: 0.0212, Val Loss: 0.0248\n",
      "Epoch [8/1000], Loss: 0.0209, Val Loss: 0.0251\n",
      "Epoch [9/1000], Loss: 0.0203, Val Loss: 0.0243\n",
      "Epoch [10/1000], Loss: 0.0201, Val Loss: 0.0237\n",
      "Epoch [11/1000], Loss: 0.0196, Val Loss: 0.0236\n",
      "Epoch [12/1000], Loss: 0.0194, Val Loss: 0.0229\n",
      "Epoch [13/1000], Loss: 0.0193, Val Loss: 0.0235\n",
      "Epoch [14/1000], Loss: 0.0188, Val Loss: 0.0231\n",
      "Epoch [15/1000], Loss: 0.0184, Val Loss: 0.0224\n",
      "Epoch [16/1000], Loss: 0.0181, Val Loss: 0.0224\n",
      "Epoch [17/1000], Loss: 0.0179, Val Loss: 0.0219\n",
      "Epoch [18/1000], Loss: 0.0177, Val Loss: 0.0219\n",
      "Epoch [19/1000], Loss: 0.0176, Val Loss: 0.0218\n",
      "Epoch [20/1000], Loss: 0.0175, Val Loss: 0.0215\n",
      "Epoch [21/1000], Loss: 0.0174, Val Loss: 0.0215\n",
      "Epoch [22/1000], Loss: 0.0174, Val Loss: 0.0214\n",
      "Epoch [23/1000], Loss: 0.0174, Val Loss: 0.0213\n",
      "Epoch [24/1000], Loss: 0.0174, Val Loss: 0.0214\n",
      "Epoch [25/1000], Loss: 0.0173, Val Loss: 0.0214\n",
      "Epoch [26/1000], Loss: 0.0173, Val Loss: 0.0213\n",
      "Epoch [27/1000], Loss: 0.0173, Val Loss: 0.0213\n",
      "Epoch [28/1000], Loss: 0.0173, Val Loss: 0.0214\n",
      "Epoch [29/1000], Loss: 0.0173, Val Loss: 0.0213\n",
      "Epoch [30/1000], Loss: 0.0173, Val Loss: 0.0212\n",
      "Epoch [31/1000], Loss: 0.0173, Val Loss: 0.0213\n",
      "Epoch [32/1000], Loss: 0.0173, Val Loss: 0.0212\n",
      "Epoch [33/1000], Loss: 0.0172, Val Loss: 0.0213\n",
      "Epoch [34/1000], Loss: 0.0172, Val Loss: 0.0213\n",
      "Epoch [35/1000], Loss: 0.0172, Val Loss: 0.0212\n",
      "Epoch [36/1000], Loss: 0.0172, Val Loss: 0.0213\n",
      "Epoch [37/1000], Loss: 0.0172, Val Loss: 0.0213\n",
      "Epoch [38/1000], Loss: 0.0172, Val Loss: 0.0212\n",
      "Epoch [39/1000], Loss: 0.0172, Val Loss: 0.0213\n",
      "Epoch [40/1000], Loss: 0.0172, Val Loss: 0.0212\n",
      "Epoch [41/1000], Loss: 0.0172, Val Loss: 0.0213\n",
      "Epoch [42/1000], Loss: 0.0172, Val Loss: 0.0212\n",
      "Epoch [43/1000], Loss: 0.0172, Val Loss: 0.0212\n",
      "Epoch [44/1000], Loss: 0.0172, Val Loss: 0.0213\n",
      "Epoch [45/1000], Loss: 0.0172, Val Loss: 0.0213\n",
      "Epoch [46/1000], Loss: 0.0172, Val Loss: 0.0212\n",
      "Epoch [47/1000], Loss: 0.0171, Val Loss: 0.0212\n",
      "Epoch [48/1000], Loss: 0.0171, Val Loss: 0.0212\n",
      "Epoch [49/1000], Loss: 0.0172, Val Loss: 0.0212\n",
      "Epoch [50/1000], Loss: 0.0171, Val Loss: 0.0212\n",
      "Epoch [51/1000], Loss: 0.0171, Val Loss: 0.0212\n",
      "Epoch [52/1000], Loss: 0.0171, Val Loss: 0.0211\n",
      "Epoch [53/1000], Loss: 0.0171, Val Loss: 0.0212\n",
      "Epoch [54/1000], Loss: 0.0171, Val Loss: 0.0212\n",
      "Epoch [55/1000], Loss: 0.0171, Val Loss: 0.0211\n",
      "Epoch [56/1000], Loss: 0.0171, Val Loss: 0.0212\n",
      "Epoch [57/1000], Loss: 0.0171, Val Loss: 0.0212\n",
      "Epoch [58/1000], Loss: 0.0171, Val Loss: 0.0211\n",
      "Epoch [59/1000], Loss: 0.0171, Val Loss: 0.0211\n",
      "Epoch [60/1000], Loss: 0.0171, Val Loss: 0.0212\n",
      "Epoch [61/1000], Loss: 0.0171, Val Loss: 0.0211\n",
      "Epoch [62/1000], Loss: 0.0171, Val Loss: 0.0211\n",
      "Epoch [63/1000], Loss: 0.0170, Val Loss: 0.0211\n",
      "Epoch [64/1000], Loss: 0.0170, Val Loss: 0.0211\n",
      "Epoch [65/1000], Loss: 0.0170, Val Loss: 0.0211\n",
      "Epoch [66/1000], Loss: 0.0170, Val Loss: 0.0211\n",
      "Epoch [67/1000], Loss: 0.0170, Val Loss: 0.0211\n",
      "Epoch [68/1000], Loss: 0.0170, Val Loss: 0.0211\n",
      "Epoch [69/1000], Loss: 0.0170, Val Loss: 0.0210\n",
      "Epoch [70/1000], Loss: 0.0170, Val Loss: 0.0210\n",
      "Epoch [71/1000], Loss: 0.0170, Val Loss: 0.0211\n",
      "Epoch [72/1000], Loss: 0.0169, Val Loss: 0.0211\n",
      "Epoch [73/1000], Loss: 0.0169, Val Loss: 0.0210\n",
      "Epoch [74/1000], Loss: 0.0169, Val Loss: 0.0210\n",
      "Epoch [75/1000], Loss: 0.0169, Val Loss: 0.0211\n",
      "Epoch [76/1000], Loss: 0.0169, Val Loss: 0.0209\n",
      "Epoch [77/1000], Loss: 0.0169, Val Loss: 0.0210\n",
      "Epoch [78/1000], Loss: 0.0169, Val Loss: 0.0209\n",
      "Epoch [79/1000], Loss: 0.0169, Val Loss: 0.0210\n",
      "Epoch [80/1000], Loss: 0.0169, Val Loss: 0.0210\n",
      "Epoch [81/1000], Loss: 0.0168, Val Loss: 0.0209\n",
      "Epoch [82/1000], Loss: 0.0168, Val Loss: 0.0209\n",
      "Epoch [83/1000], Loss: 0.0168, Val Loss: 0.0208\n",
      "Epoch [84/1000], Loss: 0.0168, Val Loss: 0.0208\n",
      "Epoch [85/1000], Loss: 0.0167, Val Loss: 0.0208\n",
      "Epoch [86/1000], Loss: 0.0167, Val Loss: 0.0208\n",
      "Epoch [87/1000], Loss: 0.0167, Val Loss: 0.0208\n",
      "Epoch [88/1000], Loss: 0.0167, Val Loss: 0.0207\n",
      "Epoch [89/1000], Loss: 0.0167, Val Loss: 0.0207\n",
      "Epoch [90/1000], Loss: 0.0166, Val Loss: 0.0207\n",
      "Epoch [91/1000], Loss: 0.0166, Val Loss: 0.0206\n",
      "Epoch [92/1000], Loss: 0.0166, Val Loss: 0.0206\n",
      "Epoch [93/1000], Loss: 0.0166, Val Loss: 0.0206\n",
      "Epoch [94/1000], Loss: 0.0165, Val Loss: 0.0206\n",
      "Epoch [95/1000], Loss: 0.0165, Val Loss: 0.0207\n",
      "Epoch [96/1000], Loss: 0.0165, Val Loss: 0.0205\n",
      "Epoch [97/1000], Loss: 0.0164, Val Loss: 0.0205\n",
      "Epoch [98/1000], Loss: 0.0164, Val Loss: 0.0204\n",
      "Epoch [99/1000], Loss: 0.0163, Val Loss: 0.0204\n",
      "Epoch [100/1000], Loss: 0.0163, Val Loss: 0.0203\n",
      "Epoch [101/1000], Loss: 0.0162, Val Loss: 0.0203\n",
      "Epoch [102/1000], Loss: 0.0162, Val Loss: 0.0203\n",
      "Epoch [103/1000], Loss: 0.0161, Val Loss: 0.0205\n",
      "Epoch [104/1000], Loss: 0.0162, Val Loss: 0.0206\n",
      "Epoch [105/1000], Loss: 0.0162, Val Loss: 0.0204\n",
      "Epoch [106/1000], Loss: 0.0162, Val Loss: 0.0202\n",
      "Epoch [107/1000], Loss: 0.0161, Val Loss: 0.0202\n",
      "Epoch [108/1000], Loss: 0.0160, Val Loss: 0.0200\n",
      "Epoch [109/1000], Loss: 0.0159, Val Loss: 0.0200\n",
      "Epoch [110/1000], Loss: 0.0159, Val Loss: 0.0200\n",
      "Epoch [111/1000], Loss: 0.0159, Val Loss: 0.0199\n",
      "Epoch [112/1000], Loss: 0.0158, Val Loss: 0.0197\n",
      "Epoch [113/1000], Loss: 0.0157, Val Loss: 0.0198\n",
      "Epoch [114/1000], Loss: 0.0157, Val Loss: 0.0196\n",
      "Epoch [115/1000], Loss: 0.0156, Val Loss: 0.0196\n",
      "Epoch [116/1000], Loss: 0.0155, Val Loss: 0.0195\n",
      "Epoch [117/1000], Loss: 0.0155, Val Loss: 0.0195\n",
      "Epoch [118/1000], Loss: 0.0154, Val Loss: 0.0194\n",
      "Epoch [119/1000], Loss: 0.0153, Val Loss: 0.0192\n",
      "Epoch [120/1000], Loss: 0.0152, Val Loss: 0.0192\n",
      "Epoch [121/1000], Loss: 0.0152, Val Loss: 0.0193\n",
      "Epoch [122/1000], Loss: 0.0152, Val Loss: 0.0190\n",
      "Epoch [123/1000], Loss: 0.0151, Val Loss: 0.0189\n",
      "Epoch [124/1000], Loss: 0.0150, Val Loss: 0.0189\n",
      "Epoch [125/1000], Loss: 0.0150, Val Loss: 0.0188\n",
      "Epoch [126/1000], Loss: 0.0149, Val Loss: 0.0188\n",
      "Epoch [127/1000], Loss: 0.0148, Val Loss: 0.0187\n",
      "Epoch [128/1000], Loss: 0.0147, Val Loss: 0.0186\n",
      "Epoch [129/1000], Loss: 0.0147, Val Loss: 0.0185\n",
      "Epoch [130/1000], Loss: 0.0146, Val Loss: 0.0185\n",
      "Epoch [131/1000], Loss: 0.0145, Val Loss: 0.0184\n",
      "Epoch [132/1000], Loss: 0.0145, Val Loss: 0.0183\n",
      "Epoch [133/1000], Loss: 0.0144, Val Loss: 0.0183\n",
      "Epoch [134/1000], Loss: 0.0143, Val Loss: 0.0182\n",
      "Epoch [135/1000], Loss: 0.0143, Val Loss: 0.0181\n",
      "Epoch [136/1000], Loss: 0.0142, Val Loss: 0.0181\n",
      "Epoch [137/1000], Loss: 0.0141, Val Loss: 0.0180\n",
      "Epoch [138/1000], Loss: 0.0141, Val Loss: 0.0179\n",
      "Epoch [139/1000], Loss: 0.0140, Val Loss: 0.0178\n",
      "Epoch [140/1000], Loss: 0.0139, Val Loss: 0.0178\n",
      "Epoch [141/1000], Loss: 0.0138, Val Loss: 0.0177\n",
      "Epoch [142/1000], Loss: 0.0138, Val Loss: 0.0178\n",
      "Epoch [143/1000], Loss: 0.0137, Val Loss: 0.0176\n",
      "Epoch [144/1000], Loss: 0.0137, Val Loss: 0.0175\n",
      "Epoch [145/1000], Loss: 0.0136, Val Loss: 0.0175\n",
      "Epoch [146/1000], Loss: 0.0135, Val Loss: 0.0174\n",
      "Epoch [147/1000], Loss: 0.0135, Val Loss: 0.0174\n",
      "Epoch [148/1000], Loss: 0.0135, Val Loss: 0.0173\n",
      "Epoch [149/1000], Loss: 0.0134, Val Loss: 0.0173\n",
      "Epoch [150/1000], Loss: 0.0134, Val Loss: 0.0173\n",
      "Epoch [151/1000], Loss: 0.0133, Val Loss: 0.0171\n",
      "Epoch [152/1000], Loss: 0.0133, Val Loss: 0.0171\n",
      "Epoch [153/1000], Loss: 0.0132, Val Loss: 0.0170\n",
      "Epoch [154/1000], Loss: 0.0132, Val Loss: 0.0170\n",
      "Epoch [155/1000], Loss: 0.0131, Val Loss: 0.0169\n",
      "Epoch [156/1000], Loss: 0.0131, Val Loss: 0.0170\n",
      "Epoch [157/1000], Loss: 0.0130, Val Loss: 0.0169\n",
      "Epoch [158/1000], Loss: 0.0130, Val Loss: 0.0169\n",
      "Epoch [159/1000], Loss: 0.0130, Val Loss: 0.0169\n",
      "Epoch [160/1000], Loss: 0.0129, Val Loss: 0.0168\n",
      "Epoch [161/1000], Loss: 0.0129, Val Loss: 0.0167\n",
      "Epoch [162/1000], Loss: 0.0129, Val Loss: 0.0167\n",
      "Epoch [163/1000], Loss: 0.0128, Val Loss: 0.0167\n",
      "Epoch [164/1000], Loss: 0.0128, Val Loss: 0.0167\n",
      "Epoch [165/1000], Loss: 0.0128, Val Loss: 0.0166\n",
      "Epoch [166/1000], Loss: 0.0127, Val Loss: 0.0166\n",
      "Epoch [167/1000], Loss: 0.0127, Val Loss: 0.0166\n",
      "Epoch [168/1000], Loss: 0.0127, Val Loss: 0.0166\n",
      "Epoch [169/1000], Loss: 0.0127, Val Loss: 0.0166\n",
      "Epoch [170/1000], Loss: 0.0127, Val Loss: 0.0165\n",
      "Epoch [171/1000], Loss: 0.0126, Val Loss: 0.0165\n",
      "Epoch [172/1000], Loss: 0.0126, Val Loss: 0.0164\n",
      "Epoch [173/1000], Loss: 0.0126, Val Loss: 0.0164\n",
      "Epoch [174/1000], Loss: 0.0126, Val Loss: 0.0164\n",
      "Epoch [175/1000], Loss: 0.0125, Val Loss: 0.0164\n",
      "Epoch [176/1000], Loss: 0.0125, Val Loss: 0.0164\n",
      "Epoch [177/1000], Loss: 0.0125, Val Loss: 0.0163\n",
      "Epoch [178/1000], Loss: 0.0125, Val Loss: 0.0163\n",
      "Epoch [179/1000], Loss: 0.0124, Val Loss: 0.0163\n",
      "Epoch [180/1000], Loss: 0.0124, Val Loss: 0.0163\n",
      "Epoch [181/1000], Loss: 0.0124, Val Loss: 0.0164\n",
      "Epoch [182/1000], Loss: 0.0124, Val Loss: 0.0162\n",
      "Epoch [183/1000], Loss: 0.0124, Val Loss: 0.0163\n",
      "Epoch [184/1000], Loss: 0.0123, Val Loss: 0.0162\n",
      "Epoch [185/1000], Loss: 0.0123, Val Loss: 0.0162\n",
      "Epoch [186/1000], Loss: 0.0123, Val Loss: 0.0162\n",
      "Epoch [187/1000], Loss: 0.0123, Val Loss: 0.0162\n",
      "Epoch [188/1000], Loss: 0.0123, Val Loss: 0.0162\n",
      "Epoch [189/1000], Loss: 0.0123, Val Loss: 0.0162\n",
      "Epoch [190/1000], Loss: 0.0123, Val Loss: 0.0161\n",
      "Epoch [191/1000], Loss: 0.0122, Val Loss: 0.0161\n",
      "Epoch [192/1000], Loss: 0.0122, Val Loss: 0.0161\n",
      "Epoch [193/1000], Loss: 0.0122, Val Loss: 0.0161\n",
      "Epoch [194/1000], Loss: 0.0122, Val Loss: 0.0161\n",
      "Epoch [195/1000], Loss: 0.0121, Val Loss: 0.0161\n",
      "Epoch [196/1000], Loss: 0.0121, Val Loss: 0.0160\n",
      "Epoch [197/1000], Loss: 0.0121, Val Loss: 0.0161\n",
      "Epoch [198/1000], Loss: 0.0121, Val Loss: 0.0161\n",
      "Epoch [199/1000], Loss: 0.0121, Val Loss: 0.0160\n",
      "Epoch [200/1000], Loss: 0.0121, Val Loss: 0.0160\n",
      "Epoch [201/1000], Loss: 0.0120, Val Loss: 0.0160\n",
      "Epoch [202/1000], Loss: 0.0120, Val Loss: 0.0160\n",
      "Epoch [203/1000], Loss: 0.0120, Val Loss: 0.0160\n",
      "Epoch [204/1000], Loss: 0.0120, Val Loss: 0.0159\n",
      "Epoch [205/1000], Loss: 0.0120, Val Loss: 0.0160\n",
      "Epoch [206/1000], Loss: 0.0120, Val Loss: 0.0159\n",
      "Epoch [207/1000], Loss: 0.0120, Val Loss: 0.0159\n",
      "Epoch [208/1000], Loss: 0.0119, Val Loss: 0.0159\n",
      "Epoch [209/1000], Loss: 0.0119, Val Loss: 0.0159\n",
      "Epoch [210/1000], Loss: 0.0119, Val Loss: 0.0159\n",
      "Epoch [211/1000], Loss: 0.0119, Val Loss: 0.0158\n",
      "Epoch [212/1000], Loss: 0.0119, Val Loss: 0.0158\n",
      "Epoch [213/1000], Loss: 0.0119, Val Loss: 0.0159\n",
      "Epoch [214/1000], Loss: 0.0118, Val Loss: 0.0159\n",
      "Epoch [215/1000], Loss: 0.0118, Val Loss: 0.0158\n",
      "Epoch [216/1000], Loss: 0.0118, Val Loss: 0.0158\n",
      "Epoch [217/1000], Loss: 0.0118, Val Loss: 0.0158\n",
      "Epoch [218/1000], Loss: 0.0118, Val Loss: 0.0157\n",
      "Epoch [219/1000], Loss: 0.0118, Val Loss: 0.0158\n",
      "Epoch [220/1000], Loss: 0.0117, Val Loss: 0.0158\n",
      "Epoch [221/1000], Loss: 0.0117, Val Loss: 0.0157\n",
      "Epoch [222/1000], Loss: 0.0117, Val Loss: 0.0158\n",
      "Epoch [223/1000], Loss: 0.0117, Val Loss: 0.0157\n",
      "Epoch [224/1000], Loss: 0.0116, Val Loss: 0.0158\n",
      "Epoch [225/1000], Loss: 0.0117, Val Loss: 0.0157\n",
      "Epoch [226/1000], Loss: 0.0116, Val Loss: 0.0157\n",
      "Epoch [227/1000], Loss: 0.0116, Val Loss: 0.0157\n",
      "Epoch [228/1000], Loss: 0.0116, Val Loss: 0.0156\n",
      "Epoch [229/1000], Loss: 0.0116, Val Loss: 0.0157\n",
      "Epoch [230/1000], Loss: 0.0116, Val Loss: 0.0156\n",
      "Epoch [231/1000], Loss: 0.0115, Val Loss: 0.0157\n",
      "Epoch [232/1000], Loss: 0.0115, Val Loss: 0.0156\n",
      "Epoch [233/1000], Loss: 0.0115, Val Loss: 0.0156\n",
      "Epoch [234/1000], Loss: 0.0115, Val Loss: 0.0155\n",
      "Epoch [235/1000], Loss: 0.0115, Val Loss: 0.0156\n",
      "Epoch [236/1000], Loss: 0.0115, Val Loss: 0.0155\n",
      "Epoch [237/1000], Loss: 0.0114, Val Loss: 0.0155\n",
      "Epoch [238/1000], Loss: 0.0114, Val Loss: 0.0155\n",
      "Epoch [239/1000], Loss: 0.0114, Val Loss: 0.0156\n",
      "Epoch [240/1000], Loss: 0.0114, Val Loss: 0.0155\n",
      "Epoch [241/1000], Loss: 0.0114, Val Loss: 0.0155\n",
      "Epoch [242/1000], Loss: 0.0114, Val Loss: 0.0154\n",
      "Epoch [243/1000], Loss: 0.0113, Val Loss: 0.0155\n",
      "Epoch [244/1000], Loss: 0.0113, Val Loss: 0.0155\n",
      "Epoch [245/1000], Loss: 0.0113, Val Loss: 0.0154\n",
      "Epoch [246/1000], Loss: 0.0113, Val Loss: 0.0154\n",
      "Epoch [247/1000], Loss: 0.0113, Val Loss: 0.0154\n",
      "Epoch [248/1000], Loss: 0.0112, Val Loss: 0.0153\n",
      "Epoch [249/1000], Loss: 0.0112, Val Loss: 0.0154\n",
      "Epoch [250/1000], Loss: 0.0113, Val Loss: 0.0153\n",
      "Epoch [251/1000], Loss: 0.0112, Val Loss: 0.0153\n",
      "Epoch [252/1000], Loss: 0.0112, Val Loss: 0.0153\n",
      "Epoch [253/1000], Loss: 0.0111, Val Loss: 0.0153\n",
      "Epoch [254/1000], Loss: 0.0111, Val Loss: 0.0153\n",
      "Epoch [255/1000], Loss: 0.0111, Val Loss: 0.0153\n",
      "Epoch [256/1000], Loss: 0.0111, Val Loss: 0.0153\n",
      "Epoch [257/1000], Loss: 0.0111, Val Loss: 0.0152\n",
      "Epoch [258/1000], Loss: 0.0110, Val Loss: 0.0153\n",
      "Epoch [259/1000], Loss: 0.0111, Val Loss: 0.0151\n",
      "Epoch [260/1000], Loss: 0.0110, Val Loss: 0.0152\n",
      "Epoch [261/1000], Loss: 0.0110, Val Loss: 0.0152\n",
      "Epoch [262/1000], Loss: 0.0110, Val Loss: 0.0152\n",
      "Epoch [263/1000], Loss: 0.0110, Val Loss: 0.0152\n",
      "Epoch [264/1000], Loss: 0.0109, Val Loss: 0.0151\n",
      "Epoch [265/1000], Loss: 0.0109, Val Loss: 0.0151\n",
      "Epoch [266/1000], Loss: 0.0109, Val Loss: 0.0151\n",
      "Epoch [267/1000], Loss: 0.0109, Val Loss: 0.0151\n",
      "Epoch [268/1000], Loss: 0.0109, Val Loss: 0.0151\n",
      "Epoch [269/1000], Loss: 0.0108, Val Loss: 0.0150\n",
      "Epoch [270/1000], Loss: 0.0108, Val Loss: 0.0150\n",
      "Epoch [271/1000], Loss: 0.0108, Val Loss: 0.0150\n",
      "Epoch [272/1000], Loss: 0.0108, Val Loss: 0.0150\n",
      "Epoch [273/1000], Loss: 0.0108, Val Loss: 0.0150\n",
      "Epoch [274/1000], Loss: 0.0108, Val Loss: 0.0150\n",
      "Epoch [275/1000], Loss: 0.0107, Val Loss: 0.0150\n",
      "Epoch [276/1000], Loss: 0.0107, Val Loss: 0.0149\n",
      "Epoch [277/1000], Loss: 0.0107, Val Loss: 0.0149\n",
      "Epoch [278/1000], Loss: 0.0107, Val Loss: 0.0148\n",
      "Epoch [279/1000], Loss: 0.0106, Val Loss: 0.0149\n",
      "Epoch [280/1000], Loss: 0.0106, Val Loss: 0.0148\n",
      "Epoch [281/1000], Loss: 0.0106, Val Loss: 0.0148\n",
      "Epoch [282/1000], Loss: 0.0106, Val Loss: 0.0148\n",
      "Epoch [283/1000], Loss: 0.0105, Val Loss: 0.0148\n",
      "Epoch [284/1000], Loss: 0.0105, Val Loss: 0.0148\n",
      "Epoch [285/1000], Loss: 0.0105, Val Loss: 0.0148\n",
      "Epoch [286/1000], Loss: 0.0105, Val Loss: 0.0148\n",
      "Epoch [287/1000], Loss: 0.0105, Val Loss: 0.0148\n",
      "Epoch [288/1000], Loss: 0.0104, Val Loss: 0.0148\n",
      "Epoch [289/1000], Loss: 0.0104, Val Loss: 0.0147\n",
      "Epoch [290/1000], Loss: 0.0104, Val Loss: 0.0147\n",
      "Epoch [291/1000], Loss: 0.0104, Val Loss: 0.0147\n",
      "Epoch [292/1000], Loss: 0.0104, Val Loss: 0.0146\n",
      "Epoch [293/1000], Loss: 0.0104, Val Loss: 0.0146\n",
      "Epoch [294/1000], Loss: 0.0103, Val Loss: 0.0146\n",
      "Epoch [295/1000], Loss: 0.0103, Val Loss: 0.0146\n",
      "Epoch [296/1000], Loss: 0.0102, Val Loss: 0.0146\n",
      "Epoch [297/1000], Loss: 0.0102, Val Loss: 0.0145\n",
      "Epoch [298/1000], Loss: 0.0102, Val Loss: 0.0145\n",
      "Epoch [299/1000], Loss: 0.0102, Val Loss: 0.0145\n",
      "Epoch [300/1000], Loss: 0.0102, Val Loss: 0.0145\n",
      "Epoch [301/1000], Loss: 0.0102, Val Loss: 0.0144\n",
      "Epoch [302/1000], Loss: 0.0101, Val Loss: 0.0144\n",
      "Epoch [303/1000], Loss: 0.0101, Val Loss: 0.0145\n",
      "Epoch [304/1000], Loss: 0.0101, Val Loss: 0.0144\n",
      "Epoch [305/1000], Loss: 0.0101, Val Loss: 0.0144\n",
      "Epoch [306/1000], Loss: 0.0101, Val Loss: 0.0145\n",
      "Epoch [307/1000], Loss: 0.0101, Val Loss: 0.0145\n",
      "Epoch [308/1000], Loss: 0.0101, Val Loss: 0.0145\n",
      "Epoch [309/1000], Loss: 0.0100, Val Loss: 0.0145\n",
      "Epoch [310/1000], Loss: 0.0100, Val Loss: 0.0144\n",
      "Epoch [311/1000], Loss: 0.0100, Val Loss: 0.0143\n",
      "Epoch [312/1000], Loss: 0.0100, Val Loss: 0.0144\n",
      "Epoch [313/1000], Loss: 0.0100, Val Loss: 0.0144\n",
      "Epoch [314/1000], Loss: 0.0099, Val Loss: 0.0143\n",
      "Epoch [315/1000], Loss: 0.0099, Val Loss: 0.0143\n",
      "Epoch [316/1000], Loss: 0.0099, Val Loss: 0.0142\n",
      "Epoch [317/1000], Loss: 0.0098, Val Loss: 0.0142\n",
      "Epoch [318/1000], Loss: 0.0098, Val Loss: 0.0143\n",
      "Epoch [319/1000], Loss: 0.0098, Val Loss: 0.0142\n",
      "Epoch [320/1000], Loss: 0.0098, Val Loss: 0.0142\n",
      "Epoch [321/1000], Loss: 0.0098, Val Loss: 0.0142\n",
      "Epoch [322/1000], Loss: 0.0098, Val Loss: 0.0142\n",
      "Epoch [323/1000], Loss: 0.0097, Val Loss: 0.0142\n",
      "Epoch [324/1000], Loss: 0.0097, Val Loss: 0.0142\n",
      "Epoch [325/1000], Loss: 0.0097, Val Loss: 0.0142\n",
      "Epoch [326/1000], Loss: 0.0097, Val Loss: 0.0141\n",
      "Epoch [327/1000], Loss: 0.0097, Val Loss: 0.0142\n",
      "Epoch [328/1000], Loss: 0.0097, Val Loss: 0.0141\n",
      "Epoch [329/1000], Loss: 0.0096, Val Loss: 0.0142\n",
      "Epoch [330/1000], Loss: 0.0096, Val Loss: 0.0140\n",
      "Epoch [331/1000], Loss: 0.0096, Val Loss: 0.0140\n",
      "Epoch [332/1000], Loss: 0.0096, Val Loss: 0.0140\n",
      "Epoch [333/1000], Loss: 0.0096, Val Loss: 0.0140\n",
      "Epoch [334/1000], Loss: 0.0095, Val Loss: 0.0139\n",
      "Epoch [335/1000], Loss: 0.0095, Val Loss: 0.0140\n",
      "Epoch [336/1000], Loss: 0.0095, Val Loss: 0.0139\n",
      "Epoch [337/1000], Loss: 0.0095, Val Loss: 0.0140\n",
      "Epoch [338/1000], Loss: 0.0095, Val Loss: 0.0139\n",
      "Epoch [339/1000], Loss: 0.0095, Val Loss: 0.0139\n",
      "Epoch [340/1000], Loss: 0.0094, Val Loss: 0.0139\n",
      "Epoch [341/1000], Loss: 0.0094, Val Loss: 0.0139\n",
      "Epoch [342/1000], Loss: 0.0094, Val Loss: 0.0139\n",
      "Epoch [343/1000], Loss: 0.0094, Val Loss: 0.0138\n",
      "Epoch [344/1000], Loss: 0.0094, Val Loss: 0.0138\n",
      "Epoch [345/1000], Loss: 0.0094, Val Loss: 0.0138\n",
      "Epoch [346/1000], Loss: 0.0094, Val Loss: 0.0138\n",
      "Epoch [347/1000], Loss: 0.0093, Val Loss: 0.0137\n",
      "Epoch [348/1000], Loss: 0.0093, Val Loss: 0.0138\n",
      "Epoch [349/1000], Loss: 0.0093, Val Loss: 0.0137\n",
      "Epoch [350/1000], Loss: 0.0093, Val Loss: 0.0137\n",
      "Epoch [351/1000], Loss: 0.0093, Val Loss: 0.0138\n",
      "Epoch [352/1000], Loss: 0.0093, Val Loss: 0.0138\n",
      "Epoch [353/1000], Loss: 0.0093, Val Loss: 0.0136\n",
      "Epoch [354/1000], Loss: 0.0093, Val Loss: 0.0137\n",
      "Epoch [355/1000], Loss: 0.0092, Val Loss: 0.0138\n",
      "Epoch [356/1000], Loss: 0.0093, Val Loss: 0.0137\n",
      "Epoch [357/1000], Loss: 0.0092, Val Loss: 0.0136\n",
      "Epoch [358/1000], Loss: 0.0092, Val Loss: 0.0137\n",
      "Epoch [359/1000], Loss: 0.0092, Val Loss: 0.0137\n",
      "Epoch [360/1000], Loss: 0.0092, Val Loss: 0.0136\n",
      "Epoch [361/1000], Loss: 0.0092, Val Loss: 0.0136\n",
      "Epoch [362/1000], Loss: 0.0092, Val Loss: 0.0136\n",
      "Epoch [363/1000], Loss: 0.0092, Val Loss: 0.0136\n",
      "Epoch [364/1000], Loss: 0.0091, Val Loss: 0.0136\n",
      "Epoch [365/1000], Loss: 0.0091, Val Loss: 0.0136\n",
      "Epoch [366/1000], Loss: 0.0091, Val Loss: 0.0136\n",
      "Epoch [367/1000], Loss: 0.0091, Val Loss: 0.0135\n",
      "Epoch [368/1000], Loss: 0.0091, Val Loss: 0.0136\n",
      "Epoch [369/1000], Loss: 0.0091, Val Loss: 0.0135\n",
      "Epoch [370/1000], Loss: 0.0091, Val Loss: 0.0135\n",
      "Epoch [371/1000], Loss: 0.0090, Val Loss: 0.0135\n",
      "Epoch [372/1000], Loss: 0.0091, Val Loss: 0.0136\n",
      "Epoch [373/1000], Loss: 0.0090, Val Loss: 0.0137\n",
      "Epoch [374/1000], Loss: 0.0091, Val Loss: 0.0135\n",
      "Epoch [375/1000], Loss: 0.0090, Val Loss: 0.0135\n",
      "Epoch [376/1000], Loss: 0.0090, Val Loss: 0.0134\n",
      "Epoch [377/1000], Loss: 0.0090, Val Loss: 0.0135\n",
      "Epoch [378/1000], Loss: 0.0090, Val Loss: 0.0135\n",
      "Epoch [379/1000], Loss: 0.0090, Val Loss: 0.0135\n",
      "Epoch [380/1000], Loss: 0.0090, Val Loss: 0.0135\n",
      "Epoch [381/1000], Loss: 0.0090, Val Loss: 0.0134\n",
      "Epoch [382/1000], Loss: 0.0089, Val Loss: 0.0135\n",
      "Epoch [383/1000], Loss: 0.0089, Val Loss: 0.0134\n",
      "Epoch [384/1000], Loss: 0.0089, Val Loss: 0.0134\n",
      "Epoch [385/1000], Loss: 0.0089, Val Loss: 0.0135\n",
      "Epoch [386/1000], Loss: 0.0089, Val Loss: 0.0135\n",
      "Epoch [387/1000], Loss: 0.0089, Val Loss: 0.0134\n",
      "Epoch [388/1000], Loss: 0.0089, Val Loss: 0.0134\n",
      "Epoch [389/1000], Loss: 0.0089, Val Loss: 0.0134\n",
      "Epoch [390/1000], Loss: 0.0089, Val Loss: 0.0134\n",
      "Epoch [391/1000], Loss: 0.0089, Val Loss: 0.0134\n",
      "Epoch [392/1000], Loss: 0.0089, Val Loss: 0.0134\n",
      "Epoch [393/1000], Loss: 0.0089, Val Loss: 0.0134\n",
      "Epoch [394/1000], Loss: 0.0088, Val Loss: 0.0134\n",
      "Epoch [395/1000], Loss: 0.0088, Val Loss: 0.0134\n",
      "Epoch [396/1000], Loss: 0.0088, Val Loss: 0.0133\n",
      "Epoch [397/1000], Loss: 0.0088, Val Loss: 0.0134\n",
      "Epoch [398/1000], Loss: 0.0088, Val Loss: 0.0133\n",
      "Epoch [399/1000], Loss: 0.0088, Val Loss: 0.0133\n",
      "Epoch [400/1000], Loss: 0.0088, Val Loss: 0.0133\n",
      "Epoch [401/1000], Loss: 0.0088, Val Loss: 0.0133\n",
      "Epoch [402/1000], Loss: 0.0088, Val Loss: 0.0134\n",
      "Epoch [403/1000], Loss: 0.0088, Val Loss: 0.0133\n",
      "Epoch [404/1000], Loss: 0.0088, Val Loss: 0.0133\n",
      "Epoch [405/1000], Loss: 0.0087, Val Loss: 0.0134\n",
      "Epoch [406/1000], Loss: 0.0087, Val Loss: 0.0133\n",
      "Epoch [407/1000], Loss: 0.0087, Val Loss: 0.0133\n",
      "Epoch [408/1000], Loss: 0.0087, Val Loss: 0.0133\n",
      "Epoch [409/1000], Loss: 0.0087, Val Loss: 0.0133\n",
      "Epoch [410/1000], Loss: 0.0087, Val Loss: 0.0133\n",
      "Epoch [411/1000], Loss: 0.0087, Val Loss: 0.0133\n",
      "Epoch [412/1000], Loss: 0.0087, Val Loss: 0.0133\n",
      "Epoch [413/1000], Loss: 0.0087, Val Loss: 0.0133\n",
      "Epoch [414/1000], Loss: 0.0087, Val Loss: 0.0133\n",
      "Epoch [415/1000], Loss: 0.0087, Val Loss: 0.0133\n",
      "Epoch [416/1000], Loss: 0.0087, Val Loss: 0.0133\n",
      "Epoch [417/1000], Loss: 0.0087, Val Loss: 0.0133\n",
      "Epoch [418/1000], Loss: 0.0087, Val Loss: 0.0132\n",
      "Epoch [419/1000], Loss: 0.0087, Val Loss: 0.0133\n",
      "Epoch [420/1000], Loss: 0.0086, Val Loss: 0.0132\n",
      "Epoch [421/1000], Loss: 0.0086, Val Loss: 0.0132\n",
      "Epoch [422/1000], Loss: 0.0086, Val Loss: 0.0133\n",
      "Epoch [423/1000], Loss: 0.0086, Val Loss: 0.0132\n",
      "Epoch [424/1000], Loss: 0.0086, Val Loss: 0.0132\n",
      "Epoch [425/1000], Loss: 0.0086, Val Loss: 0.0133\n",
      "Epoch [426/1000], Loss: 0.0086, Val Loss: 0.0132\n",
      "Epoch [427/1000], Loss: 0.0086, Val Loss: 0.0133\n",
      "Epoch [428/1000], Loss: 0.0086, Val Loss: 0.0132\n",
      "Epoch [429/1000], Loss: 0.0086, Val Loss: 0.0133\n",
      "Epoch [430/1000], Loss: 0.0086, Val Loss: 0.0132\n",
      "Epoch [431/1000], Loss: 0.0086, Val Loss: 0.0132\n",
      "Epoch [432/1000], Loss: 0.0086, Val Loss: 0.0132\n",
      "Epoch [433/1000], Loss: 0.0086, Val Loss: 0.0132\n",
      "Epoch [434/1000], Loss: 0.0086, Val Loss: 0.0131\n",
      "Epoch [435/1000], Loss: 0.0086, Val Loss: 0.0132\n",
      "Epoch [436/1000], Loss: 0.0085, Val Loss: 0.0132\n",
      "Epoch [437/1000], Loss: 0.0085, Val Loss: 0.0132\n",
      "Epoch [438/1000], Loss: 0.0085, Val Loss: 0.0132\n",
      "Epoch [439/1000], Loss: 0.0085, Val Loss: 0.0132\n",
      "Epoch [440/1000], Loss: 0.0085, Val Loss: 0.0132\n",
      "Epoch [441/1000], Loss: 0.0085, Val Loss: 0.0132\n",
      "Epoch [442/1000], Loss: 0.0085, Val Loss: 0.0132\n",
      "Epoch [443/1000], Loss: 0.0085, Val Loss: 0.0132\n",
      "Epoch [444/1000], Loss: 0.0085, Val Loss: 0.0132\n",
      "Early stopping triggered. Restoring best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fm/3vzr0bd54y38wk6x2_8f9xlm0000gn/T/ipykernel_71539/3597263399.py:447: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  reverse_model.load_state_dict(torch.load('best_model.pth'))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a function to tokenize a formula\n",
    "def tokenize_formula(formula):\n",
    "    token_pattern = r\"[a-zA-Z_][a-zA-Z0-9_]*|[()+\\-*/]|\\d+\\.?\\d*\"\n",
    "    tokens = re.findall(token_pattern, formula)\n",
    "    return tokens\n",
    "\n",
    "@dataclass\n",
    "class tNetConfig:\n",
    "    num_vars: int\n",
    "    embedding_size: int\n",
    "\n",
    "class tNet(nn.Module):\n",
    "    def __init__(self, config: tNetConfig):\n",
    "        super(tNet, self).__init__()\n",
    "\n",
    "        self.config = config\n",
    "        self.num_vars = config.num_vars\n",
    "        self.n_embd = config.embedding_size\n",
    "\n",
    "        self.activation_func = F.relu\n",
    "\n",
    "        self.conv1 = nn.Conv1d(self.num_vars + 1, self.n_embd, 1)\n",
    "        self.conv2 = nn.Conv1d(self.n_embd, 2 * self.n_embd, 1)\n",
    "        self.conv3 = nn.Conv1d(2 * self.n_embd, 4 * self.n_embd, 1)\n",
    "\n",
    "        self.fc1 = nn.Linear(4 * self.n_embd, 2 * self.n_embd)\n",
    "        self.fc2 = nn.Linear(2 * self.n_embd, self.n_embd)\n",
    "\n",
    "        self.input_batch_norm = nn.GroupNorm(1, self.num_vars + 1)\n",
    "\n",
    "        self.bn1 = nn.GroupNorm(1, self.n_embd)\n",
    "        self.bn2 = nn.GroupNorm(1, 2 * self.n_embd)\n",
    "        self.bn3 = nn.GroupNorm(1, 4 * self.n_embd)\n",
    "        self.bn4 = nn.GroupNorm(1, 2 * self.n_embd)\n",
    "        self.bn5 = nn.GroupNorm(1, self.n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: [batch, #features + 1, #points]\n",
    "        :return: logit: [batch, embedding_size]\n",
    "        \"\"\"\n",
    "        x = self.input_batch_norm(x)\n",
    "        x = self.activation_func(self.bn1(self.conv1(x)))\n",
    "        x = self.activation_func(self.bn2(self.conv2(x)))\n",
    "        x = self.activation_func(self.bn3(self.conv3(x)))\n",
    "        x, _ = torch.max(x, dim=2)  # global max pooling\n",
    "        assert x.size(1) == 4 * self.n_embd\n",
    "\n",
    "        x = self.activation_func(self.bn4(self.fc1(x)))\n",
    "        x = self.activation_func(self.bn5(self.fc2(x)))\n",
    "\n",
    "        return x\n",
    "\n",
    "class TextDiffusionModel:\n",
    "    def __init__(self, vocab_size, seq_len, device=\"cpu\"):\n",
    "        \"\"\"\n",
    "        Initialize the text diffusion model.\n",
    "\n",
    "        Parameters:\n",
    "        - vocab_size: Size of the vocabulary (number of unique tokens).\n",
    "        - seq_len: Length of the token sequence.\n",
    "        - device: Device to use (\"cpu\" or \"cuda\").\n",
    "        \"\"\"\n",
    "        self.vocab_size = vocab_size\n",
    "        self.seq_len = seq_len\n",
    "        self.device = device\n",
    "        # self.noise_schedule = torch.linspace(0.01, 0.1, steps=1000).to(device)  # Noise variance per timestep\n",
    "        self.noise_schedule = torch.linspace(1e-4, 2e-2, steps=1000).to(device)  # Noise variance per timestep\n",
    "\n",
    "    def add_noise(self, tokens, t):\n",
    "        \"\"\"\n",
    "        Add noise to a sequence of tokens based on timestep t.\n",
    "\n",
    "        Parameters:\n",
    "        - tokens: A tensor of token indices with shape (batch_size, seq_len).\n",
    "        - t: A tensor of timesteps with shape (batch_size,).\n",
    "\n",
    "        Returns:\n",
    "        - noisy_tokens: The tokens with added noise.\n",
    "        - noise: The noise added to the tokens.\n",
    "        \"\"\"\n",
    "        noise_std = self.noise_schedule[t].view(-1, 1, 1)  # Shape: (batch_size, 1, 1)\n",
    "\n",
    "        # Convert tokens to one-hot vectors\n",
    "        one_hot = F.one_hot(tokens.long(), num_classes=self.vocab_size).float()\n",
    "        \n",
    "        # Add Gaussian noise to the one-hot vectors\n",
    "        noise = torch.randn_like(one_hot) * noise_std\n",
    "        noisy_one_hot = one_hot + noise\n",
    "\n",
    "        # Compute softmax to normalize the noisy one-hot vectors\n",
    "        noisy_tokens = F.softmax(noisy_one_hot, dim=-1)\n",
    "        return noisy_tokens, noise\n",
    "\n",
    "    def sample_from_noisy_tokens(self, noisy_tokens):\n",
    "        \"\"\"\n",
    "        Sample discrete tokens from the noisy token distribution.\n",
    "\n",
    "        Parameters:\n",
    "        - noisy_tokens: A tensor of noisy token distributions with shape (batch_size, seq_len, vocab_size).\n",
    "\n",
    "        Returns:\n",
    "        - sampled_tokens: A tensor of sampled token indices with shape (batch_size, seq_len).\n",
    "        \"\"\"\n",
    "        sampled_tokens = torch.argmax(noisy_tokens, dim=-1)\n",
    "        return sampled_tokens\n",
    "\n",
    "class ReverseProcessModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, num_vars, seq_len):\n",
    "        super(ReverseProcessModel, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.num_vars = num_vars\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "        # Calculate the correct input size for fc1\n",
    "        input_size = embedding_size + (seq_len * vocab_size) + 1  # embeddings + noisy_tokens + timestep\n",
    "\n",
    "        # Define layers for the reverse process model\n",
    "        self.fc1 = nn.Linear(input_size, 512)  # Adjusted input size\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, seq_len * vocab_size)  # Output for all tokens in the sequence\n",
    "\n",
    "    def forward(self, noisy_tokens, embeddings, t):\n",
    "        \"\"\"\n",
    "        Forward pass for the reverse process model.\n",
    "\n",
    "        :param noisy_tokens: Tensor of noisy tokens with shape [batch_size, seq_len, vocab_size].\n",
    "        :param embeddings: Tensor of embeddings with shape [batch_size, embedding_size].\n",
    "        :param t: Tensor of timesteps with shape [batch_size].\n",
    "        :return: Predicted noise.\n",
    "        \"\"\"\n",
    "        # Flatten noisy tokens to [batch_size, seq_len * vocab_size]\n",
    "        noisy_tokens_flat = noisy_tokens.view(noisy_tokens.size(0), -1)\n",
    "\n",
    "        # Concatenate embeddings, flattened noisy tokens, and timestep information\n",
    "        timestep_embedding = torch.cat([embeddings, noisy_tokens_flat, t.unsqueeze(1).float()], dim=-1)\n",
    "        \n",
    "        # Pass through the fully connected layers\n",
    "        x = F.relu(self.fc1(timestep_embedding))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        predicted_noise = self.fc3(x)\n",
    "\n",
    "        # Reshape to [batch_size, seq_len, vocab_size]\n",
    "        predicted_noise = predicted_noise.view(-1, self.seq_len, self.vocab_size)\n",
    "        \n",
    "        return predicted_noise\n",
    "\n",
    "# Main function\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Define the device \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    folder_path = \"data_symbolic_regression/train\"\n",
    "    val_folder_path = \"data_symbolic_regression/val\"\n",
    "\n",
    "    # Load and tokenize formulas from the training set; Convert the data points to a Pytorch tensor\n",
    "    tokenized_formulas = []\n",
    "    points_list = []\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".json\") and not file_name.startswith('properties'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            with open(file_path, \"r\") as file:\n",
    "                data = json.load(file)\n",
    "\n",
    "                formula_human_readable = data.get(\"formula_human_readable\", \"\")\n",
    "                if formula_human_readable:\n",
    "                    tokens = tokenize_formula(formula_human_readable)\n",
    "                    tokenized_formulas.append(tokens)\n",
    "                \n",
    "                points = data.get(\"points\")\n",
    "                if points:\n",
    "                    points_array = np.array([points[\"var_0\"], points[\"var_1\"], points[\"var_2\"], points[\"target\"]])\n",
    "                    points_tensor = torch.tensor(points_array, dtype=torch.float32, device=device).unsqueeze(0)  # Add batch dimension\n",
    "                    points_list.append(points_tensor)\n",
    "                    # Need below line if points_array is transposed\n",
    "                    # points_tensor = torch.tensor(points_array, dtype=torch.float32, device=device).unsqueeze(0).permute(0, 2, 1)  # Add batch dimension and transpose\n",
    "\n",
    "    val_tokenized_formulas = []\n",
    "    val_points_list = []\n",
    "\n",
    "    # Create the vocabulary from the tokens\n",
    "    for file_name in os.listdir(val_folder_path):\n",
    "        if file_name.endswith(\".json\") and not file_name.startswith('properties'):\n",
    "            file_path = os.path.join(val_folder_path, file_name)\n",
    "            with open(file_path, \"r\") as file:\n",
    "                val_data = json.load(file)\n",
    "\n",
    "                val_formula_human_readable = val_data.get(\"formula_human_readable\", \"\")\n",
    "                if val_formula_human_readable:\n",
    "                    val_tokens = tokenize_formula(val_formula_human_readable)\n",
    "                    val_tokenized_formulas.append(val_tokens)\n",
    "                \n",
    "                val_points = val_data.get(\"points\")\n",
    "                if val_points:\n",
    "                    val_points_array = np.array([val_points[\"var_0\"], val_points[\"var_1\"], val_points[\"var_2\"], val_points[\"target\"]])\n",
    "                    val_points_tensor = torch.tensor(val_points_array, dtype=torch.float32, device=device).unsqueeze(0)  # Add batch dimension\n",
    "                    val_points_list.append(val_points_tensor)\n",
    "\n",
    "    vocab_mapping = {token: idx for idx, token in enumerate(set(t for tokens in tokenized_formulas for t in tokens))}\n",
    "    vocab_size = len(vocab_mapping)\n",
    "\n",
    "    # Define EOS and PAD token IDs\n",
    "    eos_token_id = vocab_size - 1  # Assuming the last ID in the vocabulary is for EOS\n",
    "    pad_token_id = vocab_size - 2  # Assuming the second-to-last ID in the vocabulary is for PAD\n",
    "\n",
    "    # Add EOS and PAD tokens to vocab_mapping if not already present\n",
    "    if eos_token_id not in vocab_mapping.values():\n",
    "        vocab_mapping['<EOS>'] = eos_token_id\n",
    "    if pad_token_id not in vocab_mapping.values():\n",
    "        vocab_mapping['<PAD>'] = pad_token_id\n",
    "\n",
    "    # Tokenize and map tokens to vocabulary indices\n",
    "    token_sequences = [[vocab_mapping.get(token, pad_token_id) for token in tokens] for tokens in tokenized_formulas]\n",
    "\n",
    "    # Calculate sequence length based on the 95th percentile of formula lengths\n",
    "    formula_lengths = [len(tokens) for tokens in tokenized_formulas]\n",
    "    seq_len = int(np.percentile(formula_lengths, 95))  # Use 95th percentile\n",
    "    batch_size = 100  # Example batch size\n",
    "\n",
    "    # Pad or truncate sequences to seq_len, adding EOS token last\n",
    "    token_sequences = [\n",
    "        seq[:seq_len] + [pad_token_id] * max(0, seq_len - len(seq)) + [eos_token_id] \n",
    "        if len(seq) < seq_len else seq[:seq_len] + [eos_token_id]  # Add EOS token at the end after padding\n",
    "        for seq in token_sequences\n",
    "    ]\n",
    "\n",
    "    # Convert to tensor\n",
    "    token_tensor = torch.tensor(token_sequences, device=device)\n",
    "\n",
    "    # Initialize the model\n",
    "    diffusion_model = TextDiffusionModel(vocab_size, seq_len, device=device)\n",
    "    \n",
    "    # Pad or truncate sequences to seq_len\n",
    "    token_sequences = [seq[:seq_len] + [0] * max(0, seq_len - len(seq)) for seq in token_sequences]\n",
    "    token_tensor = torch.tensor(token_sequences, device=device)\n",
    "\n",
    "    val_vocab_mapping = {token: idx for idx, token in enumerate(set(t for tokens in val_tokenized_formulas for t in tokens))}\n",
    "    val_vocab_size = len(val_vocab_mapping)\n",
    "\n",
    "    # Add EOS and PAD tokens to vocab_mapping if not already present\n",
    "    if eos_token_id not in val_vocab_mapping.values():\n",
    "        val_vocab_mapping['<EOS>'] = eos_token_id\n",
    "    if pad_token_id not in val_vocab_mapping.values():\n",
    "        val_vocab_mapping['<PAD>'] = pad_token_id\n",
    "\n",
    "    # Tokenize and map tokens to vocabulary indices\n",
    "    val_token_sequences = [[val_vocab_mapping.get(token, pad_token_id) for token in tokens] for tokens in val_tokenized_formulas]\n",
    "\n",
    "    # Calculate sequence length based on the 95th percentile of formula lengths\n",
    "    val_formula_lengths = [len(tokens) for tokens in val_tokenized_formulas]\n",
    "    val_seq_len = int(np.percentile(val_formula_lengths, 95))  # Use 95th percentile\n",
    "\n",
    "    # Pad or truncate sequences to seq_len, adding EOS token last\n",
    "    val_token_sequences = [\n",
    "        seq[:seq_len] + [pad_token_id] * max(0, seq_len - len(seq)) + [eos_token_id] \n",
    "        if len(seq) < seq_len else seq[:seq_len] + [eos_token_id]  # Add EOS token at the end after padding\n",
    "        for seq in val_token_sequences\n",
    "    ]\n",
    "\n",
    "    # Convert to tensor\n",
    "    val_token_tensor = torch.tensor(val_token_sequences, device=device)\n",
    "\n",
    "    # Initialize the model\n",
    "    diffusion_model = TextDiffusionModel(vocab_size, seq_len, device=device)\n",
    "    \n",
    "    # Pad or truncate sequences to seq_len\n",
    "    val_token_sequences = [seq[:seq_len] + [0] * max(0, seq_len - len(seq)) for seq in val_token_sequences]\n",
    "    val_token_tensor = torch.tensor(val_token_sequences, device=device)\n",
    "\n",
    "    t = torch.randint(0, 1000, (len(token_tensor),), device=device)\n",
    "\n",
    "    # Add noise to the tokens\n",
    "    noisy_tokens, noise = diffusion_model.add_noise(token_tensor, t)\n",
    "\n",
    "    # Sample from noisy tokens\n",
    "    sampled_tokens = diffusion_model.sample_from_noisy_tokens(noisy_tokens)\n",
    "\n",
    "    # Configuration for tNet\n",
    "    num_vars = 3\n",
    "    embedding_size = 128  # Example embedding size\n",
    "    config = tNetConfig(num_vars=num_vars, embedding_size=embedding_size)\n",
    "\n",
    "    # Instantiate the model\n",
    "    tnet_model = tNet(config)\n",
    "\n",
    "    # Input: batch_size x (num_vars + 1) x num_points\n",
    "    batch_size = 1\n",
    "\n",
    "    # Generate embeddings\n",
    "    # input_tensor = torch.rand(batch_size, num_vars, 100)\n",
    "\n",
    "    output_embeddings = []\n",
    "    for pt in points_list:\n",
    "        output_embedding = tnet_model(pt)\n",
    "        output_embeddings.append(output_embedding)\n",
    "    \n",
    "    points_tensors = torch.cat(points_list, dim=0)\n",
    "    \n",
    "    output_embeddings_tensor = torch.cat(output_embeddings, dim=0)\n",
    "    # Print the output\n",
    "    print(\"Input shape:\", points_tensors.shape)\n",
    "    print(\"Output shape:\", output_embeddings_tensor.shape)\n",
    "\n",
    "    # Print results\n",
    "    print(\"Original Tokens shape:\", token_tensor.shape)\n",
    "    print(\"Noisy Tokens (probabilities) shape:\", noisy_tokens.shape)\n",
    "    print(\"Sampled Tokens shape:\", sampled_tokens.shape)\n",
    "\n",
    "    # Initialize reverse model (denoiser)\n",
    "    reverse_model = ReverseProcessModel(vocab_size, embedding_size, num_vars, seq_len).to(device)\n",
    "\n",
    "    # Cross-entropy loss function\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Train the reverse process model\n",
    "    epochs = 1000  # Define the number of epochs for training\n",
    "    batch_size = 100  # Example batch size\n",
    "\n",
    "    # Optimizer for the reverse process model\n",
    "    optimizer = torch.optim.Adam(reverse_model.parameters(), lr=1e-4)\n",
    "\n",
    "    # Early stopping parameters\n",
    "    patience = 10\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    # Initialize lists to store training and validation losses\n",
    "    training_losses = []\n",
    "    validation_losses = []\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        reverse_model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        # Training Phase\n",
    "        for batch_idx in range(0, len(points_list), batch_size):\n",
    "            batch_points = points_list[batch_idx:batch_idx + batch_size]\n",
    "            batch_token_tensor = token_tensor[batch_idx:batch_idx + batch_size]\n",
    "\n",
    "            # Random timesteps\n",
    "            t_batch = torch.randint(0, 1000, (len(batch_points),), device=device)\n",
    "\n",
    "            # Add noise\n",
    "            noisy_tokens, _ = diffusion_model.add_noise(batch_token_tensor, t_batch)\n",
    "\n",
    "            # Get embeddings\n",
    "            batch_embeddings = [tnet_model(pt) for pt in batch_points]\n",
    "            embeddings_tensor = torch.cat(batch_embeddings, dim=0)\n",
    "\n",
    "            # Predict logits\n",
    "            logits = reverse_model(noisy_tokens, embeddings_tensor, t_batch)\n",
    "\n",
    "            # Reshape logits and target tokens for CrossEntropyLoss\n",
    "            logits_flat = logits.view(-1, vocab_size)\n",
    "            target_tokens = batch_token_tensor.view(-1)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_fn(logits_flat, target_tokens)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation Phase\n",
    "        reverse_model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for val_batch_idx in range(0, len(val_points_list), batch_size):\n",
    "                val_batch_points = val_points_list[val_batch_idx:val_batch_idx + batch_size]\n",
    "                val_batch_token_tensor = val_token_tensor[val_batch_idx:val_batch_idx + batch_size]\n",
    "\n",
    "                val_t_batch = torch.randint(0, 1000, (len(val_batch_points),), device=device)\n",
    "\n",
    "                val_noisy_tokens, _ = diffusion_model.add_noise(val_batch_token_tensor, val_t_batch)\n",
    "\n",
    "                val_embeddings = [tnet_model(pt) for pt in val_batch_points]\n",
    "                val_embeddings_tensor = torch.cat(val_embeddings, dim=0)\n",
    "\n",
    "                val_logits = reverse_model(val_noisy_tokens, val_embeddings_tensor, val_t_batch)\n",
    "                val_logits_flat = val_logits.view(-1, vocab_size)\n",
    "                val_target_tokens = val_batch_token_tensor.view(-1)\n",
    "\n",
    "                val_loss += loss_fn(val_logits_flat, val_target_tokens).item()\n",
    "\n",
    "        val_loss /= len(val_points_list)\n",
    "\n",
    "        # Store losses for plotting\n",
    "        training_losses.append(total_loss / len(points_list))\n",
    "        validation_losses.append(val_loss)\n",
    "\n",
    "        # Print progress\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {training_losses[-1]:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Early stopping logic\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(reverse_model.state_dict(), 'best_model.pth')  # Save the best model\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"Early stopping triggered. Restoring best model...\")\n",
    "            reverse_model.load_state_dict(torch.load('best_model.pth'))\n",
    "            break\n",
    "\n",
    "    # Plot training and validation losses\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(training_losses) + 1), training_losses, label='Training Loss', color='blue')\n",
    "    plt.plot(range(1, len(validation_losses) + 1), validation_losses, label='Validation Loss', color='orange')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss Curves')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_diffusion_model(test_folder, diffusion_model, reverse_model, tnet_model, vocab_mapping, seq_len, device):\n",
    "    \"\"\"\n",
    "    Evaluate the diffusion model on the test set.\n",
    "\n",
    "    Parameters:\n",
    "    - test_folder: Path to the folder containing the test JSON files.\n",
    "    - diffusion_model: Instance of the TextDiffusionModel.\n",
    "    - reverse_model: Instance of the ReverseProcessModel.\n",
    "    - tnet_model: Instance of the tNet model for generating embeddings.\n",
    "    - vocab_mapping: Dictionary mapping tokens to indices.\n",
    "    - seq_len: Length of the token sequence.\n",
    "    - device: Device to use (\"cpu\" or \"cuda\").\n",
    "\n",
    "    Returns:\n",
    "    - results: List of tuples (actual_formula, reconstructed_formula).\n",
    "    \"\"\"\n",
    "    reverse_vocab_mapping = {idx: token for token, idx in vocab_mapping.items()}\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for file_name in os.listdir(test_folder):\n",
    "        if file_name.endswith(\".json\") and not file_name.startswith('properties'):\n",
    "            file_path = os.path.join(test_folder, file_name)\n",
    "\n",
    "            with open(file_path, \"r\") as file:\n",
    "                data = json.load(file)\n",
    "\n",
    "                formula_human_readable = data.get(\"formula_human_readable\", \"\")\n",
    "                tokens = tokenize_formula(formula_human_readable)\n",
    "\n",
    "                # Convert tokens to indices\n",
    "                token_indices = [vocab_mapping.get(token, 0) for token in tokens]\n",
    "\n",
    "                # Pad or truncate to seq_len\n",
    "                token_indices = token_indices[:seq_len] + [0] * max(0, seq_len - len(token_indices))\n",
    "                token_tensor = torch.tensor(token_indices, device=device).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "                points = data.get(\"points\")\n",
    "                if points:\n",
    "                    points_array = np.array([points[\"var_0\"], points[\"var_1\"], points[\"var_2\"], points[\"target\"]])\n",
    "                    points_tensor = torch.tensor(points_array, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "                    # Generate embeddings using tNet model\n",
    "                    embedding = tnet_model(points_tensor)\n",
    "\n",
    "                    # Choose random timestep\n",
    "                    t = torch.randint(0, 1000, (1,), device=device)\n",
    "\n",
    "                    # Add noise to the tokens\n",
    "                    noisy_tokens, _ = diffusion_model.add_noise(token_tensor, t)\n",
    "\n",
    "                    # Use reverse model to reconstruct the clean tokens\n",
    "                    reconstructed_noise = reverse_model(noisy_tokens, embedding, t)\n",
    "                    # print(f\"Reconstructed Noise Shape: {reconstructed_noise.shape}\")\n",
    "                    # Convert reconstructed noise to token indices\n",
    "                    # reconstructed_tokens = torch.argmax(reconstructed_noise, dim=-1).squeeze(0)\n",
    "\n",
    "                    # Ensure reconstructed_tokens is a list\n",
    "                    reconstructed_tokens = torch.argmax(reconstructed_noise, dim=-1)\n",
    "                    # print(reconstructed_tokens)\n",
    "                    if reconstructed_tokens.dim() == 2:  # Case: (batch_size, seq_len)\n",
    "                        reconstructed_tokens = reconstructed_tokens.squeeze(0)  # Remove batch dimension\n",
    "                    elif reconstructed_tokens.dim() == 1:  # Case: (seq_len,)\n",
    "                        pass  # Already correct\n",
    "                    else:\n",
    "                        raise ValueError(f\"Unexpected shape for reconstructed_tokens: {reconstructed_tokens.shape}\")\n",
    "\n",
    "                    # print(reconstructed_tokens)\n",
    "                    # Map token indices back to tokens\n",
    "                    reconstructed_formula = \" \".join(\n",
    "                        reverse_vocab_mapping[idx] if idx in reverse_vocab_mapping else \"<UNK>\" for idx in reconstructed_tokens.tolist()\n",
    "                    )\n",
    "                    \n",
    "                    actual_formula = \" \".join(tokens)\n",
    "\n",
    "                    results.append((actual_formula, reconstructed_formula))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Formula: ( sin ( ( var_2 * var_1 ) ) * log ( sinh ( var_0 ) ) )\n",
      "Reconstructed Formula: ( log ( ( var_2 + var_1 ) ) * tanh ( ( ( var_2 ) ) ) gaussian gaussian gaussian gaussian gaussian gaussian\n"
     ]
    }
   ],
   "source": [
    "# Define the device \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "folder_path_test = \"data_symbolic_regression/test\"\n",
    "\n",
    "# Load and tokenize formulas from the training set; Convert the data points to a Pytorch tensor\n",
    "tokenized_formulas_test = []\n",
    "points_list_test = []\n",
    "\n",
    "for file_name in os.listdir(folder_path_test):\n",
    "    if file_name.endswith(\".json\") and not file_name.startswith('properties'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        with open(file_path, \"r\") as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "            formula_human_readable_test = data.get(\"formula_human_readable\", \"\")\n",
    "            if formula_human_readable_test:\n",
    "                tokens_test = tokenize_formula(formula_human_readable_test)\n",
    "                tokenized_formulas_test.append(tokens_test)\n",
    "                \n",
    "            points_test = data.get(\"points\")\n",
    "            if points_test:\n",
    "                points_array_test = np.array([points_test[\"var_0\"], points_test[\"var_1\"], points_test[\"var_2\"], points_test[\"target\"]])\n",
    "                points_tensor_test = torch.tensor(points_array_test, dtype=torch.float32, device=device).unsqueeze(0)  # Add batch dimension\n",
    "                points_list_test.append(points_tensor_test)\n",
    "                # Need below line if points_array is transposed\n",
    "                # points_tensor = torch.tensor(points_array, dtype=torch.float32, device=device).unsqueeze(0).permute(0, 2, 1)  # Add batch dimension and transpose\n",
    "\n",
    "# Create the vocabulary from the tokens\n",
    "# vocab_mapping_test = {token: idx for idx, token in enumerate(set(t for tokens in tokenized_formulas_test for t in tokens))}\n",
    "# vocab_size_test = len(vocab_mapping_test)\n",
    "\n",
    "# token_sequences_test = [[vocab_mapping_test[token] for token in tokens] for tokens in tokenized_formulas_test]\n",
    "\n",
    "# formula_lengths_test = [len(tokens) for tokens in tokenized_formulas_test]\n",
    "# seq_len_test = int(np.percentile(formula_lengths_test, 95))  # Use 95th percentile\n",
    "\n",
    "# # Initialize the model\n",
    "# diffusion_model_test = TextDiffusionModel(vocab_size_test, seq_len_test, device=device)\n",
    "    \n",
    "# # Pad or truncate sequences to seq_len\n",
    "# token_sequences_test = [seq[:seq_len] + [0] * max(0, seq_len - len(seq)) for seq in token_sequences_test]\n",
    "# token_tensor_test = torch.tensor(token_sequences_test, device=device)\n",
    "\n",
    "# # Choose random timesteps for each sequence\n",
    "# t = torch.randint(0, 1000, (len(token_tensor_test),), device=device)\n",
    "\n",
    "# # Configuration for tNet\n",
    "# num_vars_test = 3\n",
    "# embedding_size_test = 32  # Example embedding size\n",
    "# config_test = tNetConfig(num_vars=num_vars_test, embedding_size=embedding_size_test)\n",
    "\n",
    "# # Instantiate the model\n",
    "# tnet_model_test = tNet(config_test)\n",
    "\n",
    "# reverse_model = ReverseProcessModel(vocab_size_test, embedding_size_test, num_vars_test, seq_len_test).to(device)\n",
    "\n",
    "# Evaluate the model\n",
    "results = evaluate_diffusion_model(folder_path_test, diffusion_model, reverse_model, tnet_model, vocab_mapping, seq_len, device)\n",
    "\n",
    "# Display example results\n",
    "example_idx = 2  # Index of the example to display\n",
    "\n",
    "if results:\n",
    "    actual, reconstructed = results[example_idx]\n",
    "    print(f\"Actual Formula: {actual}\")\n",
    "    print(f\"Reconstructed Formula: {reconstructed}\")\n",
    "\n",
    "# Calculate accuracy or similarity score (optional)\n",
    "# accuracies = [accuracy_score(list(actual), list(reconstructed)) for actual, reconstructed in results]\n",
    "# print(f\"Average Reconstruction Accuracy: {np.mean(accuracies):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stat940-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
